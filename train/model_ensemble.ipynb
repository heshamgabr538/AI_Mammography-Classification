{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('X_val_with_callback.npy')\n",
    "y=np.load('y_val_with_callback.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def model_load(model):\n",
    "    model = load_model(model,compile=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "            metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble할 model load\n",
    "\n",
    "model1=model_load('./G_팔로미_models/VGG16_fine_tuning_3(665).hdf5')\n",
    "model2=model_load('./G_팔로미_models/Inception v3_fine tuning_2(631).hdf5')\n",
    "model3=model_load('./G_팔로미_models/VGG16_2.hdf5')\n",
    "\n",
    "members = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, X):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(X) for model in members]\n",
    "    yhats = np.array(yhats)\n",
    "    # sum across ensemble members\n",
    "    summed = np.sum(yhats, axis=0)\n",
    "    # argmax across classes\n",
    "    avg=summed/len(members)\n",
    "    #result = np.argmax(summed, axis=1)\n",
    "    return avg\n",
    "\n",
    "# evaluate ensemble model\n",
    "def evaluate_members(members, X, y):\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(members, X)\n",
    "    # calculate accuracy\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = ensemble_predictions(members, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=np.argmax(y,axis=1)\n",
    "predict=np.argmax(yhat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980777291320255"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC 출력하기\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "roc_auc_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6620111731843575"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
