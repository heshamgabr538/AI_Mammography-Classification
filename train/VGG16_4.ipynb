{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    ##featurewise_center=True,\n",
    "    #featurewise_std_normalization=True, \n",
    "    rotation_range=25.0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0604 13:53:40.272425 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0604 13:53:40.291999 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0604 13:53:40.293010 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0604 13:53:40.331020 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0604 13:53:40.525205 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0604 13:53:40.531656 14236 deprecation.py:506] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0604 13:53:40.601682 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 264)               135432    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1060      \n",
      "=================================================================\n",
      "Total params: 128,629,356\n",
      "Trainable params: 128,629,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.applications import VGG16\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
    " \n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    " \n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    " \n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    " \n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    " \n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    " \n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, kernel_initializer='he_normal')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(2048, kernel_initializer='he_normal')(x)\n",
    "x = layers.Dense(1024, kernel_initializer='he_normal')(x)\n",
    "x = layers.Dense(512, kernel_initializer='he_normal')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(264, kernel_initializer='he_normal')(x)\n",
    "output_tensor = layers.Dense(4, activation='softmax')(x)\n",
    " \n",
    "myvgg = Model(input_tensor, output_tensor)\n",
    "myvgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='My_VGG_weight_4.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 13:54:38.253296 14236 deprecation_wrapper.py:119] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0604 13:54:38.349557 14236 deprecation.py:323] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "myvgg.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['accuracy', auc, precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2861, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history1=myvgg.fit(X,y,batch_size=32,\n",
    "#                   epochs=100,\n",
    "#                   validation_split=0.3,\n",
    "#                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 13:54:52.348991 14236 deprecation.py:323] From C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 86.7691 - acc: 0.3770 - auc: 0.5467 - precision: 0.4127 - recall: 0.3016 - f1score: 0.3435 - val_loss: 82.6399 - val_acc: 0.5332 - val_auc: 0.6249 - val_precision: 0.6417 - val_recall: 0.3562 - val_f1score: 0.4570\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 81.3189 - acc: 0.4959 - auc: 0.6714 - precision: 0.5657 - recall: 0.3516 - f1score: 0.4304 - val_loss: 79.6685 - val_acc: 0.5192 - val_auc: 0.7055 - val_precision: 0.6257 - val_recall: 0.4040 - val_f1score: 0.4904\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 54s 544ms/step - loss: 78.2809 - acc: 0.5149 - auc: 0.7262 - precision: 0.5902 - recall: 0.3861 - f1score: 0.4644 - val_loss: 76.7093 - val_acc: 0.5367 - val_auc: 0.7440 - val_precision: 0.5806 - val_recall: 0.4610 - val_f1score: 0.5134\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 75.2654 - acc: 0.5309 - auc: 0.7565 - precision: 0.5998 - recall: 0.4069 - f1score: 0.4829 - val_loss: 73.6783 - val_acc: 0.5658 - val_auc: 0.7677 - val_precision: 0.6322 - val_recall: 0.4761 - val_f1score: 0.5426\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 72.3069 - acc: 0.5567 - auc: 0.7770 - precision: 0.6182 - recall: 0.4372 - f1score: 0.5108 - val_loss: 70.8141 - val_acc: 0.5611 - val_auc: 0.7849 - val_precision: 0.6322 - val_recall: 0.4494 - val_f1score: 0.5245\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 69.4732 - acc: 0.5624 - auc: 0.7914 - precision: 0.6211 - recall: 0.4535 - f1score: 0.5232 - val_loss: 68.1442 - val_acc: 0.5402 - val_auc: 0.7969 - val_precision: 0.5850 - val_recall: 0.4342 - val_f1score: 0.4980\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 57s 566ms/step - loss: 66.7127 - acc: 0.5633 - auc: 0.8015 - precision: 0.6129 - recall: 0.4593 - f1score: 0.5239 - val_loss: 65.3856 - val_acc: 0.5646 - val_auc: 0.8060 - val_precision: 0.6194 - val_recall: 0.4680 - val_f1score: 0.5327\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 57s 565ms/step - loss: 64.0460 - acc: 0.5650 - auc: 0.8100 - precision: 0.6153 - recall: 0.4677 - f1score: 0.5306 - val_loss: 62.8099 - val_acc: 0.5250 - val_auc: 0.8134 - val_precision: 0.5655 - val_recall: 0.4575 - val_f1score: 0.5043\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 61.4979 - acc: 0.5722 - auc: 0.8167 - precision: 0.6222 - recall: 0.4862 - f1score: 0.5449 - val_loss: 60.2347 - val_acc: 0.5623 - val_auc: 0.8198 - val_precision: 0.5980 - val_recall: 0.4936 - val_f1score: 0.5402\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 59.0630 - acc: 0.5842 - auc: 0.8225 - precision: 0.6272 - recall: 0.4925 - f1score: 0.5512 - val_loss: 57.8271 - val_acc: 0.5809 - val_auc: 0.8252 - val_precision: 0.6198 - val_recall: 0.5274 - val_f1score: 0.5695\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 56.7075 - acc: 0.5793 - auc: 0.8274 - precision: 0.6229 - recall: 0.4963 - f1score: 0.5517 - val_loss: 55.5700 - val_acc: 0.5786 - val_auc: 0.8296 - val_precision: 0.6231 - val_recall: 0.5192 - val_f1score: 0.5661\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 54.4639 - acc: 0.5879 - auc: 0.8316 - precision: 0.6234 - recall: 0.5053 - f1score: 0.5575 - val_loss: 53.3407 - val_acc: 0.5774 - val_auc: 0.8336 - val_precision: 0.6082 - val_recall: 0.5250 - val_f1score: 0.5634\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 52.3161 - acc: 0.5892 - auc: 0.8354 - precision: 0.6278 - recall: 0.5157 - f1score: 0.5656 - val_loss: 51.2081 - val_acc: 0.5949 - val_auc: 0.8373 - val_precision: 0.6371 - val_recall: 0.5378 - val_f1score: 0.5832\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 50.2423 - acc: 0.5887 - auc: 0.8389 - precision: 0.6232 - recall: 0.5205 - f1score: 0.5667 - val_loss: 49.2178 - val_acc: 0.5902 - val_auc: 0.8403 - val_precision: 0.6293 - val_recall: 0.5460 - val_f1score: 0.5846\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 48.2577 - acc: 0.6013 - auc: 0.8419 - precision: 0.6370 - recall: 0.5408 - f1score: 0.5846 - val_loss: 47.3034 - val_acc: 0.5960 - val_auc: 0.8434 - val_precision: 0.6297 - val_recall: 0.5623 - val_f1score: 0.5940\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 46.4092 - acc: 0.5958 - auc: 0.8447 - precision: 0.6227 - recall: 0.5308 - f1score: 0.5725 - val_loss: 45.8122 - val_acc: 0.5332 - val_auc: 0.8457 - val_precision: 0.5755 - val_recall: 0.5099 - val_f1score: 0.5399\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 44.6831 - acc: 0.6096 - auc: 0.8467 - precision: 0.6388 - recall: 0.5431 - f1score: 0.5864 - val_loss: 43.8282 - val_acc: 0.5844 - val_auc: 0.8479 - val_precision: 0.6083 - val_recall: 0.5378 - val_f1score: 0.5707\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 43.0652 - acc: 0.6083 - auc: 0.8490 - precision: 0.6357 - recall: 0.5523 - f1score: 0.5906 - val_loss: 42.2656 - val_acc: 0.5937 - val_auc: 0.8501 - val_precision: 0.6242 - val_recall: 0.5448 - val_f1score: 0.5817\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 41.4948 - acc: 0.6046 - auc: 0.8511 - precision: 0.6300 - recall: 0.5448 - f1score: 0.5837 - val_loss: 40.7592 - val_acc: 0.5902 - val_auc: 0.8520 - val_precision: 0.6226 - val_recall: 0.5471 - val_f1score: 0.5822\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 39.9699 - acc: 0.6050 - auc: 0.8530 - precision: 0.6311 - recall: 0.5514 - f1score: 0.5882 - val_loss: 39.2061 - val_acc: 0.5984 - val_auc: 0.8539 - val_precision: 0.6237 - val_recall: 0.5739 - val_f1score: 0.5977\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 38.5577 - acc: 0.6136 - auc: 0.8548 - precision: 0.6395 - recall: 0.5635 - f1score: 0.5986 - val_loss: 37.8388 - val_acc: 0.6135 - val_auc: 0.8558 - val_precision: 0.6374 - val_recall: 0.5728 - val_f1score: 0.6031\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 37.1983 - acc: 0.6250 - auc: 0.8567 - precision: 0.6484 - recall: 0.5768 - f1score: 0.6101 - val_loss: 36.5306 - val_acc: 0.5995 - val_auc: 0.8576 - val_precision: 0.6122 - val_recall: 0.5774 - val_f1score: 0.5943\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 35.9040 - acc: 0.6199 - auc: 0.8585 - precision: 0.6425 - recall: 0.5753 - f1score: 0.6067 - val_loss: 35.2778 - val_acc: 0.6007 - val_auc: 0.8592 - val_precision: 0.6144 - val_recall: 0.5693 - val_f1score: 0.5908\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 34.7005 - acc: 0.6219 - auc: 0.8600 - precision: 0.6445 - recall: 0.5803 - f1score: 0.6104 - val_loss: 34.1270 - val_acc: 0.5867 - val_auc: 0.8607 - val_precision: 0.5978 - val_recall: 0.5553 - val_f1score: 0.5753\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 33.5513 - acc: 0.6154 - auc: 0.8614 - precision: 0.6391 - recall: 0.5771 - f1score: 0.6062 - val_loss: 33.0698 - val_acc: 0.5879 - val_auc: 0.8620 - val_precision: 0.6198 - val_recall: 0.5611 - val_f1score: 0.5886\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 32.4369 - acc: 0.6207 - auc: 0.8627 - precision: 0.6398 - recall: 0.5784 - f1score: 0.6073 - val_loss: 31.8776 - val_acc: 0.6182 - val_auc: 0.8633 - val_precision: 0.6258 - val_recall: 0.5856 - val_f1score: 0.6049\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 31.3772 - acc: 0.6294 - auc: 0.8640 - precision: 0.6470 - recall: 0.5918 - f1score: 0.6179 - val_loss: 30.8942 - val_acc: 0.5972 - val_auc: 0.8647 - val_precision: 0.6155 - val_recall: 0.5693 - val_f1score: 0.5913\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 30.3740 - acc: 0.6271 - auc: 0.8653 - precision: 0.6456 - recall: 0.5919 - f1score: 0.6173 - val_loss: 30.1605 - val_acc: 0.5471 - val_auc: 0.8658 - val_precision: 0.5780 - val_recall: 0.5332 - val_f1score: 0.5545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 29.4303 - acc: 0.6276 - auc: 0.8663 - precision: 0.6445 - recall: 0.5944 - f1score: 0.6182 - val_loss: 28.9396 - val_acc: 0.6228 - val_auc: 0.8669 - val_precision: 0.6348 - val_recall: 0.5949 - val_f1score: 0.6141\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 28.5244 - acc: 0.6242 - auc: 0.8674 - precision: 0.6436 - recall: 0.5877 - f1score: 0.6141 - val_loss: 28.0525 - val_acc: 0.6263 - val_auc: 0.8680 - val_precision: 0.6391 - val_recall: 0.6042 - val_f1score: 0.6211\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 27.6780 - acc: 0.6322 - auc: 0.8685 - precision: 0.6502 - recall: 0.6007 - f1score: 0.6242 - val_loss: 27.3613 - val_acc: 0.5984 - val_auc: 0.8691 - val_precision: 0.6118 - val_recall: 0.5832 - val_f1score: 0.5971\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 26.8741 - acc: 0.6389 - auc: 0.8695 - precision: 0.6552 - recall: 0.6082 - f1score: 0.6306 - val_loss: 26.6654 - val_acc: 0.5960 - val_auc: 0.8700 - val_precision: 0.6046 - val_recall: 0.5891 - val_f1score: 0.5965\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 26.1341 - acc: 0.6400 - auc: 0.8704 - precision: 0.6571 - recall: 0.6093 - f1score: 0.6320 - val_loss: 25.7650 - val_acc: 0.5809 - val_auc: 0.8709 - val_precision: 0.5913 - val_recall: 0.5413 - val_f1score: 0.5650\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 25.4004 - acc: 0.6398 - auc: 0.8714 - precision: 0.6566 - recall: 0.6123 - f1score: 0.6335 - val_loss: 25.1483 - val_acc: 0.6112 - val_auc: 0.8719 - val_precision: 0.6259 - val_recall: 0.5960 - val_f1score: 0.6104\n",
      "Epoch 35/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 24.7076 - acc: 0.6473 - auc: 0.8723 - precision: 0.6571 - recall: 0.6143 - f1score: 0.6348 - val_loss: 24.3872 - val_acc: 0.6135 - val_auc: 0.8728 - val_precision: 0.6265 - val_recall: 0.5902 - val_f1score: 0.6077\n",
      "Epoch 36/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 24.0481 - acc: 0.6406 - auc: 0.8732 - precision: 0.6561 - recall: 0.6150 - f1score: 0.6347 - val_loss: 23.7133 - val_acc: 0.6170 - val_auc: 0.8737 - val_precision: 0.6259 - val_recall: 0.5995 - val_f1score: 0.6124\n",
      "Epoch 37/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 23.3974 - acc: 0.6428 - auc: 0.8741 - precision: 0.6553 - recall: 0.6158 - f1score: 0.6347 - val_loss: 23.0879 - val_acc: 0.6345 - val_auc: 0.8745 - val_precision: 0.6398 - val_recall: 0.6170 - val_f1score: 0.6282\n",
      "Epoch 38/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 22.8020 - acc: 0.6407 - auc: 0.8749 - precision: 0.6538 - recall: 0.6149 - f1score: 0.6335 - val_loss: 22.5225 - val_acc: 0.6042 - val_auc: 0.8753 - val_precision: 0.6116 - val_recall: 0.5925 - val_f1score: 0.6019\n",
      "Epoch 39/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 22.2370 - acc: 0.6356 - auc: 0.8756 - precision: 0.6500 - recall: 0.6120 - f1score: 0.6302 - val_loss: 22.0147 - val_acc: 0.6007 - val_auc: 0.8760 - val_precision: 0.6171 - val_recall: 0.5902 - val_f1score: 0.6033\n",
      "Epoch 40/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 21.7242 - acc: 0.6484 - auc: 0.8763 - precision: 0.6591 - recall: 0.6220 - f1score: 0.6397 - val_loss: 21.4688 - val_acc: 0.5995 - val_auc: 0.8767 - val_precision: 0.6094 - val_recall: 0.5879 - val_f1score: 0.5982\n",
      "Epoch 41/300\n",
      "100/100 [==============================] - 55s 545ms/step - loss: 21.2017 - acc: 0.6568 - auc: 0.8771 - precision: 0.6693 - recall: 0.6325 - f1score: 0.6502 - val_loss: 20.9871 - val_acc: 0.6251 - val_auc: 0.8775 - val_precision: 0.6340 - val_recall: 0.6100 - val_f1score: 0.6217\n",
      "Epoch 42/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 20.7214 - acc: 0.6469 - auc: 0.8779 - precision: 0.6644 - recall: 0.6235 - f1score: 0.6430 - val_loss: 20.5140 - val_acc: 0.6205 - val_auc: 0.8782 - val_precision: 0.6310 - val_recall: 0.6042 - val_f1score: 0.6173\n",
      "Epoch 43/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 20.2633 - acc: 0.6512 - auc: 0.8785 - precision: 0.6630 - recall: 0.6255 - f1score: 0.6435 - val_loss: 20.0689 - val_acc: 0.6251 - val_auc: 0.8788 - val_precision: 0.6383 - val_recall: 0.6123 - val_f1score: 0.6250\n",
      "Epoch 44/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 19.7860 - acc: 0.6531 - auc: 0.8792 - precision: 0.6648 - recall: 0.6320 - f1score: 0.6478 - val_loss: 19.5762 - val_acc: 0.6298 - val_auc: 0.8795 - val_precision: 0.6422 - val_recall: 0.6182 - val_f1score: 0.6299\n",
      "Epoch 45/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 19.3486 - acc: 0.6545 - auc: 0.8798 - precision: 0.6655 - recall: 0.6293 - f1score: 0.6467 - val_loss: 19.2305 - val_acc: 0.6030 - val_auc: 0.8802 - val_precision: 0.6151 - val_recall: 0.5856 - val_f1score: 0.5998\n",
      "Epoch 46/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 18.9344 - acc: 0.6569 - auc: 0.8804 - precision: 0.6671 - recall: 0.6354 - f1score: 0.6507 - val_loss: 18.7331 - val_acc: 0.6310 - val_auc: 0.8808 - val_precision: 0.6317 - val_recall: 0.6147 - val_f1score: 0.6230\n",
      "Epoch 47/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 18.5397 - acc: 0.6565 - auc: 0.8811 - precision: 0.6679 - recall: 0.6369 - f1score: 0.6519 - val_loss: 18.4640 - val_acc: 0.6065 - val_auc: 0.8814 - val_precision: 0.6205 - val_recall: 0.5844 - val_f1score: 0.6018\n",
      "Epoch 48/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 18.1839 - acc: 0.6605 - auc: 0.8816 - precision: 0.6701 - recall: 0.6415 - f1score: 0.6554 - val_loss: 18.0462 - val_acc: 0.6123 - val_auc: 0.8819 - val_precision: 0.6270 - val_recall: 0.6019 - val_f1score: 0.6139\n",
      "Epoch 49/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 17.8030 - acc: 0.6588 - auc: 0.8822 - precision: 0.6680 - recall: 0.6343 - f1score: 0.6505 - val_loss: 17.6891 - val_acc: 0.6170 - val_auc: 0.8825 - val_precision: 0.6292 - val_recall: 0.6065 - val_f1score: 0.6176\n",
      "Epoch 50/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 17.4593 - acc: 0.6670 - auc: 0.8828 - precision: 0.6776 - recall: 0.6463 - f1score: 0.6615 - val_loss: 17.4058 - val_acc: 0.6042 - val_auc: 0.8831 - val_precision: 0.6113 - val_recall: 0.5809 - val_f1score: 0.5957\n",
      "Epoch 51/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 17.1370 - acc: 0.6532 - auc: 0.8833 - precision: 0.6626 - recall: 0.6311 - f1score: 0.6463 - val_loss: 17.0407 - val_acc: 0.6205 - val_auc: 0.8836 - val_precision: 0.6285 - val_recall: 0.6112 - val_f1score: 0.6197\n",
      "Epoch 52/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 16.8240 - acc: 0.6566 - auc: 0.8838 - precision: 0.6673 - recall: 0.6373 - f1score: 0.6518 - val_loss: 16.7168 - val_acc: 0.6182 - val_auc: 0.8841 - val_precision: 0.6245 - val_recall: 0.6054 - val_f1score: 0.6147\n",
      "Epoch 53/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 16.5113 - acc: 0.6615 - auc: 0.8843 - precision: 0.6713 - recall: 0.6422 - f1score: 0.6562 - val_loss: 16.4344 - val_acc: 0.5995 - val_auc: 0.8846 - val_precision: 0.6055 - val_recall: 0.5821 - val_f1score: 0.5935\n",
      "Epoch 54/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 16.2159 - acc: 0.6616 - auc: 0.8848 - precision: 0.6710 - recall: 0.6417 - f1score: 0.6559 - val_loss: 16.1403 - val_acc: 0.6275 - val_auc: 0.8850 - val_precision: 0.6278 - val_recall: 0.6170 - val_f1score: 0.6223\n",
      "Epoch 55/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 15.9338 - acc: 0.6657 - auc: 0.8853 - precision: 0.6764 - recall: 0.6468 - f1score: 0.6611 - val_loss: 15.8758 - val_acc: 0.6182 - val_auc: 0.8855 - val_precision: 0.6277 - val_recall: 0.6100 - val_f1score: 0.6186\n",
      "Epoch 56/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 15.6664 - acc: 0.6649 - auc: 0.8858 - precision: 0.6744 - recall: 0.6485 - f1score: 0.6611 - val_loss: 15.6029 - val_acc: 0.5786 - val_auc: 0.8860 - val_precision: 0.5884 - val_recall: 0.5658 - val_f1score: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 15.4111 - acc: 0.6629 - auc: 0.8862 - precision: 0.6713 - recall: 0.6476 - f1score: 0.6591 - val_loss: 15.3285 - val_acc: 0.6310 - val_auc: 0.8865 - val_precision: 0.6371 - val_recall: 0.6228 - val_f1score: 0.6298\n",
      "Epoch 58/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 15.1642 - acc: 0.6649 - auc: 0.8867 - precision: 0.6766 - recall: 0.6461 - f1score: 0.6608 - val_loss: 15.1161 - val_acc: 0.6065 - val_auc: 0.8869 - val_precision: 0.6107 - val_recall: 0.5902 - val_f1score: 0.6002\n",
      "Epoch 59/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 14.9251 - acc: 0.6647 - auc: 0.8871 - precision: 0.6732 - recall: 0.6502 - f1score: 0.6613 - val_loss: 14.8403 - val_acc: 0.6147 - val_auc: 0.8874 - val_precision: 0.6192 - val_recall: 0.6042 - val_f1score: 0.6116\n",
      "Epoch 60/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 14.6841 - acc: 0.6714 - auc: 0.8876 - precision: 0.6796 - recall: 0.6536 - f1score: 0.6662 - val_loss: 14.7434 - val_acc: 0.5984 - val_auc: 0.8878 - val_precision: 0.6030 - val_recall: 0.5809 - val_f1score: 0.5917\n",
      "Epoch 61/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 14.4558 - acc: 0.6644 - auc: 0.8880 - precision: 0.6725 - recall: 0.6509 - f1score: 0.6614 - val_loss: 14.4158 - val_acc: 0.6100 - val_auc: 0.8882 - val_precision: 0.6249 - val_recall: 0.5984 - val_f1score: 0.6112\n",
      "Epoch 62/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 14.2349 - acc: 0.6717 - auc: 0.8884 - precision: 0.6792 - recall: 0.6547 - f1score: 0.6666 - val_loss: 14.1752 - val_acc: 0.6065 - val_auc: 0.8886 - val_precision: 0.6135 - val_recall: 0.5937 - val_f1score: 0.6034\n",
      "Epoch 63/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 14.0214 - acc: 0.6666 - auc: 0.8888 - precision: 0.6759 - recall: 0.6504 - f1score: 0.6627 - val_loss: 13.9914 - val_acc: 0.6112 - val_auc: 0.8890 - val_precision: 0.6171 - val_recall: 0.5995 - val_f1score: 0.6081\n",
      "Epoch 64/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 13.8054 - acc: 0.6689 - auc: 0.8892 - precision: 0.6760 - recall: 0.6520 - f1score: 0.6637 - val_loss: 13.7894 - val_acc: 0.6228 - val_auc: 0.8894 - val_precision: 0.6269 - val_recall: 0.6112 - val_f1score: 0.6187\n",
      "Epoch 65/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 13.6178 - acc: 0.6666 - auc: 0.8896 - precision: 0.6755 - recall: 0.6499 - f1score: 0.6623 - val_loss: 13.6203 - val_acc: 0.6100 - val_auc: 0.8897 - val_precision: 0.6168 - val_recall: 0.5984 - val_f1score: 0.6074\n",
      "Epoch 66/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 13.4152 - acc: 0.6795 - auc: 0.8899 - precision: 0.6878 - recall: 0.6624 - f1score: 0.6747 - val_loss: 13.4699 - val_acc: 0.6007 - val_auc: 0.8901 - val_precision: 0.6097 - val_recall: 0.5925 - val_f1score: 0.6009\n",
      "Epoch 67/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 13.2321 - acc: 0.6804 - auc: 0.8903 - precision: 0.6885 - recall: 0.6668 - f1score: 0.6774 - val_loss: 13.3206 - val_acc: 0.6065 - val_auc: 0.8905 - val_precision: 0.6140 - val_recall: 0.5914 - val_f1score: 0.6023\n",
      "Epoch 68/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 13.0690 - acc: 0.6684 - auc: 0.8907 - precision: 0.6755 - recall: 0.6522 - f1score: 0.6635 - val_loss: 13.2401 - val_acc: 0.5914 - val_auc: 0.8908 - val_precision: 0.5976 - val_recall: 0.5821 - val_f1score: 0.5896\n",
      "Epoch 69/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 12.8941 - acc: 0.6801 - auc: 0.8910 - precision: 0.6864 - recall: 0.6630 - f1score: 0.6743 - val_loss: 12.9693 - val_acc: 0.6077 - val_auc: 0.8912 - val_precision: 0.6177 - val_recall: 0.5949 - val_f1score: 0.6059\n",
      "Epoch 70/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 12.7214 - acc: 0.6797 - auc: 0.8914 - precision: 0.6873 - recall: 0.6648 - f1score: 0.6758 - val_loss: 12.9191 - val_acc: 0.5867 - val_auc: 0.8915 - val_precision: 0.6065 - val_recall: 0.5704 - val_f1score: 0.5878\n",
      "Epoch 71/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 12.5584 - acc: 0.6678 - auc: 0.8917 - precision: 0.6745 - recall: 0.6539 - f1score: 0.6639 - val_loss: 12.5465 - val_acc: 0.6228 - val_auc: 0.8918 - val_precision: 0.6256 - val_recall: 0.6100 - val_f1score: 0.6177\n",
      "Epoch 72/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 12.3812 - acc: 0.6853 - auc: 0.8920 - precision: 0.6921 - recall: 0.6700 - f1score: 0.6807 - val_loss: 12.4509 - val_acc: 0.6170 - val_auc: 0.8922 - val_precision: 0.6216 - val_recall: 0.6123 - val_f1score: 0.6168\n",
      "Epoch 73/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 12.2224 - acc: 0.6798 - auc: 0.8924 - precision: 0.6888 - recall: 0.6661 - f1score: 0.6771 - val_loss: 12.3081 - val_acc: 0.6100 - val_auc: 0.8925 - val_precision: 0.6170 - val_recall: 0.5972 - val_f1score: 0.6068\n",
      "Epoch 74/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 12.0676 - acc: 0.6847 - auc: 0.8927 - precision: 0.6911 - recall: 0.6712 - f1score: 0.6809 - val_loss: 12.0375 - val_acc: 0.6088 - val_auc: 0.8929 - val_precision: 0.6153 - val_recall: 0.6019 - val_f1score: 0.6085\n",
      "Epoch 75/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 11.9248 - acc: 0.6822 - auc: 0.8930 - precision: 0.6895 - recall: 0.6680 - f1score: 0.6785 - val_loss: 12.1236 - val_acc: 0.5856 - val_auc: 0.8932 - val_precision: 0.5981 - val_recall: 0.5797 - val_f1score: 0.5887\n",
      "Epoch 76/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 11.7836 - acc: 0.6823 - auc: 0.8933 - precision: 0.6912 - recall: 0.6684 - f1score: 0.6795 - val_loss: 11.8428 - val_acc: 0.6088 - val_auc: 0.8935 - val_precision: 0.6130 - val_recall: 0.6007 - val_f1score: 0.6067\n",
      "Epoch 77/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 11.6474 - acc: 0.6750 - auc: 0.8936 - precision: 0.6828 - recall: 0.6626 - f1score: 0.6725 - val_loss: 11.6895 - val_acc: 0.6065 - val_auc: 0.8938 - val_precision: 0.6093 - val_recall: 0.5972 - val_f1score: 0.6032\n",
      "Epoch 78/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 11.5099 - acc: 0.6820 - auc: 0.8939 - precision: 0.6882 - recall: 0.6693 - f1score: 0.6785 - val_loss: 11.6072 - val_acc: 0.5879 - val_auc: 0.8941 - val_precision: 0.6035 - val_recall: 0.5774 - val_f1score: 0.5901\n",
      "Epoch 79/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 11.3762 - acc: 0.6833 - auc: 0.8942 - precision: 0.6896 - recall: 0.6707 - f1score: 0.6799 - val_loss: 11.3735 - val_acc: 0.6030 - val_auc: 0.8944 - val_precision: 0.6044 - val_recall: 0.5937 - val_f1score: 0.5989\n",
      "Epoch 80/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 11.2570 - acc: 0.6825 - auc: 0.8945 - precision: 0.6896 - recall: 0.6717 - f1score: 0.6804 - val_loss: 11.4090 - val_acc: 0.5856 - val_auc: 0.8947 - val_precision: 0.5954 - val_recall: 0.5681 - val_f1score: 0.5811\n",
      "Epoch 81/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 11.1231 - acc: 0.6833 - auc: 0.8948 - precision: 0.6893 - recall: 0.6704 - f1score: 0.6796 - val_loss: 11.1376 - val_acc: 0.6321 - val_auc: 0.8950 - val_precision: 0.6364 - val_recall: 0.6217 - val_f1score: 0.6289\n",
      "Epoch 82/300\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 10.9964 - acc: 0.6892 - auc: 0.8951 - precision: 0.6954 - recall: 0.6755 - f1score: 0.6852 - val_loss: 11.0881 - val_acc: 0.6054 - val_auc: 0.8953 - val_precision: 0.6079 - val_recall: 0.5949 - val_f1score: 0.6013\n",
      "Epoch 83/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 10.8741 - acc: 0.6896 - auc: 0.8954 - precision: 0.6946 - recall: 0.6761 - f1score: 0.6852 - val_loss: 10.9178 - val_acc: 0.5984 - val_auc: 0.8956 - val_precision: 0.6019 - val_recall: 0.5949 - val_f1score: 0.5983\n",
      "Epoch 84/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 10.7559 - acc: 0.6865 - auc: 0.8957 - precision: 0.6920 - recall: 0.6735 - f1score: 0.6826 - val_loss: 10.7844 - val_acc: 0.6217 - val_auc: 0.8959 - val_precision: 0.6258 - val_recall: 0.6135 - val_f1score: 0.6196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 10.6583 - acc: 0.6850 - auc: 0.8960 - precision: 0.6925 - recall: 0.6717 - f1score: 0.6817 - val_loss: 10.7708 - val_acc: 0.6077 - val_auc: 0.8961 - val_precision: 0.6182 - val_recall: 0.5949 - val_f1score: 0.6062\n",
      "Epoch 86/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 10.5463 - acc: 0.6962 - auc: 0.8963 - precision: 0.7031 - recall: 0.6860 - f1score: 0.6944 - val_loss: 10.6433 - val_acc: 0.6228 - val_auc: 0.8964 - val_precision: 0.6274 - val_recall: 0.6077 - val_f1score: 0.6173\n",
      "Epoch 87/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 10.4341 - acc: 0.7000 - auc: 0.8966 - precision: 0.7070 - recall: 0.6896 - f1score: 0.6981 - val_loss: 10.5596 - val_acc: 0.6042 - val_auc: 0.8967 - val_precision: 0.6118 - val_recall: 0.5937 - val_f1score: 0.6025\n",
      "Epoch 88/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 10.3267 - acc: 0.6926 - auc: 0.8969 - precision: 0.7001 - recall: 0.6817 - f1score: 0.6907 - val_loss: 10.3702 - val_acc: 0.5960 - val_auc: 0.8970 - val_precision: 0.5944 - val_recall: 0.5856 - val_f1score: 0.5898\n",
      "Epoch 89/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 10.2159 - acc: 0.6945 - auc: 0.8971 - precision: 0.7005 - recall: 0.6855 - f1score: 0.6929 - val_loss: 10.2446 - val_acc: 0.6368 - val_auc: 0.8973 - val_precision: 0.6411 - val_recall: 0.6298 - val_f1score: 0.6354\n",
      "Epoch 90/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 10.1229 - acc: 0.6887 - auc: 0.8974 - precision: 0.6944 - recall: 0.6770 - f1score: 0.6855 - val_loss: 10.1694 - val_acc: 0.6054 - val_auc: 0.8976 - val_precision: 0.6117 - val_recall: 0.5937 - val_f1score: 0.6025\n",
      "Epoch 91/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 10.0228 - acc: 0.6873 - auc: 0.8977 - precision: 0.6938 - recall: 0.6772 - f1score: 0.6853 - val_loss: 10.0941 - val_acc: 0.6100 - val_auc: 0.8978 - val_precision: 0.6155 - val_recall: 0.6019 - val_f1score: 0.6085\n",
      "Epoch 92/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 9.9313 - acc: 0.6877 - auc: 0.8980 - precision: 0.6961 - recall: 0.6805 - f1score: 0.6882 - val_loss: 10.1420 - val_acc: 0.6030 - val_auc: 0.8981 - val_precision: 0.6099 - val_recall: 0.5891 - val_f1score: 0.5992\n",
      "Epoch 93/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 9.8408 - acc: 0.6989 - auc: 0.8982 - precision: 0.7051 - recall: 0.6875 - f1score: 0.6961 - val_loss: 9.8641 - val_acc: 0.6158 - val_auc: 0.8983 - val_precision: 0.6216 - val_recall: 0.6100 - val_f1score: 0.6157\n",
      "Epoch 94/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 9.7513 - acc: 0.7017 - auc: 0.8985 - precision: 0.7078 - recall: 0.6892 - f1score: 0.6983 - val_loss: 9.8318 - val_acc: 0.6135 - val_auc: 0.8986 - val_precision: 0.6181 - val_recall: 0.6042 - val_f1score: 0.6110\n",
      "Epoch 95/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 9.6630 - acc: 0.6960 - auc: 0.8988 - precision: 0.7028 - recall: 0.6869 - f1score: 0.6947 - val_loss: 9.7775 - val_acc: 0.6112 - val_auc: 0.8989 - val_precision: 0.6161 - val_recall: 0.6007 - val_f1score: 0.6083\n",
      "Epoch 96/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 9.5867 - acc: 0.6931 - auc: 0.8990 - precision: 0.6974 - recall: 0.6807 - f1score: 0.6889 - val_loss: 9.7068 - val_acc: 0.5891 - val_auc: 0.8991 - val_precision: 0.5959 - val_recall: 0.5832 - val_f1score: 0.5893\n",
      "Epoch 97/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 9.5009 - acc: 0.6950 - auc: 0.8993 - precision: 0.7032 - recall: 0.6848 - f1score: 0.6937 - val_loss: 9.6642 - val_acc: 0.5832 - val_auc: 0.8994 - val_precision: 0.5878 - val_recall: 0.5751 - val_f1score: 0.5813\n",
      "Epoch 98/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 9.4265 - acc: 0.6943 - auc: 0.8995 - precision: 0.7010 - recall: 0.6816 - f1score: 0.6911 - val_loss: 9.5141 - val_acc: 0.6193 - val_auc: 0.8996 - val_precision: 0.6229 - val_recall: 0.6123 - val_f1score: 0.6175\n",
      "Epoch 99/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 9.3462 - acc: 0.7020 - auc: 0.8997 - precision: 0.7116 - recall: 0.6925 - f1score: 0.7019 - val_loss: 9.5250 - val_acc: 0.5960 - val_auc: 0.8999 - val_precision: 0.6089 - val_recall: 0.5879 - val_f1score: 0.5981\n",
      "Epoch 100/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 9.2595 - acc: 0.7037 - auc: 0.9000 - precision: 0.7096 - recall: 0.6946 - f1score: 0.7019 - val_loss: 9.3572 - val_acc: 0.6356 - val_auc: 0.9001 - val_precision: 0.6426 - val_recall: 0.6217 - val_f1score: 0.6319\n",
      "Epoch 101/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 9.1855 - acc: 0.6976 - auc: 0.9002 - precision: 0.7042 - recall: 0.6871 - f1score: 0.6955 - val_loss: 9.3047 - val_acc: 0.6135 - val_auc: 0.9003 - val_precision: 0.6228 - val_recall: 0.6042 - val_f1score: 0.6132\n",
      "Epoch 102/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 9.1071 - acc: 0.6991 - auc: 0.9005 - precision: 0.7058 - recall: 0.6902 - f1score: 0.6979 - val_loss: 9.3194 - val_acc: 0.5937 - val_auc: 0.9006 - val_precision: 0.5998 - val_recall: 0.5821 - val_f1score: 0.5907\n",
      "Epoch 103/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 9.0202 - acc: 0.7010 - auc: 0.9007 - precision: 0.7076 - recall: 0.6935 - f1score: 0.7004 - val_loss: 9.1102 - val_acc: 0.6368 - val_auc: 0.9008 - val_precision: 0.6390 - val_recall: 0.6251 - val_f1score: 0.6319\n",
      "Epoch 104/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 8.9513 - acc: 0.7008 - auc: 0.9009 - precision: 0.7082 - recall: 0.6942 - f1score: 0.7011 - val_loss: 9.1502 - val_acc: 0.5832 - val_auc: 0.9010 - val_precision: 0.5886 - val_recall: 0.5751 - val_f1score: 0.5816\n",
      "Epoch 105/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 8.8786 - acc: 0.7057 - auc: 0.9012 - precision: 0.7108 - recall: 0.6960 - f1score: 0.7032 - val_loss: 9.0260 - val_acc: 0.6054 - val_auc: 0.9013 - val_precision: 0.6136 - val_recall: 0.6007 - val_f1score: 0.6071\n",
      "Epoch 106/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 8.8133 - acc: 0.7065 - auc: 0.9014 - precision: 0.7127 - recall: 0.6990 - f1score: 0.7057 - val_loss: 8.9258 - val_acc: 0.6170 - val_auc: 0.9015 - val_precision: 0.6213 - val_recall: 0.6088 - val_f1score: 0.6150\n",
      "Epoch 107/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 8.7496 - acc: 0.7022 - auc: 0.9016 - precision: 0.7065 - recall: 0.6914 - f1score: 0.6988 - val_loss: 8.8576 - val_acc: 0.5867 - val_auc: 0.9017 - val_precision: 0.5917 - val_recall: 0.5809 - val_f1score: 0.5862\n",
      "Epoch 108/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 8.6712 - acc: 0.7157 - auc: 0.9019 - precision: 0.7209 - recall: 0.7060 - f1score: 0.7133 - val_loss: 8.8231 - val_acc: 0.6065 - val_auc: 0.9020 - val_precision: 0.6147 - val_recall: 0.6019 - val_f1score: 0.6082\n",
      "Epoch 109/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 8.6241 - acc: 0.7084 - auc: 0.9021 - precision: 0.7138 - recall: 0.7008 - f1score: 0.7072 - val_loss: 8.7475 - val_acc: 0.5786 - val_auc: 0.9022 - val_precision: 0.5885 - val_recall: 0.5716 - val_f1score: 0.5799\n",
      "Epoch 110/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 8.5540 - acc: 0.7065 - auc: 0.9024 - precision: 0.7125 - recall: 0.6962 - f1score: 0.7042 - val_loss: 8.6593 - val_acc: 0.6182 - val_auc: 0.9025 - val_precision: 0.6214 - val_recall: 0.6135 - val_f1score: 0.6174\n",
      "Epoch 111/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 8.4880 - acc: 0.7129 - auc: 0.9026 - precision: 0.7179 - recall: 0.7053 - f1score: 0.7115 - val_loss: 8.7148 - val_acc: 0.6100 - val_auc: 0.9027 - val_precision: 0.6168 - val_recall: 0.6065 - val_f1score: 0.6116\n",
      "Epoch 112/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 8.4269 - acc: 0.7068 - auc: 0.9028 - precision: 0.7100 - recall: 0.6983 - f1score: 0.7041 - val_loss: 8.5508 - val_acc: 0.6205 - val_auc: 0.9029 - val_precision: 0.6259 - val_recall: 0.6123 - val_f1score: 0.6189\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 549ms/step - loss: 8.3639 - acc: 0.7099 - auc: 0.9030 - precision: 0.7159 - recall: 0.7027 - f1score: 0.7092 - val_loss: 8.4791 - val_acc: 0.6112 - val_auc: 0.9031 - val_precision: 0.6173 - val_recall: 0.6088 - val_f1score: 0.6130\n",
      "Epoch 114/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 8.3124 - acc: 0.7174 - auc: 0.9032 - precision: 0.7225 - recall: 0.7097 - f1score: 0.7160 - val_loss: 8.4152 - val_acc: 0.5960 - val_auc: 0.9034 - val_precision: 0.6002 - val_recall: 0.5937 - val_f1score: 0.5969\n",
      "Epoch 115/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 8.2536 - acc: 0.7126 - auc: 0.9035 - precision: 0.7168 - recall: 0.7027 - f1score: 0.7096 - val_loss: 8.5198 - val_acc: 0.5960 - val_auc: 0.9036 - val_precision: 0.6017 - val_recall: 0.5902 - val_f1score: 0.5959\n",
      "Epoch 116/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 8.1959 - acc: 0.7220 - auc: 0.9037 - precision: 0.7284 - recall: 0.7141 - f1score: 0.7211 - val_loss: 8.3995 - val_acc: 0.6193 - val_auc: 0.9038 - val_precision: 0.6244 - val_recall: 0.6077 - val_f1score: 0.6159\n",
      "Epoch 117/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 8.1434 - acc: 0.7105 - auc: 0.9039 - precision: 0.7159 - recall: 0.7027 - f1score: 0.7092 - val_loss: 8.3101 - val_acc: 0.6275 - val_auc: 0.9040 - val_precision: 0.6294 - val_recall: 0.6182 - val_f1score: 0.6237\n",
      "Epoch 118/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 8.0875 - acc: 0.7130 - auc: 0.9041 - precision: 0.7192 - recall: 0.7072 - f1score: 0.7131 - val_loss: 8.3060 - val_acc: 0.5972 - val_auc: 0.9042 - val_precision: 0.6015 - val_recall: 0.5914 - val_f1score: 0.5963\n",
      "Epoch 119/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 8.0327 - acc: 0.7182 - auc: 0.9044 - precision: 0.7226 - recall: 0.7099 - f1score: 0.7161 - val_loss: 8.1623 - val_acc: 0.6100 - val_auc: 0.9045 - val_precision: 0.6134 - val_recall: 0.6054 - val_f1score: 0.6093\n",
      "Epoch 120/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 7.9777 - acc: 0.7194 - auc: 0.9046 - precision: 0.7233 - recall: 0.7119 - f1score: 0.7175 - val_loss: 8.4289 - val_acc: 0.5716 - val_auc: 0.9047 - val_precision: 0.5725 - val_recall: 0.5646 - val_f1score: 0.5684\n",
      "Epoch 121/300\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 7.9252 - acc: 0.7171 - auc: 0.9048 - precision: 0.7227 - recall: 0.7089 - f1score: 0.7157 - val_loss: 8.0736 - val_acc: 0.6251 - val_auc: 0.9049 - val_precision: 0.6281 - val_recall: 0.6135 - val_f1score: 0.6207\n",
      "Epoch 122/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 7.8705 - acc: 0.7234 - auc: 0.9050 - precision: 0.7264 - recall: 0.7141 - f1score: 0.7201 - val_loss: 8.0715 - val_acc: 0.6170 - val_auc: 0.9051 - val_precision: 0.6234 - val_recall: 0.6147 - val_f1score: 0.6190\n",
      "Epoch 123/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 7.8246 - acc: 0.7285 - auc: 0.9052 - precision: 0.7327 - recall: 0.7186 - f1score: 0.7255 - val_loss: 7.9709 - val_acc: 0.6135 - val_auc: 0.9053 - val_precision: 0.6159 - val_recall: 0.6054 - val_f1score: 0.6105\n",
      "Epoch 124/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 7.7695 - acc: 0.7208 - auc: 0.9054 - precision: 0.7240 - recall: 0.7152 - f1score: 0.7195 - val_loss: 7.9994 - val_acc: 0.6182 - val_auc: 0.9056 - val_precision: 0.6204 - val_recall: 0.6077 - val_f1score: 0.6139\n",
      "Epoch 125/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 7.7259 - acc: 0.7166 - auc: 0.9057 - precision: 0.7217 - recall: 0.7101 - f1score: 0.7158 - val_loss: 8.0065 - val_acc: 0.6019 - val_auc: 0.9058 - val_precision: 0.6120 - val_recall: 0.5937 - val_f1score: 0.6027\n",
      "Epoch 126/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 7.6786 - acc: 0.7173 - auc: 0.9059 - precision: 0.7234 - recall: 0.7093 - f1score: 0.7162 - val_loss: 7.8421 - val_acc: 0.5867 - val_auc: 0.9060 - val_precision: 0.5910 - val_recall: 0.5821 - val_f1score: 0.5865\n",
      "Epoch 127/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 7.6294 - acc: 0.7245 - auc: 0.9061 - precision: 0.7286 - recall: 0.7181 - f1score: 0.7232 - val_loss: 7.7968 - val_acc: 0.6112 - val_auc: 0.9062 - val_precision: 0.6160 - val_recall: 0.6065 - val_f1score: 0.6112\n",
      "Epoch 128/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 7.5756 - acc: 0.7260 - auc: 0.9063 - precision: 0.7295 - recall: 0.7187 - f1score: 0.7240 - val_loss: 7.8804 - val_acc: 0.6077 - val_auc: 0.9064 - val_precision: 0.6172 - val_recall: 0.5984 - val_f1score: 0.6073\n",
      "Epoch 129/300\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 7.5326 - acc: 0.7196 - auc: 0.9065 - precision: 0.7236 - recall: 0.7117 - f1score: 0.7176 - val_loss: 7.7702 - val_acc: 0.6112 - val_auc: 0.9066 - val_precision: 0.6189 - val_recall: 0.6042 - val_f1score: 0.6114\n",
      "Epoch 130/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 7.4905 - acc: 0.7235 - auc: 0.9067 - precision: 0.7283 - recall: 0.7171 - f1score: 0.7226 - val_loss: 7.7101 - val_acc: 0.6135 - val_auc: 0.9068 - val_precision: 0.6141 - val_recall: 0.6054 - val_f1score: 0.6096\n",
      "Epoch 131/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 7.4384 - acc: 0.7309 - auc: 0.9069 - precision: 0.7353 - recall: 0.7227 - f1score: 0.7289 - val_loss: 7.5942 - val_acc: 0.6333 - val_auc: 0.9070 - val_precision: 0.6362 - val_recall: 0.6263 - val_f1score: 0.6312\n",
      "Epoch 132/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 7.4028 - acc: 0.7275 - auc: 0.9071 - precision: 0.7328 - recall: 0.7202 - f1score: 0.7264 - val_loss: 7.6162 - val_acc: 0.6112 - val_auc: 0.9072 - val_precision: 0.6167 - val_recall: 0.6088 - val_f1score: 0.6127\n",
      "Epoch 133/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 7.3534 - acc: 0.7281 - auc: 0.9073 - precision: 0.7321 - recall: 0.7206 - f1score: 0.7262 - val_loss: 7.5223 - val_acc: 0.6100 - val_auc: 0.9074 - val_precision: 0.6114 - val_recall: 0.6030 - val_f1score: 0.6072\n",
      "Epoch 134/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 7.3143 - acc: 0.7231 - auc: 0.9075 - precision: 0.7275 - recall: 0.7155 - f1score: 0.7214 - val_loss: 7.5266 - val_acc: 0.6193 - val_auc: 0.9076 - val_precision: 0.6245 - val_recall: 0.6135 - val_f1score: 0.6189\n",
      "Epoch 135/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 7.2752 - acc: 0.7230 - auc: 0.9077 - precision: 0.7278 - recall: 0.7162 - f1score: 0.7219 - val_loss: 7.4454 - val_acc: 0.6158 - val_auc: 0.9078 - val_precision: 0.6160 - val_recall: 0.6100 - val_f1score: 0.6130\n",
      "Epoch 136/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 7.2325 - acc: 0.7302 - auc: 0.9079 - precision: 0.7336 - recall: 0.7234 - f1score: 0.7284 - val_loss: 7.5350 - val_acc: 0.5774 - val_auc: 0.9080 - val_precision: 0.5847 - val_recall: 0.5728 - val_f1score: 0.5785\n",
      "Epoch 137/300\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 7.1913 - acc: 0.7262 - auc: 0.9081 - precision: 0.7293 - recall: 0.7186 - f1score: 0.7239 - val_loss: 7.4718 - val_acc: 0.6112 - val_auc: 0.9082 - val_precision: 0.6121 - val_recall: 0.6065 - val_f1score: 0.6093\n",
      "Epoch 138/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 7.1446 - acc: 0.7365 - auc: 0.9083 - precision: 0.7414 - recall: 0.7307 - f1score: 0.7359 - val_loss: 7.3615 - val_acc: 0.6054 - val_auc: 0.9084 - val_precision: 0.6118 - val_recall: 0.6030 - val_f1score: 0.6073\n",
      "Epoch 139/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 7.1161 - acc: 0.7286 - auc: 0.9085 - precision: 0.7327 - recall: 0.7202 - f1score: 0.7263 - val_loss: 7.2830 - val_acc: 0.6286 - val_auc: 0.9086 - val_precision: 0.6335 - val_recall: 0.6240 - val_f1score: 0.6287\n",
      "Epoch 140/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 7.0737 - acc: 0.7253 - auc: 0.9087 - precision: 0.7285 - recall: 0.7188 - f1score: 0.7236 - val_loss: 7.4483 - val_acc: 0.6135 - val_auc: 0.9088 - val_precision: 0.6133 - val_recall: 0.6054 - val_f1score: 0.6093\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 551ms/step - loss: 7.0308 - acc: 0.7335 - auc: 0.9089 - precision: 0.7370 - recall: 0.7269 - f1score: 0.7319 - val_loss: 7.2562 - val_acc: 0.6100 - val_auc: 0.9090 - val_precision: 0.6149 - val_recall: 0.6019 - val_f1score: 0.6083\n",
      "Epoch 142/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.9888 - acc: 0.7373 - auc: 0.9091 - precision: 0.7416 - recall: 0.7303 - f1score: 0.7359 - val_loss: 7.2245 - val_acc: 0.6158 - val_auc: 0.9092 - val_precision: 0.6210 - val_recall: 0.6123 - val_f1score: 0.6166\n",
      "Epoch 143/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.9595 - acc: 0.7304 - auc: 0.9093 - precision: 0.7358 - recall: 0.7245 - f1score: 0.7301 - val_loss: 7.1817 - val_acc: 0.5960 - val_auc: 0.9094 - val_precision: 0.6045 - val_recall: 0.5879 - val_f1score: 0.5960\n",
      "Epoch 144/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 6.9223 - acc: 0.7299 - auc: 0.9095 - precision: 0.7349 - recall: 0.7235 - f1score: 0.7291 - val_loss: 7.1679 - val_acc: 0.5925 - val_auc: 0.9096 - val_precision: 0.5973 - val_recall: 0.5891 - val_f1score: 0.5930\n",
      "Epoch 145/300\n",
      "100/100 [==============================] - 54s 542ms/step - loss: 6.8787 - acc: 0.7421 - auc: 0.9097 - precision: 0.7453 - recall: 0.7375 - f1score: 0.7414 - val_loss: 7.2840 - val_acc: 0.5623 - val_auc: 0.9098 - val_precision: 0.5710 - val_recall: 0.5553 - val_f1score: 0.5629\n",
      "Epoch 146/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 6.8422 - acc: 0.7377 - auc: 0.9099 - precision: 0.7410 - recall: 0.7301 - f1score: 0.7355 - val_loss: 7.1259 - val_acc: 0.6135 - val_auc: 0.9099 - val_precision: 0.6212 - val_recall: 0.6123 - val_f1score: 0.6167\n",
      "Epoch 147/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 6.8003 - acc: 0.7474 - auc: 0.9100 - precision: 0.7511 - recall: 0.7423 - f1score: 0.7466 - val_loss: 7.0996 - val_acc: 0.6077 - val_auc: 0.9101 - val_precision: 0.6116 - val_recall: 0.6054 - val_f1score: 0.6084\n",
      "Epoch 148/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 6.7806 - acc: 0.7353 - auc: 0.9102 - precision: 0.7387 - recall: 0.7313 - f1score: 0.7350 - val_loss: 6.9735 - val_acc: 0.6391 - val_auc: 0.9103 - val_precision: 0.6406 - val_recall: 0.6356 - val_f1score: 0.6381\n",
      "Epoch 149/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 6.7383 - acc: 0.7465 - auc: 0.9104 - precision: 0.7517 - recall: 0.7416 - f1score: 0.7466 - val_loss: 7.0049 - val_acc: 0.6019 - val_auc: 0.9105 - val_precision: 0.6084 - val_recall: 0.5960 - val_f1score: 0.6021\n",
      "Epoch 150/300\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 6.7099 - acc: 0.7467 - auc: 0.9106 - precision: 0.7511 - recall: 0.7411 - f1score: 0.7460 - val_loss: 6.9596 - val_acc: 0.6182 - val_auc: 0.9107 - val_precision: 0.6174 - val_recall: 0.6030 - val_f1score: 0.6100\n",
      "Epoch 151/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 6.6777 - acc: 0.7403 - auc: 0.9108 - precision: 0.7449 - recall: 0.7360 - f1score: 0.7404 - val_loss: 6.8683 - val_acc: 0.6228 - val_auc: 0.9109 - val_precision: 0.6249 - val_recall: 0.6205 - val_f1score: 0.6227\n",
      "Epoch 152/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 6.6553 - acc: 0.7398 - auc: 0.9110 - precision: 0.7438 - recall: 0.7338 - f1score: 0.7387 - val_loss: 6.9407 - val_acc: 0.6030 - val_auc: 0.9111 - val_precision: 0.6078 - val_recall: 0.5995 - val_f1score: 0.6035\n",
      "Epoch 153/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 6.6075 - acc: 0.7514 - auc: 0.9112 - precision: 0.7533 - recall: 0.7443 - f1score: 0.7487 - val_loss: 6.8793 - val_acc: 0.5879 - val_auc: 0.9113 - val_precision: 0.5913 - val_recall: 0.5844 - val_f1score: 0.5878\n",
      "Epoch 154/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 6.5767 - acc: 0.7470 - auc: 0.9114 - precision: 0.7514 - recall: 0.7407 - f1score: 0.7460 - val_loss: 6.7967 - val_acc: 0.6310 - val_auc: 0.9115 - val_precision: 0.6332 - val_recall: 0.6251 - val_f1score: 0.6291\n",
      "Epoch 155/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 6.5560 - acc: 0.7388 - auc: 0.9116 - precision: 0.7414 - recall: 0.7332 - f1score: 0.7373 - val_loss: 6.8551 - val_acc: 0.6158 - val_auc: 0.9117 - val_precision: 0.6216 - val_recall: 0.6123 - val_f1score: 0.6169\n",
      "Epoch 156/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 6.5135 - acc: 0.7475 - auc: 0.9118 - precision: 0.7519 - recall: 0.7430 - f1score: 0.7474 - val_loss: 6.7879 - val_acc: 0.6112 - val_auc: 0.9119 - val_precision: 0.6144 - val_recall: 0.6100 - val_f1score: 0.6122\n",
      "Epoch 157/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 6.4902 - acc: 0.7473 - auc: 0.9120 - precision: 0.7518 - recall: 0.7421 - f1score: 0.7469 - val_loss: 6.6938 - val_acc: 0.6065 - val_auc: 0.9121 - val_precision: 0.6084 - val_recall: 0.6042 - val_f1score: 0.6063\n",
      "Epoch 158/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 6.4584 - acc: 0.7520 - auc: 0.9122 - precision: 0.7552 - recall: 0.7479 - f1score: 0.7515 - val_loss: 6.8322 - val_acc: 0.6065 - val_auc: 0.9123 - val_precision: 0.6063 - val_recall: 0.5984 - val_f1score: 0.6023\n",
      "Epoch 159/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 6.4239 - acc: 0.7522 - auc: 0.9124 - precision: 0.7553 - recall: 0.7483 - f1score: 0.7518 - val_loss: 6.7421 - val_acc: 0.6030 - val_auc: 0.9125 - val_precision: 0.6078 - val_recall: 0.6007 - val_f1score: 0.6042\n",
      "Epoch 160/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 6.3982 - acc: 0.7400 - auc: 0.9126 - precision: 0.7445 - recall: 0.7348 - f1score: 0.7396 - val_loss: 7.0112 - val_acc: 0.5891 - val_auc: 0.9126 - val_precision: 0.5947 - val_recall: 0.5879 - val_f1score: 0.5912\n",
      "Epoch 161/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 6.3702 - acc: 0.7522 - auc: 0.9127 - precision: 0.7544 - recall: 0.7487 - f1score: 0.7515 - val_loss: 6.8198 - val_acc: 0.6088 - val_auc: 0.9128 - val_precision: 0.6099 - val_recall: 0.6019 - val_f1score: 0.6058\n",
      "Epoch 162/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.3381 - acc: 0.7511 - auc: 0.9129 - precision: 0.7544 - recall: 0.7465 - f1score: 0.7504 - val_loss: 6.7158 - val_acc: 0.5937 - val_auc: 0.9130 - val_precision: 0.6017 - val_recall: 0.5867 - val_f1score: 0.5941\n",
      "Epoch 163/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 6.3003 - acc: 0.7614 - auc: 0.9131 - precision: 0.7648 - recall: 0.7563 - f1score: 0.7605 - val_loss: 6.6376 - val_acc: 0.6007 - val_auc: 0.9132 - val_precision: 0.6030 - val_recall: 0.5925 - val_f1score: 0.5977\n",
      "Epoch 164/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 6.2827 - acc: 0.7540 - auc: 0.9133 - precision: 0.7569 - recall: 0.7497 - f1score: 0.7533 - val_loss: 6.5369 - val_acc: 0.6123 - val_auc: 0.9133 - val_precision: 0.6155 - val_recall: 0.6112 - val_f1score: 0.6133\n",
      "Epoch 165/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 6.2486 - acc: 0.7486 - auc: 0.9134 - precision: 0.7527 - recall: 0.7441 - f1score: 0.7483 - val_loss: 6.5201 - val_acc: 0.6193 - val_auc: 0.9135 - val_precision: 0.6233 - val_recall: 0.6158 - val_f1score: 0.6195\n",
      "Epoch 166/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 6.2288 - acc: 0.7537 - auc: 0.9136 - precision: 0.7557 - recall: 0.7475 - f1score: 0.7515 - val_loss: 6.4834 - val_acc: 0.6100 - val_auc: 0.9137 - val_precision: 0.6118 - val_recall: 0.6065 - val_f1score: 0.6091\n",
      "Epoch 167/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 6.2023 - acc: 0.7569 - auc: 0.9138 - precision: 0.7617 - recall: 0.7526 - f1score: 0.7571 - val_loss: 6.5812 - val_acc: 0.5995 - val_auc: 0.9139 - val_precision: 0.6033 - val_recall: 0.5960 - val_f1score: 0.5996\n",
      "Epoch 168/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.1777 - acc: 0.7511 - auc: 0.9140 - precision: 0.7547 - recall: 0.7469 - f1score: 0.7507 - val_loss: 6.5150 - val_acc: 0.6182 - val_auc: 0.9141 - val_precision: 0.6205 - val_recall: 0.6135 - val_f1score: 0.6169\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 546ms/step - loss: 6.1409 - acc: 0.7637 - auc: 0.9142 - precision: 0.7670 - recall: 0.7592 - f1score: 0.7631 - val_loss: 6.4116 - val_acc: 0.6240 - val_auc: 0.9143 - val_precision: 0.6296 - val_recall: 0.6217 - val_f1score: 0.6255\n",
      "Epoch 170/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.1240 - acc: 0.7588 - auc: 0.9144 - precision: 0.7617 - recall: 0.7548 - f1score: 0.7582 - val_loss: 6.5726 - val_acc: 0.6007 - val_auc: 0.9145 - val_precision: 0.6079 - val_recall: 0.5972 - val_f1score: 0.6025\n",
      "Epoch 171/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 6.0934 - acc: 0.7544 - auc: 0.9145 - precision: 0.7573 - recall: 0.7508 - f1score: 0.7540 - val_loss: 6.3844 - val_acc: 0.5995 - val_auc: 0.9146 - val_precision: 0.6008 - val_recall: 0.5949 - val_f1score: 0.5978\n",
      "Epoch 172/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 6.0691 - acc: 0.7593 - auc: 0.9147 - precision: 0.7625 - recall: 0.7549 - f1score: 0.7587 - val_loss: 6.5297 - val_acc: 0.5984 - val_auc: 0.9148 - val_precision: 0.6005 - val_recall: 0.5925 - val_f1score: 0.5964\n",
      "Epoch 173/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 6.0403 - acc: 0.7576 - auc: 0.9149 - precision: 0.7602 - recall: 0.7548 - f1score: 0.7575 - val_loss: 6.3025 - val_acc: 0.6100 - val_auc: 0.9150 - val_precision: 0.6120 - val_recall: 0.6077 - val_f1score: 0.6098\n",
      "Epoch 174/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 6.0287 - acc: 0.7586 - auc: 0.9151 - precision: 0.7617 - recall: 0.7550 - f1score: 0.7583 - val_loss: 6.2806 - val_acc: 0.6217 - val_auc: 0.9152 - val_precision: 0.6233 - val_recall: 0.6170 - val_f1score: 0.6201\n",
      "Epoch 175/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.9951 - acc: 0.7688 - auc: 0.9153 - precision: 0.7708 - recall: 0.7643 - f1score: 0.7675 - val_loss: 6.3149 - val_acc: 0.6251 - val_auc: 0.9154 - val_precision: 0.6297 - val_recall: 0.6251 - val_f1score: 0.6274\n",
      "Epoch 176/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 5.9658 - acc: 0.7649 - auc: 0.9154 - precision: 0.7676 - recall: 0.7620 - f1score: 0.7648 - val_loss: 7.2490 - val_acc: 0.5111 - val_auc: 0.9155 - val_precision: 0.5217 - val_recall: 0.5029 - val_f1score: 0.5118\n",
      "Epoch 177/300\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 5.9463 - acc: 0.7621 - auc: 0.9156 - precision: 0.7647 - recall: 0.7583 - f1score: 0.7615 - val_loss: 6.4057 - val_acc: 0.5832 - val_auc: 0.9156 - val_precision: 0.5828 - val_recall: 0.5774 - val_f1score: 0.5801\n",
      "Epoch 178/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.9161 - acc: 0.7674 - auc: 0.9157 - precision: 0.7700 - recall: 0.7632 - f1score: 0.7666 - val_loss: 6.2220 - val_acc: 0.6240 - val_auc: 0.9158 - val_precision: 0.6264 - val_recall: 0.6228 - val_f1score: 0.6246\n",
      "Epoch 179/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.8983 - acc: 0.7625 - auc: 0.9159 - precision: 0.7654 - recall: 0.7580 - f1score: 0.7617 - val_loss: 6.2874 - val_acc: 0.6182 - val_auc: 0.9160 - val_precision: 0.6205 - val_recall: 0.6147 - val_f1score: 0.6175\n",
      "Epoch 180/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.8741 - acc: 0.7636 - auc: 0.9161 - precision: 0.7664 - recall: 0.7604 - f1score: 0.7634 - val_loss: 6.1071 - val_acc: 0.6251 - val_auc: 0.9162 - val_precision: 0.6300 - val_recall: 0.6217 - val_f1score: 0.6258\n",
      "Epoch 181/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.8516 - acc: 0.7756 - auc: 0.9163 - precision: 0.7778 - recall: 0.7708 - f1score: 0.7743 - val_loss: 6.2011 - val_acc: 0.6170 - val_auc: 0.9164 - val_precision: 0.6211 - val_recall: 0.6158 - val_f1score: 0.6184\n",
      "Epoch 182/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.8187 - acc: 0.7709 - auc: 0.9165 - precision: 0.7740 - recall: 0.7677 - f1score: 0.7708 - val_loss: 6.2710 - val_acc: 0.6251 - val_auc: 0.9166 - val_precision: 0.6276 - val_recall: 0.6240 - val_f1score: 0.6258\n",
      "Epoch 183/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.8079 - acc: 0.7665 - auc: 0.9166 - precision: 0.7693 - recall: 0.7634 - f1score: 0.7663 - val_loss: 6.1297 - val_acc: 0.5984 - val_auc: 0.9167 - val_precision: 0.6022 - val_recall: 0.5949 - val_f1score: 0.5985\n",
      "Epoch 184/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 5.7836 - acc: 0.7706 - auc: 0.9168 - precision: 0.7738 - recall: 0.7662 - f1score: 0.7700 - val_loss: 6.3358 - val_acc: 0.5809 - val_auc: 0.9169 - val_precision: 0.5813 - val_recall: 0.5751 - val_f1score: 0.5781\n",
      "Epoch 185/300\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 5.7650 - acc: 0.7602 - auc: 0.9170 - precision: 0.7633 - recall: 0.7563 - f1score: 0.7598 - val_loss: 6.0930 - val_acc: 0.6019 - val_auc: 0.9171 - val_precision: 0.6045 - val_recall: 0.5995 - val_f1score: 0.6020\n",
      "Epoch 186/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.7367 - acc: 0.7704 - auc: 0.9171 - precision: 0.7735 - recall: 0.7663 - f1score: 0.7698 - val_loss: 6.1063 - val_acc: 0.6019 - val_auc: 0.9172 - val_precision: 0.6063 - val_recall: 0.6007 - val_f1score: 0.6034\n",
      "Epoch 187/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.7138 - acc: 0.7775 - auc: 0.9173 - precision: 0.7794 - recall: 0.7737 - f1score: 0.7765 - val_loss: 6.3044 - val_acc: 0.5972 - val_auc: 0.9174 - val_precision: 0.6019 - val_recall: 0.5925 - val_f1score: 0.5972\n",
      "Epoch 188/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.6864 - acc: 0.7783 - auc: 0.9175 - precision: 0.7814 - recall: 0.7752 - f1score: 0.7783 - val_loss: 6.0607 - val_acc: 0.6205 - val_auc: 0.9176 - val_precision: 0.6236 - val_recall: 0.6193 - val_f1score: 0.6214\n",
      "Epoch 189/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.6783 - acc: 0.7736 - auc: 0.9177 - precision: 0.7760 - recall: 0.7698 - f1score: 0.7729 - val_loss: 6.1659 - val_acc: 0.6019 - val_auc: 0.9177 - val_precision: 0.6045 - val_recall: 0.5891 - val_f1score: 0.5966\n",
      "Epoch 190/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.6698 - acc: 0.7680 - auc: 0.9178 - precision: 0.7705 - recall: 0.7645 - f1score: 0.7675 - val_loss: 6.0093 - val_acc: 0.6380 - val_auc: 0.9179 - val_precision: 0.6440 - val_recall: 0.6356 - val_f1score: 0.6398\n",
      "Epoch 191/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.6346 - acc: 0.7744 - auc: 0.9180 - precision: 0.7782 - recall: 0.7713 - f1score: 0.7747 - val_loss: 5.9879 - val_acc: 0.6193 - val_auc: 0.9181 - val_precision: 0.6210 - val_recall: 0.6158 - val_f1score: 0.6184\n",
      "Epoch 192/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.6116 - acc: 0.7752 - auc: 0.9182 - precision: 0.7773 - recall: 0.7710 - f1score: 0.7741 - val_loss: 6.0183 - val_acc: 0.5797 - val_auc: 0.9183 - val_precision: 0.5818 - val_recall: 0.5763 - val_f1score: 0.5789\n",
      "Epoch 193/300\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 5.5921 - acc: 0.7829 - auc: 0.9183 - precision: 0.7861 - recall: 0.7794 - f1score: 0.7827 - val_loss: 6.0860 - val_acc: 0.5995 - val_auc: 0.9184 - val_precision: 0.6047 - val_recall: 0.5960 - val_f1score: 0.6003\n",
      "Epoch 194/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.5703 - acc: 0.7826 - auc: 0.9185 - precision: 0.7848 - recall: 0.7787 - f1score: 0.7817 - val_loss: 5.9546 - val_acc: 0.6135 - val_auc: 0.9186 - val_precision: 0.6187 - val_recall: 0.6088 - val_f1score: 0.6137\n",
      "Epoch 195/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.5540 - acc: 0.7747 - auc: 0.9187 - precision: 0.7772 - recall: 0.7719 - f1score: 0.7745 - val_loss: 5.9868 - val_acc: 0.6019 - val_auc: 0.9188 - val_precision: 0.6099 - val_recall: 0.5984 - val_f1score: 0.6040\n",
      "Epoch 196/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.5300 - acc: 0.7743 - auc: 0.9188 - precision: 0.7775 - recall: 0.7711 - f1score: 0.7743 - val_loss: 5.9557 - val_acc: 0.5984 - val_auc: 0.9189 - val_precision: 0.6024 - val_recall: 0.5960 - val_f1score: 0.5992\n",
      "Epoch 197/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 553ms/step - loss: 5.5079 - acc: 0.7768 - auc: 0.9190 - precision: 0.7788 - recall: 0.7732 - f1score: 0.7759 - val_loss: 5.9226 - val_acc: 0.6356 - val_auc: 0.9191 - val_precision: 0.6387 - val_recall: 0.6310 - val_f1score: 0.6348\n",
      "Epoch 198/300\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 5.5042 - acc: 0.7736 - auc: 0.9192 - precision: 0.7760 - recall: 0.7691 - f1score: 0.7725 - val_loss: 5.9664 - val_acc: 0.6054 - val_auc: 0.9193 - val_precision: 0.6069 - val_recall: 0.5984 - val_f1score: 0.6026\n",
      "Epoch 199/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 5.4762 - acc: 0.7837 - auc: 0.9193 - precision: 0.7860 - recall: 0.7804 - f1score: 0.7831 - val_loss: 5.8790 - val_acc: 0.6147 - val_auc: 0.9194 - val_precision: 0.6182 - val_recall: 0.6112 - val_f1score: 0.6146\n",
      "Epoch 200/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.4500 - acc: 0.7896 - auc: 0.9195 - precision: 0.7917 - recall: 0.7854 - f1score: 0.7885 - val_loss: 5.9016 - val_acc: 0.5925 - val_auc: 0.9196 - val_precision: 0.6021 - val_recall: 0.5891 - val_f1score: 0.5954\n",
      "Epoch 201/300\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 5.4389 - acc: 0.7812 - auc: 0.9197 - precision: 0.7834 - recall: 0.7781 - f1score: 0.7807 - val_loss: 5.8345 - val_acc: 0.6065 - val_auc: 0.9198 - val_precision: 0.6122 - val_recall: 0.6042 - val_f1score: 0.6081\n",
      "Epoch 202/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.4228 - acc: 0.7812 - auc: 0.9199 - precision: 0.7827 - recall: 0.7780 - f1score: 0.7803 - val_loss: 5.8757 - val_acc: 0.5984 - val_auc: 0.9199 - val_precision: 0.6012 - val_recall: 0.5960 - val_f1score: 0.5986\n",
      "Epoch 203/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.3982 - acc: 0.7843 - auc: 0.9200 - precision: 0.7875 - recall: 0.7807 - f1score: 0.7841 - val_loss: 5.7354 - val_acc: 0.6251 - val_auc: 0.9201 - val_precision: 0.6261 - val_recall: 0.6217 - val_f1score: 0.6238\n",
      "Epoch 204/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.3727 - acc: 0.7907 - auc: 0.9202 - precision: 0.7932 - recall: 0.7875 - f1score: 0.7903 - val_loss: 5.8456 - val_acc: 0.5972 - val_auc: 0.9203 - val_precision: 0.5962 - val_recall: 0.5914 - val_f1score: 0.5938\n",
      "Epoch 205/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.3699 - acc: 0.7784 - auc: 0.9204 - precision: 0.7803 - recall: 0.7745 - f1score: 0.7774 - val_loss: 5.7333 - val_acc: 0.6193 - val_auc: 0.9204 - val_precision: 0.6214 - val_recall: 0.6170 - val_f1score: 0.6192\n",
      "Epoch 206/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 5.3410 - acc: 0.7905 - auc: 0.9205 - precision: 0.7933 - recall: 0.7866 - f1score: 0.7899 - val_loss: 5.7887 - val_acc: 0.6228 - val_auc: 0.9206 - val_precision: 0.6258 - val_recall: 0.6170 - val_f1score: 0.6213\n",
      "Epoch 207/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 5.3259 - acc: 0.7857 - auc: 0.9207 - precision: 0.7872 - recall: 0.7818 - f1score: 0.7844 - val_loss: 5.7625 - val_acc: 0.5960 - val_auc: 0.9208 - val_precision: 0.6012 - val_recall: 0.5914 - val_f1score: 0.5962\n",
      "Epoch 208/300\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 5.3091 - acc: 0.7921 - auc: 0.9209 - precision: 0.7952 - recall: 0.7885 - f1score: 0.7918 - val_loss: 5.9283 - val_acc: 0.5902 - val_auc: 0.9210 - val_precision: 0.5945 - val_recall: 0.5879 - val_f1score: 0.5911\n",
      "Epoch 209/300\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 5.2851 - acc: 0.7945 - auc: 0.9210 - precision: 0.7968 - recall: 0.7914 - f1score: 0.7940 - val_loss: 5.8057 - val_acc: 0.5949 - val_auc: 0.9211 - val_precision: 0.5964 - val_recall: 0.5937 - val_f1score: 0.5950\n",
      "Epoch 210/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.2733 - acc: 0.7948 - auc: 0.9212 - precision: 0.7975 - recall: 0.7909 - f1score: 0.7942 - val_loss: 5.6577 - val_acc: 0.5856 - val_auc: 0.9213 - val_precision: 0.5891 - val_recall: 0.5844 - val_f1score: 0.5867\n",
      "Epoch 211/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.2555 - acc: 0.7943 - auc: 0.9214 - precision: 0.7964 - recall: 0.7916 - f1score: 0.7940 - val_loss: 5.8554 - val_acc: 0.6007 - val_auc: 0.9215 - val_precision: 0.6026 - val_recall: 0.5984 - val_f1score: 0.6005\n",
      "Epoch 212/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 5.2367 - acc: 0.7989 - auc: 0.9215 - precision: 0.8006 - recall: 0.7951 - f1score: 0.7978 - val_loss: 5.5849 - val_acc: 0.6030 - val_auc: 0.9216 - val_precision: 0.6068 - val_recall: 0.6019 - val_f1score: 0.6043\n",
      "Epoch 213/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 5.2166 - acc: 0.7969 - auc: 0.9217 - precision: 0.7984 - recall: 0.7931 - f1score: 0.7957 - val_loss: 5.7200 - val_acc: 0.5984 - val_auc: 0.9218 - val_precision: 0.6019 - val_recall: 0.5914 - val_f1score: 0.5965\n",
      "Epoch 214/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.2093 - acc: 0.7871 - auc: 0.9219 - precision: 0.7918 - recall: 0.7838 - f1score: 0.7877 - val_loss: 5.6088 - val_acc: 0.6077 - val_auc: 0.9220 - val_precision: 0.6098 - val_recall: 0.6077 - val_f1score: 0.6087\n",
      "Epoch 215/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.2028 - acc: 0.7944 - auc: 0.9220 - precision: 0.7978 - recall: 0.7913 - f1score: 0.7945 - val_loss: 5.6890 - val_acc: 0.6054 - val_auc: 0.9221 - val_precision: 0.6099 - val_recall: 0.6019 - val_f1score: 0.6058\n",
      "Epoch 216/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 5.1797 - acc: 0.7869 - auc: 0.9222 - precision: 0.7882 - recall: 0.7836 - f1score: 0.7859 - val_loss: 5.6737 - val_acc: 0.6123 - val_auc: 0.9223 - val_precision: 0.6161 - val_recall: 0.6100 - val_f1score: 0.6130\n",
      "Epoch 217/300\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 5.1606 - acc: 0.7997 - auc: 0.9224 - precision: 0.8015 - recall: 0.7968 - f1score: 0.7992 - val_loss: 5.5788 - val_acc: 0.6019 - val_auc: 0.9224 - val_precision: 0.6026 - val_recall: 0.6019 - val_f1score: 0.6022\n",
      "Epoch 218/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 5.1338 - acc: 0.8025 - auc: 0.9225 - precision: 0.8052 - recall: 0.7996 - f1score: 0.8024 - val_loss: 5.6959 - val_acc: 0.6333 - val_auc: 0.9226 - val_precision: 0.6371 - val_recall: 0.6275 - val_f1score: 0.6322\n",
      "Epoch 219/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.1248 - acc: 0.7984 - auc: 0.9227 - precision: 0.8018 - recall: 0.7969 - f1score: 0.7993 - val_loss: 5.6486 - val_acc: 0.6193 - val_auc: 0.9228 - val_precision: 0.6219 - val_recall: 0.6123 - val_f1score: 0.6171\n",
      "Epoch 220/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 5.1103 - acc: 0.7928 - auc: 0.9229 - precision: 0.7936 - recall: 0.7901 - f1score: 0.7918 - val_loss: 5.5465 - val_acc: 0.6193 - val_auc: 0.9229 - val_precision: 0.6202 - val_recall: 0.6158 - val_f1score: 0.6180\n",
      "Epoch 221/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 5.1004 - acc: 0.7904 - auc: 0.9230 - precision: 0.7920 - recall: 0.7872 - f1score: 0.7896 - val_loss: 5.5325 - val_acc: 0.5856 - val_auc: 0.9231 - val_precision: 0.5895 - val_recall: 0.5844 - val_f1score: 0.5869\n",
      "Epoch 222/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 5.0830 - acc: 0.8009 - auc: 0.9232 - precision: 0.8030 - recall: 0.7980 - f1score: 0.8005 - val_loss: 5.4734 - val_acc: 0.6286 - val_auc: 0.9233 - val_precision: 0.6298 - val_recall: 0.6251 - val_f1score: 0.6274\n",
      "Epoch 223/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.0662 - acc: 0.8041 - auc: 0.9234 - precision: 0.8063 - recall: 0.8016 - f1score: 0.8039 - val_loss: 5.5500 - val_acc: 0.5925 - val_auc: 0.9234 - val_precision: 0.5963 - val_recall: 0.5914 - val_f1score: 0.5938\n",
      "Epoch 224/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 5.0435 - acc: 0.8046 - auc: 0.9235 - precision: 0.8063 - recall: 0.8023 - f1score: 0.8042 - val_loss: 5.5767 - val_acc: 0.6088 - val_auc: 0.9236 - val_precision: 0.6138 - val_recall: 0.6054 - val_f1score: 0.6095\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 548ms/step - loss: 5.0378 - acc: 0.8037 - auc: 0.9237 - precision: 0.8061 - recall: 0.7998 - f1score: 0.8029 - val_loss: 5.5452 - val_acc: 0.6030 - val_auc: 0.9238 - val_precision: 0.6080 - val_recall: 0.6007 - val_f1score: 0.6043\n",
      "Epoch 226/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 5.0208 - acc: 0.8062 - auc: 0.9239 - precision: 0.8077 - recall: 0.8043 - f1score: 0.8060 - val_loss: 5.4935 - val_acc: 0.6205 - val_auc: 0.9239 - val_precision: 0.6266 - val_recall: 0.6170 - val_f1score: 0.6217\n",
      "Epoch 227/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 5.0001 - acc: 0.8035 - auc: 0.9240 - precision: 0.8072 - recall: 0.8000 - f1score: 0.8036 - val_loss: 5.4902 - val_acc: 0.6251 - val_auc: 0.9241 - val_precision: 0.6288 - val_recall: 0.6228 - val_f1score: 0.6258\n",
      "Epoch 228/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 4.9825 - acc: 0.8109 - auc: 0.9242 - precision: 0.8123 - recall: 0.8066 - f1score: 0.8094 - val_loss: 5.5180 - val_acc: 0.6123 - val_auc: 0.9243 - val_precision: 0.6160 - val_recall: 0.6123 - val_f1score: 0.6142\n",
      "Epoch 229/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 4.9823 - acc: 0.7980 - auc: 0.9244 - precision: 0.7996 - recall: 0.7957 - f1score: 0.7977 - val_loss: 5.4435 - val_acc: 0.6088 - val_auc: 0.9244 - val_precision: 0.6140 - val_recall: 0.6065 - val_f1score: 0.6102\n",
      "Epoch 230/300\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 4.9534 - acc: 0.8115 - auc: 0.9245 - precision: 0.8134 - recall: 0.8096 - f1score: 0.8115 - val_loss: 5.4339 - val_acc: 0.6112 - val_auc: 0.9246 - val_precision: 0.6138 - val_recall: 0.6088 - val_f1score: 0.6113\n",
      "Epoch 231/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 4.9486 - acc: 0.8091 - auc: 0.9247 - precision: 0.8110 - recall: 0.8061 - f1score: 0.8085 - val_loss: 5.4269 - val_acc: 0.6147 - val_auc: 0.9248 - val_precision: 0.6157 - val_recall: 0.6123 - val_f1score: 0.6140\n",
      "Epoch 232/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.9264 - acc: 0.8098 - auc: 0.9248 - precision: 0.8119 - recall: 0.8075 - f1score: 0.8096 - val_loss: 5.7216 - val_acc: 0.5914 - val_auc: 0.9249 - val_precision: 0.5937 - val_recall: 0.5914 - val_f1score: 0.5925\n",
      "Epoch 233/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 4.9060 - acc: 0.8128 - auc: 0.9250 - precision: 0.8148 - recall: 0.8100 - f1score: 0.8124 - val_loss: 5.4410 - val_acc: 0.6193 - val_auc: 0.9251 - val_precision: 0.6222 - val_recall: 0.6170 - val_f1score: 0.6196\n",
      "Epoch 234/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.9040 - acc: 0.8106 - auc: 0.9252 - precision: 0.8127 - recall: 0.8080 - f1score: 0.8103 - val_loss: 5.4887 - val_acc: 0.6228 - val_auc: 0.9252 - val_precision: 0.6245 - val_recall: 0.6193 - val_f1score: 0.6219\n",
      "Epoch 235/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.8812 - acc: 0.8152 - auc: 0.9253 - precision: 0.8162 - recall: 0.8117 - f1score: 0.8139 - val_loss: 5.5343 - val_acc: 0.5972 - val_auc: 0.9254 - val_precision: 0.6023 - val_recall: 0.5960 - val_f1score: 0.5991\n",
      "Epoch 236/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.8700 - acc: 0.8180 - auc: 0.9255 - precision: 0.8196 - recall: 0.8157 - f1score: 0.8176 - val_loss: 5.4757 - val_acc: 0.6228 - val_auc: 0.9256 - val_precision: 0.6250 - val_recall: 0.6205 - val_f1score: 0.6227\n",
      "Epoch 237/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.8619 - acc: 0.8105 - auc: 0.9256 - precision: 0.8126 - recall: 0.8085 - f1score: 0.8105 - val_loss: 5.3801 - val_acc: 0.5984 - val_auc: 0.9257 - val_precision: 0.5995 - val_recall: 0.5949 - val_f1score: 0.5972\n",
      "Epoch 238/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.8410 - acc: 0.8142 - auc: 0.9258 - precision: 0.8159 - recall: 0.8128 - f1score: 0.8143 - val_loss: 5.6056 - val_acc: 0.6135 - val_auc: 0.9259 - val_precision: 0.6184 - val_recall: 0.6112 - val_f1score: 0.6147\n",
      "Epoch 239/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.8368 - acc: 0.8143 - auc: 0.9260 - precision: 0.8163 - recall: 0.8123 - f1score: 0.8143 - val_loss: 5.3522 - val_acc: 0.6205 - val_auc: 0.9261 - val_precision: 0.6226 - val_recall: 0.6205 - val_f1score: 0.6216\n",
      "Epoch 240/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.8178 - acc: 0.8170 - auc: 0.9261 - precision: 0.8194 - recall: 0.8145 - f1score: 0.8169 - val_loss: 5.4270 - val_acc: 0.5960 - val_auc: 0.9262 - val_precision: 0.5978 - val_recall: 0.5949 - val_f1score: 0.5963\n",
      "Epoch 241/300\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 4.8012 - acc: 0.8205 - auc: 0.9263 - precision: 0.8225 - recall: 0.8176 - f1score: 0.8200 - val_loss: 5.3577 - val_acc: 0.5891 - val_auc: 0.9264 - val_precision: 0.5925 - val_recall: 0.5891 - val_f1score: 0.5907\n",
      "Epoch 242/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.8002 - acc: 0.8176 - auc: 0.9264 - precision: 0.8195 - recall: 0.8151 - f1score: 0.8173 - val_loss: 5.3926 - val_acc: 0.5891 - val_auc: 0.9265 - val_precision: 0.5915 - val_recall: 0.5844 - val_f1score: 0.5879\n",
      "Epoch 243/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.7779 - acc: 0.8224 - auc: 0.9266 - precision: 0.8242 - recall: 0.8207 - f1score: 0.8225 - val_loss: 5.3641 - val_acc: 0.6112 - val_auc: 0.9267 - val_precision: 0.6142 - val_recall: 0.6065 - val_f1score: 0.6103\n",
      "Epoch 244/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.7656 - acc: 0.8200 - auc: 0.9268 - precision: 0.8223 - recall: 0.8181 - f1score: 0.8202 - val_loss: 5.2728 - val_acc: 0.6158 - val_auc: 0.9268 - val_precision: 0.6190 - val_recall: 0.6135 - val_f1score: 0.6162\n",
      "Epoch 245/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.7526 - acc: 0.8224 - auc: 0.9269 - precision: 0.8234 - recall: 0.8199 - f1score: 0.8216 - val_loss: 5.3857 - val_acc: 0.5914 - val_auc: 0.9270 - val_precision: 0.5936 - val_recall: 0.5867 - val_f1score: 0.5902\n",
      "Epoch 246/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 4.7388 - acc: 0.8258 - auc: 0.9271 - precision: 0.8285 - recall: 0.8233 - f1score: 0.8259 - val_loss: 5.3465 - val_acc: 0.6100 - val_auc: 0.9272 - val_precision: 0.6098 - val_recall: 0.6077 - val_f1score: 0.6087\n",
      "Epoch 247/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.7218 - acc: 0.8228 - auc: 0.9272 - precision: 0.8265 - recall: 0.8208 - f1score: 0.8236 - val_loss: 5.3416 - val_acc: 0.6182 - val_auc: 0.9273 - val_precision: 0.6234 - val_recall: 0.6182 - val_f1score: 0.6207\n",
      "Epoch 248/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.7044 - acc: 0.8319 - auc: 0.9274 - precision: 0.8333 - recall: 0.8287 - f1score: 0.8310 - val_loss: 5.4558 - val_acc: 0.6042 - val_auc: 0.9275 - val_precision: 0.6092 - val_recall: 0.6030 - val_f1score: 0.6060\n",
      "Epoch 249/300\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 4.6969 - acc: 0.8265 - auc: 0.9276 - precision: 0.8285 - recall: 0.8243 - f1score: 0.8264 - val_loss: 5.4807 - val_acc: 0.6030 - val_auc: 0.9276 - val_precision: 0.6058 - val_recall: 0.6007 - val_f1score: 0.6032\n",
      "Epoch 250/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 4.6882 - acc: 0.8257 - auc: 0.9277 - precision: 0.8284 - recall: 0.8243 - f1score: 0.8263 - val_loss: 5.2348 - val_acc: 0.5972 - val_auc: 0.9278 - val_precision: 0.6027 - val_recall: 0.5972 - val_f1score: 0.5999\n",
      "Epoch 251/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 4.6810 - acc: 0.8256 - auc: 0.9279 - precision: 0.8265 - recall: 0.8223 - f1score: 0.8244 - val_loss: 5.2852 - val_acc: 0.5809 - val_auc: 0.9280 - val_precision: 0.5871 - val_recall: 0.5739 - val_f1score: 0.5804\n",
      "Epoch 252/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.6686 - acc: 0.8230 - auc: 0.9280 - precision: 0.8246 - recall: 0.8220 - f1score: 0.8233 - val_loss: 5.1945 - val_acc: 0.6286 - val_auc: 0.9281 - val_precision: 0.6313 - val_recall: 0.6263 - val_f1score: 0.6288\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 549ms/step - loss: 4.6428 - acc: 0.8315 - auc: 0.9282 - precision: 0.8334 - recall: 0.8293 - f1score: 0.8313 - val_loss: 5.5372 - val_acc: 0.5914 - val_auc: 0.9283 - val_precision: 0.5941 - val_recall: 0.5914 - val_f1score: 0.5927\n",
      "Epoch 254/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.6425 - acc: 0.8277 - auc: 0.9283 - precision: 0.8296 - recall: 0.8262 - f1score: 0.8279 - val_loss: 5.4690 - val_acc: 0.6054 - val_auc: 0.9284 - val_precision: 0.6092 - val_recall: 0.6042 - val_f1score: 0.6067\n",
      "Epoch 255/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.6265 - acc: 0.8331 - auc: 0.9285 - precision: 0.8349 - recall: 0.8312 - f1score: 0.8330 - val_loss: 5.1940 - val_acc: 0.6042 - val_auc: 0.9286 - val_precision: 0.6065 - val_recall: 0.6030 - val_f1score: 0.6048\n",
      "Epoch 256/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 4.6020 - acc: 0.8411 - auc: 0.9287 - precision: 0.8434 - recall: 0.8386 - f1score: 0.8410 - val_loss: 5.1248 - val_acc: 0.6217 - val_auc: 0.9287 - val_precision: 0.6227 - val_recall: 0.6193 - val_f1score: 0.6210\n",
      "Epoch 257/300\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 4.6008 - acc: 0.8328 - auc: 0.9288 - precision: 0.8349 - recall: 0.8314 - f1score: 0.8331 - val_loss: 5.1880 - val_acc: 0.6251 - val_auc: 0.9289 - val_precision: 0.6273 - val_recall: 0.6251 - val_f1score: 0.6262\n",
      "Epoch 258/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.5963 - acc: 0.8289 - auc: 0.9290 - precision: 0.8307 - recall: 0.8266 - f1score: 0.8286 - val_loss: 5.2464 - val_acc: 0.6007 - val_auc: 0.9291 - val_precision: 0.6049 - val_recall: 0.5984 - val_f1score: 0.6016\n",
      "Epoch 259/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.5815 - acc: 0.8312 - auc: 0.9291 - precision: 0.8325 - recall: 0.8284 - f1score: 0.8304 - val_loss: 5.1650 - val_acc: 0.6321 - val_auc: 0.9292 - val_precision: 0.6339 - val_recall: 0.6286 - val_f1score: 0.6312\n",
      "Epoch 260/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.5688 - acc: 0.8309 - auc: 0.9293 - precision: 0.8324 - recall: 0.8279 - f1score: 0.8301 - val_loss: 5.1210 - val_acc: 0.6123 - val_auc: 0.9294 - val_precision: 0.6152 - val_recall: 0.6123 - val_f1score: 0.6137\n",
      "Epoch 261/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.5674 - acc: 0.8281 - auc: 0.9295 - precision: 0.8291 - recall: 0.8264 - f1score: 0.8277 - val_loss: 5.1037 - val_acc: 0.6251 - val_auc: 0.9295 - val_precision: 0.6265 - val_recall: 0.6228 - val_f1score: 0.6246\n",
      "Epoch 262/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.5459 - acc: 0.8294 - auc: 0.9296 - precision: 0.8312 - recall: 0.8273 - f1score: 0.8292 - val_loss: 5.0665 - val_acc: 0.6019 - val_auc: 0.9297 - val_precision: 0.6028 - val_recall: 0.6007 - val_f1score: 0.6017\n",
      "Epoch 263/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.5315 - acc: 0.8380 - auc: 0.9298 - precision: 0.8396 - recall: 0.8369 - f1score: 0.8382 - val_loss: 5.3466 - val_acc: 0.6147 - val_auc: 0.9298 - val_precision: 0.6168 - val_recall: 0.6147 - val_f1score: 0.6157\n",
      "Epoch 264/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.5285 - acc: 0.8349 - auc: 0.9299 - precision: 0.8362 - recall: 0.8341 - f1score: 0.8352 - val_loss: 5.1555 - val_acc: 0.6275 - val_auc: 0.9300 - val_precision: 0.6331 - val_recall: 0.6240 - val_f1score: 0.6284\n",
      "Epoch 265/300\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 4.5162 - acc: 0.8358 - auc: 0.9301 - precision: 0.8371 - recall: 0.8336 - f1score: 0.8353 - val_loss: 5.1484 - val_acc: 0.6065 - val_auc: 0.9301 - val_precision: 0.6074 - val_recall: 0.6030 - val_f1score: 0.6052\n",
      "Epoch 266/300\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 4.4930 - acc: 0.8434 - auc: 0.9302 - precision: 0.8437 - recall: 0.8411 - f1score: 0.8424 - val_loss: 5.1394 - val_acc: 0.6007 - val_auc: 0.9303 - val_precision: 0.6078 - val_recall: 0.6007 - val_f1score: 0.6042\n",
      "Epoch 267/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.4842 - acc: 0.8351 - auc: 0.9304 - precision: 0.8364 - recall: 0.8335 - f1score: 0.8349 - val_loss: 5.2315 - val_acc: 0.6077 - val_auc: 0.9304 - val_precision: 0.6093 - val_recall: 0.6065 - val_f1score: 0.6079\n",
      "Epoch 268/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.4711 - acc: 0.8343 - auc: 0.9305 - precision: 0.8357 - recall: 0.8323 - f1score: 0.8340 - val_loss: 5.0842 - val_acc: 0.6019 - val_auc: 0.9306 - val_precision: 0.6028 - val_recall: 0.5984 - val_f1score: 0.6005\n",
      "Epoch 269/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.4648 - acc: 0.8438 - auc: 0.9307 - precision: 0.8448 - recall: 0.8412 - f1score: 0.8429 - val_loss: 5.0609 - val_acc: 0.6345 - val_auc: 0.9307 - val_precision: 0.6345 - val_recall: 0.6345 - val_f1score: 0.6345\n",
      "Epoch 270/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.4611 - acc: 0.8348 - auc: 0.9308 - precision: 0.8355 - recall: 0.8331 - f1score: 0.8343 - val_loss: 4.9743 - val_acc: 0.6298 - val_auc: 0.9309 - val_precision: 0.6312 - val_recall: 0.6251 - val_f1score: 0.6281\n",
      "Epoch 271/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.4359 - acc: 0.8479 - auc: 0.9310 - precision: 0.8494 - recall: 0.8456 - f1score: 0.8475 - val_loss: 5.1960 - val_acc: 0.5972 - val_auc: 0.9311 - val_precision: 0.6005 - val_recall: 0.5949 - val_f1score: 0.5977\n",
      "Epoch 272/300\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 4.4383 - acc: 0.8415 - auc: 0.9311 - precision: 0.8427 - recall: 0.8399 - f1score: 0.8413 - val_loss: 5.1907 - val_acc: 0.6263 - val_auc: 0.9312 - val_precision: 0.6258 - val_recall: 0.6228 - val_f1score: 0.6243\n",
      "Epoch 273/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.4240 - acc: 0.8360 - auc: 0.9313 - precision: 0.8383 - recall: 0.8337 - f1score: 0.8360 - val_loss: 5.1503 - val_acc: 0.6042 - val_auc: 0.9313 - val_precision: 0.6058 - val_recall: 0.6007 - val_f1score: 0.6032\n",
      "Epoch 274/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.4124 - acc: 0.8392 - auc: 0.9314 - precision: 0.8406 - recall: 0.8372 - f1score: 0.8389 - val_loss: 5.2290 - val_acc: 0.6007 - val_auc: 0.9315 - val_precision: 0.5994 - val_recall: 0.5960 - val_f1score: 0.5977\n",
      "Epoch 275/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.4059 - acc: 0.8390 - auc: 0.9316 - precision: 0.8402 - recall: 0.8379 - f1score: 0.8390 - val_loss: 5.0878 - val_acc: 0.6112 - val_auc: 0.9316 - val_precision: 0.6140 - val_recall: 0.6112 - val_f1score: 0.6126\n",
      "Epoch 276/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.4022 - acc: 0.8364 - auc: 0.9317 - precision: 0.8384 - recall: 0.8351 - f1score: 0.8367 - val_loss: 5.0396 - val_acc: 0.6100 - val_auc: 0.9318 - val_precision: 0.6127 - val_recall: 0.6100 - val_f1score: 0.6114\n",
      "Epoch 277/300\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 4.3882 - acc: 0.8341 - auc: 0.9318 - precision: 0.8345 - recall: 0.8307 - f1score: 0.8326 - val_loss: 4.9495 - val_acc: 0.6170 - val_auc: 0.9319 - val_precision: 0.6168 - val_recall: 0.6147 - val_f1score: 0.6157\n",
      "Epoch 278/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.3728 - acc: 0.8455 - auc: 0.9320 - precision: 0.8465 - recall: 0.8442 - f1score: 0.8454 - val_loss: 5.0831 - val_acc: 0.6135 - val_auc: 0.9321 - val_precision: 0.6152 - val_recall: 0.6123 - val_f1score: 0.6137\n",
      "Epoch 279/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.3620 - acc: 0.8428 - auc: 0.9321 - precision: 0.8439 - recall: 0.8414 - f1score: 0.8427 - val_loss: 5.0195 - val_acc: 0.5984 - val_auc: 0.9322 - val_precision: 0.5994 - val_recall: 0.5937 - val_f1score: 0.5965\n",
      "Epoch 280/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 4.3434 - acc: 0.8483 - auc: 0.9323 - precision: 0.8500 - recall: 0.8466 - f1score: 0.8483 - val_loss: 5.2521 - val_acc: 0.6065 - val_auc: 0.9323 - val_precision: 0.6100 - val_recall: 0.6030 - val_f1score: 0.6064\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 55s 548ms/step - loss: 4.3509 - acc: 0.8427 - auc: 0.9324 - precision: 0.8440 - recall: 0.8407 - f1score: 0.8424 - val_loss: 5.0291 - val_acc: 0.6030 - val_auc: 0.9325 - val_precision: 0.6080 - val_recall: 0.6019 - val_f1score: 0.6049\n",
      "Epoch 282/300\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 4.3416 - acc: 0.8391 - auc: 0.9326 - precision: 0.8415 - recall: 0.8369 - f1score: 0.8392 - val_loss: 5.0583 - val_acc: 0.6007 - val_auc: 0.9326 - val_precision: 0.6032 - val_recall: 0.5995 - val_f1score: 0.6013\n",
      "Epoch 283/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 4.3102 - acc: 0.8508 - auc: 0.9327 - precision: 0.8522 - recall: 0.8501 - f1score: 0.8512 - val_loss: 5.2042 - val_acc: 0.6158 - val_auc: 0.9328 - val_precision: 0.6179 - val_recall: 0.6135 - val_f1score: 0.6157\n",
      "Epoch 284/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.3026 - acc: 0.8553 - auc: 0.9328 - precision: 0.8568 - recall: 0.8533 - f1score: 0.8550 - val_loss: 5.1571 - val_acc: 0.6240 - val_auc: 0.9329 - val_precision: 0.6283 - val_recall: 0.6217 - val_f1score: 0.6249\n",
      "Epoch 285/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.2980 - acc: 0.8527 - auc: 0.9330 - precision: 0.8540 - recall: 0.8502 - f1score: 0.8521 - val_loss: 5.0132 - val_acc: 0.6182 - val_auc: 0.9331 - val_precision: 0.6172 - val_recall: 0.6135 - val_f1score: 0.6153\n",
      "Epoch 286/300\n",
      "100/100 [==============================] - 56s 557ms/step - loss: 4.2981 - acc: 0.8435 - auc: 0.9331 - precision: 0.8448 - recall: 0.8420 - f1score: 0.8434 - val_loss: 4.9654 - val_acc: 0.6147 - val_auc: 0.9332 - val_precision: 0.6162 - val_recall: 0.6147 - val_f1score: 0.6154\n",
      "Epoch 287/300\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 4.2805 - acc: 0.8469 - auc: 0.9333 - precision: 0.8479 - recall: 0.8445 - f1score: 0.8462 - val_loss: 5.0118 - val_acc: 0.6030 - val_auc: 0.9333 - val_precision: 0.6033 - val_recall: 0.6007 - val_f1score: 0.6020\n",
      "Epoch 288/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.2787 - acc: 0.8493 - auc: 0.9334 - precision: 0.8502 - recall: 0.8474 - f1score: 0.8488 - val_loss: 5.0570 - val_acc: 0.6170 - val_auc: 0.9335 - val_precision: 0.6199 - val_recall: 0.6170 - val_f1score: 0.6184\n",
      "Epoch 289/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 4.2490 - acc: 0.8531 - auc: 0.9335 - precision: 0.8534 - recall: 0.8518 - f1score: 0.8526 - val_loss: 5.0381 - val_acc: 0.5949 - val_auc: 0.9336 - val_precision: 0.5975 - val_recall: 0.5949 - val_f1score: 0.5962\n",
      "Epoch 290/300\n",
      "100/100 [==============================] - 55s 552ms/step - loss: 4.2434 - acc: 0.8516 - auc: 0.9337 - precision: 0.8527 - recall: 0.8499 - f1score: 0.8513 - val_loss: 5.0799 - val_acc: 0.5972 - val_auc: 0.9337 - val_precision: 0.5996 - val_recall: 0.5949 - val_f1score: 0.5972\n",
      "Epoch 291/300\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 4.2356 - acc: 0.8509 - auc: 0.9338 - precision: 0.8527 - recall: 0.8494 - f1score: 0.8510 - val_loss: 4.9580 - val_acc: 0.5809 - val_auc: 0.9339 - val_precision: 0.5816 - val_recall: 0.5797 - val_f1score: 0.5807\n",
      "Epoch 292/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.2197 - acc: 0.8610 - auc: 0.9340 - precision: 0.8628 - recall: 0.8603 - f1score: 0.8615 - val_loss: 5.2968 - val_acc: 0.5832 - val_auc: 0.9340 - val_precision: 0.5889 - val_recall: 0.5809 - val_f1score: 0.5849\n",
      "Epoch 293/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.2154 - acc: 0.8560 - auc: 0.9341 - precision: 0.8577 - recall: 0.8543 - f1score: 0.8560 - val_loss: 4.9530 - val_acc: 0.5984 - val_auc: 0.9342 - val_precision: 0.5998 - val_recall: 0.5984 - val_f1score: 0.5991\n",
      "Epoch 294/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.2082 - acc: 0.8571 - auc: 0.9342 - precision: 0.8584 - recall: 0.8562 - f1score: 0.8573 - val_loss: 5.0161 - val_acc: 0.6007 - val_auc: 0.9343 - val_precision: 0.6036 - val_recall: 0.5972 - val_f1score: 0.6003\n",
      "Epoch 295/300\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 4.2020 - acc: 0.8550 - auc: 0.9344 - precision: 0.8566 - recall: 0.8536 - f1score: 0.8551 - val_loss: 5.0214 - val_acc: 0.6391 - val_auc: 0.9344 - val_precision: 0.6386 - val_recall: 0.6380 - val_f1score: 0.6383\n",
      "Epoch 296/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.1950 - acc: 0.8615 - auc: 0.9345 - precision: 0.8633 - recall: 0.8594 - f1score: 0.8613 - val_loss: 4.9806 - val_acc: 0.6065 - val_auc: 0.9346 - val_precision: 0.6069 - val_recall: 0.6054 - val_f1score: 0.6061\n",
      "Epoch 297/300\n",
      "100/100 [==============================] - 55s 545ms/step - loss: 4.1746 - acc: 0.8585 - auc: 0.9347 - precision: 0.8597 - recall: 0.8566 - f1score: 0.8581 - val_loss: 5.1750 - val_acc: 0.6042 - val_auc: 0.9347 - val_precision: 0.6073 - val_recall: 0.6019 - val_f1score: 0.6045\n",
      "Epoch 298/300\n",
      "100/100 [==============================] - 55s 550ms/step - loss: 4.1653 - acc: 0.8678 - auc: 0.9348 - precision: 0.8687 - recall: 0.8670 - f1score: 0.8678 - val_loss: 5.0047 - val_acc: 0.5937 - val_auc: 0.9349 - val_precision: 0.5955 - val_recall: 0.5925 - val_f1score: 0.5940\n",
      "Epoch 299/300\n",
      "100/100 [==============================] - 55s 555ms/step - loss: 4.1644 - acc: 0.8581 - auc: 0.9349 - precision: 0.8595 - recall: 0.8567 - f1score: 0.8581 - val_loss: 5.0700 - val_acc: 0.6158 - val_auc: 0.9350 - val_precision: 0.6192 - val_recall: 0.6135 - val_f1score: 0.6163\n",
      "Epoch 300/300\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 4.1407 - acc: 0.8706 - auc: 0.9351 - precision: 0.8723 - recall: 0.8693 - f1score: 0.8708 - val_loss: 4.9713 - val_acc: 0.5984 - val_auc: 0.9352 - val_precision: 0.6022 - val_recall: 0.5972 - val_f1score: 0.5997\n"
     ]
    }
   ],
   "source": [
    "history = myvgg.fit_generator(dgf, \n",
    "            steps_per_epoch=100, \n",
    "            epochs=300, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=16, \n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvgg.save('VGG16_Aug_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('X_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 2s 3ms/step\n",
      "loss: 15.470, accuracy: 0.278, auc: 0.935, precision: 0.278, recall: 0.278, f1score: 0.278\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = myvgg.evaluate(X_test, y_test, batch_size=64)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859/859 [==============================] - 2s 3ms/step\n",
      "loss: 4.971, accuracy: 0.598, auc: 0.935, precision: 0.602, recall: 0.597, f1score: 0.600\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = myvgg.evaluate(X_val, y_val, batch_size=64)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
