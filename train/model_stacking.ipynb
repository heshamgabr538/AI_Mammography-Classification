{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('X_val.npy')\n",
    "y=np.load('y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def model_load(model):\n",
    "    model = load_model(model,compile=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "            metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble할 model load\n",
    "\n",
    "model1=model_load('./G_팔로미_models/VGG16_1_no callback(541).hdf5')\n",
    "model2=model_load('./G_팔로미_models/VGG16_fine_tuning_2(623)_no callback.hdf5')\n",
    "model3=model_load('./G_팔로미_models/Inception v3_fine tuning_2(613).hdf5')\n",
    "\n",
    "members = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked generalization with neural net meta model on blobs dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "    # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            # rename to avoid 'unuque layer name' issue\n",
    "            layer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "\n",
    "    # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.input for model in members]\n",
    "    \n",
    "    for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            \n",
    "    x = concatenate(ensemble_outputs)\n",
    "    x=layers.Flatten()(x)\n",
    "    #hidden = Dense(9, activation = 'relu')(flatten)\n",
    "    output = Dense(4, activation = 'softmax')(x)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ensemble model\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "vgg16_input (InputLayer)        (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_ensemble_ (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_3_ensemble_3_ensemble_ (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 9)  0           vgg16_input[0][0]                \n",
      "                                                                 ensemble_2_ensemble_2_ensemble_2_\n",
      "                                                                 ensemble_3_ensemble_3_ensemble_3_\n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 451584)       0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            1806340     flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,806,340\n",
      "Trainable params: 1,806,340\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='model_stacking.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a stacked model\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "    # prepare input data\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # encode output data\n",
    "    # fir model\n",
    "    model.fit(X, inputy, epochs=300, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 115.0517 - accuracy: 0.2680\n",
      "Epoch 2/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 35.3957 - accuracy: 0.3345\n",
      "Epoch 3/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 19.5085 - accuracy: 0.4431\n",
      "Epoch 4/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.2197 - accuracy: 0.4028\n",
      "Epoch 5/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 28.6315 - accuracy: 0.3730\n",
      "Epoch 6/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 28.2006 - accuracy: 0.3415\n",
      "Epoch 7/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 23.9146 - accuracy: 0.3713\n",
      "Epoch 8/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 43.3967 - accuracy: 0.3678\n",
      "Epoch 9/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.4681 - accuracy: 0.4378\n",
      "Epoch 10/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.2609 - accuracy: 0.3678\n",
      "Epoch 11/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.6809 - accuracy: 0.4063\n",
      "Epoch 12/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.9690 - accuracy: 0.4256\n",
      "Epoch 13/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.9142 - accuracy: 0.4028\n",
      "Epoch 14/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.5469 - accuracy: 0.4203\n",
      "Epoch 15/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 25.4375 - accuracy: 0.4186\n",
      "Epoch 16/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.3069 - accuracy: 0.4238\n",
      "Epoch 17/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 33.5601 - accuracy: 0.3730\n",
      "Epoch 18/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.2048 - accuracy: 0.4378\n",
      "Epoch 19/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.9686 - accuracy: 0.4501\n",
      "Epoch 20/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.6652 - accuracy: 0.5026\n",
      "Epoch 21/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.7682 - accuracy: 0.5061\n",
      "Epoch 22/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.7949 - accuracy: 0.4168\n",
      "Epoch 23/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 29.4752 - accuracy: 0.3975\n",
      "Epoch 24/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 26.5301 - accuracy: 0.4168\n",
      "Epoch 25/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 23.5620 - accuracy: 0.4746\n",
      "Epoch 26/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.4107 - accuracy: 0.4956\n",
      "Epoch 27/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.6259 - accuracy: 0.4711\n",
      "Epoch 28/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.2279 - accuracy: 0.4588\n",
      "Epoch 29/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.0218 - accuracy: 0.4869\n",
      "Epoch 30/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 33.1356 - accuracy: 0.3835\n",
      "Epoch 31/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.2236 - accuracy: 0.4676\n",
      "Epoch 32/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.2981 - accuracy: 0.5114\n",
      "Epoch 33/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.4714 - accuracy: 0.6217\n",
      "Epoch 34/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.5139 - accuracy: 0.5306\n",
      "Epoch 35/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 23.4607 - accuracy: 0.4431\n",
      "Epoch 36/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.4733 - accuracy: 0.5342\n",
      "Epoch 37/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.6683 - accuracy: 0.4904\n",
      "Epoch 38/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.9168 - accuracy: 0.4746\n",
      "Epoch 39/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.4502 - accuracy: 0.5079\n",
      "Epoch 40/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 28.0055 - accuracy: 0.4974\n",
      "Epoch 41/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 28.4898 - accuracy: 0.4448\n",
      "Epoch 42/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.1935 - accuracy: 0.4378\n",
      "Epoch 43/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 22.9909 - accuracy: 0.4694\n",
      "Epoch 44/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.0169 - accuracy: 0.5009\n",
      "Epoch 45/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.4416 - accuracy: 0.5377\n",
      "Epoch 46/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.3369 - accuracy: 0.5377\n",
      "Epoch 47/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.6073 - accuracy: 0.5114\n",
      "Epoch 48/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.6521 - accuracy: 0.5464\n",
      "Epoch 49/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.4904 - accuracy: 0.5534\n",
      "Epoch 50/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.2525 - accuracy: 0.5464\n",
      "Epoch 51/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.3226 - accuracy: 0.5236\n",
      "Epoch 52/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.3876 - accuracy: 0.5324\n",
      "Epoch 53/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.6246 - accuracy: 0.5131\n",
      "Epoch 54/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 41.1520 - accuracy: 0.4186\n",
      "Epoch 55/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 22.7216 - accuracy: 0.4904\n",
      "Epoch 56/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.7735 - accuracy: 0.5867\n",
      "Epoch 57/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.0883 - accuracy: 0.6690\n",
      "Epoch 58/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.9227 - accuracy: 0.5412 0s - loss: 7.6790 - accu\n",
      "Epoch 59/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.4228 - accuracy: 0.5534\n",
      "Epoch 60/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.0854 - accuracy: 0.5306\n",
      "Epoch 61/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2171 - accuracy: 0.5674\n",
      "Epoch 62/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.1608 - accuracy: 0.5131\n",
      "Epoch 63/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.3261 - accuracy: 0.5884\n",
      "Epoch 64/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.2341 - accuracy: 0.6602\n",
      "Epoch 65/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.2625 - accuracy: 0.4729\n",
      "Epoch 66/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 23.1053 - accuracy: 0.4939\n",
      "Epoch 67/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 26.6193 - accuracy: 0.4921\n",
      "Epoch 68/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.6901 - accuracy: 0.5482\n",
      "Epoch 69/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.0327 - accuracy: 0.5096\n",
      "Epoch 70/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 22.0553 - accuracy: 0.4904\n",
      "Epoch 71/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.0610 - accuracy: 0.5587\n",
      "Epoch 72/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.3207 - accuracy: 0.5236\n",
      "Epoch 73/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.9361 - accuracy: 0.5972\n",
      "Epoch 74/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.4998 - accuracy: 0.5814\n",
      "Epoch 75/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 27.8689 - accuracy: 0.4974\n",
      "Epoch 76/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.4239 - accuracy: 0.5447\n",
      "Epoch 77/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.5227 - accuracy: 0.5377\n",
      "Epoch 78/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.9267 - accuracy: 0.5482\n",
      "Epoch 79/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.9741 - accuracy: 0.5587\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 2s 3ms/step - loss: 14.1705 - accuracy: 0.5727\n",
      "Epoch 81/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.2422 - accuracy: 0.5061\n",
      "Epoch 82/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.9936 - accuracy: 0.5517\n",
      "Epoch 83/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.0052 - accuracy: 0.6725\n",
      "Epoch 84/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.3490 - accuracy: 0.6357\n",
      "Epoch 85/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.1248 - accuracy: 0.5517\n",
      "Epoch 86/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.8049 - accuracy: 0.6270\n",
      "Epoch 87/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.7892 - accuracy: 0.6305\n",
      "Epoch 88/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2961 - accuracy: 0.6042\n",
      "Epoch 89/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2477 - accuracy: 0.6095\n",
      "Epoch 90/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.8912 - accuracy: 0.6935\n",
      "Epoch 91/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.0203 - accuracy: 0.6620\n",
      "Epoch 92/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.7782 - accuracy: 0.6025\n",
      "Epoch 93/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.7731 - accuracy: 0.6497\n",
      "Epoch 94/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.8505 - accuracy: 0.5674\n",
      "Epoch 95/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.3756 - accuracy: 0.6182\n",
      "Epoch 96/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.3768 - accuracy: 0.5026\n",
      "Epoch 97/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.8352 - accuracy: 0.5709\n",
      "Epoch 98/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.0316 - accuracy: 0.5814\n",
      "Epoch 99/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 34.8017 - accuracy: 0.4308\n",
      "Epoch 100/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.3562 - accuracy: 0.5639\n",
      "Epoch 101/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.0009 - accuracy: 0.5342\n",
      "Epoch 102/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.0906 - accuracy: 0.5552\n",
      "Epoch 103/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.6556 - accuracy: 0.6725\n",
      "Epoch 104/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.4816 - accuracy: 0.6760\n",
      "Epoch 105/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.0761 - accuracy: 0.6462\n",
      "Epoch 106/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.2921 - accuracy: 0.6305\n",
      "Epoch 107/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.3307 - accuracy: 0.5884\n",
      "Epoch 108/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.5774 - accuracy: 0.6357\n",
      "Epoch 109/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.0047 - accuracy: 0.6077\n",
      "Epoch 110/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.9579 - accuracy: 0.7110\n",
      "Epoch 111/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.1263 - accuracy: 0.6480\n",
      "Epoch 112/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.7852 - accuracy: 0.7391\n",
      "Epoch 113/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.1990 - accuracy: 0.4799\n",
      "Epoch 114/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.6305 - accuracy: 0.5149\n",
      "Epoch 115/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 22.3195 - accuracy: 0.5604\n",
      "Epoch 116/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.9821 - accuracy: 0.5902\n",
      "Epoch 117/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.0165 - accuracy: 0.5814\n",
      "Epoch 118/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2824 - accuracy: 0.6480\n",
      "Epoch 119/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.2664 - accuracy: 0.5184\n",
      "Epoch 120/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 19.7778 - accuracy: 0.5271\n",
      "Epoch 121/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.8393 - accuracy: 0.7250\n",
      "Epoch 122/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.8405 - accuracy: 0.5972\n",
      "Epoch 123/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.7439 - accuracy: 0.6988\n",
      "Epoch 124/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.3324 - accuracy: 0.7093\n",
      "Epoch 125/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.3380 - accuracy: 0.5639\n",
      "Epoch 126/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 26.8272 - accuracy: 0.4904\n",
      "Epoch 127/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.2072 - accuracy: 0.6515\n",
      "Epoch 128/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.9701 - accuracy: 0.6988: 1s -\n",
      "Epoch 129/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.7140 - accuracy: 0.6830\n",
      "Epoch 130/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.9291 - accuracy: 0.5884\n",
      "Epoch 131/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 26.8825 - accuracy: 0.5219\n",
      "Epoch 132/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.9008 - accuracy: 0.6305\n",
      "Epoch 133/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.6360 - accuracy: 0.6602\n",
      "Epoch 134/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.3855 - accuracy: 0.5569\n",
      "Epoch 135/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.3461 - accuracy: 0.6515\n",
      "Epoch 136/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.9955 - accuracy: 0.5867\n",
      "Epoch 137/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.8277 - accuracy: 0.7023\n",
      "Epoch 138/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.5887 - accuracy: 0.5744\n",
      "Epoch 139/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.6629 - accuracy: 0.6918\n",
      "Epoch 140/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.5190 - accuracy: 0.6655\n",
      "Epoch 141/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.1065 - accuracy: 0.7005\n",
      "Epoch 142/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.4947 - accuracy: 0.6462: 0s - loss: 10.9859 - ac\n",
      "Epoch 143/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.7421 - accuracy: 0.6480\n",
      "Epoch 144/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.4795 - accuracy: 0.8021\n",
      "Epoch 145/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.9438 - accuracy: 0.7531\n",
      "Epoch 146/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.1532 - accuracy: 0.6585\n",
      "Epoch 147/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.6419 - accuracy: 0.6322\n",
      "Epoch 148/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.9322 - accuracy: 0.7128\n",
      "Epoch 149/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.6060 - accuracy: 0.7268: 0s - loss: 5.3406 - accu\n",
      "Epoch 150/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.0581 - accuracy: 0.7706\n",
      "Epoch 151/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.5362 - accuracy: 0.6778\n",
      "Epoch 152/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 26.4448 - accuracy: 0.5604\n",
      "Epoch 153/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.2608 - accuracy: 0.6200\n",
      "Epoch 154/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.8738 - accuracy: 0.7250\n",
      "Epoch 155/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.2224 - accuracy: 0.7583\n",
      "Epoch 156/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.4412 - accuracy: 0.7163\n",
      "Epoch 157/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.1526 - accuracy: 0.8459\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 2s 3ms/step - loss: 3.4949 - accuracy: 0.7863\n",
      "Epoch 159/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.1425 - accuracy: 0.7285\n",
      "Epoch 160/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.8910 - accuracy: 0.6743\n",
      "Epoch 161/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.7215 - accuracy: 0.6883\n",
      "Epoch 162/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.2704 - accuracy: 0.5727\n",
      "Epoch 163/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 15.9330 - accuracy: 0.6305\n",
      "Epoch 164/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.5144 - accuracy: 0.5797\n",
      "Epoch 165/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.4792 - accuracy: 0.6427\n",
      "Epoch 166/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.5682 - accuracy: 0.6585\n",
      "Epoch 167/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.7376 - accuracy: 0.5569\n",
      "Epoch 168/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 19.5073 - accuracy: 0.5972\n",
      "Epoch 169/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.5709 - accuracy: 0.7198\n",
      "Epoch 170/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.6169 - accuracy: 0.7128\n",
      "Epoch 171/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.8962 - accuracy: 0.6865\n",
      "Epoch 172/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.8656 - accuracy: 0.7706\n",
      "Epoch 173/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.8138 - accuracy: 0.7373\n",
      "Epoch 174/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2994 - accuracy: 0.6375\n",
      "Epoch 175/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.4704 - accuracy: 0.6532\n",
      "Epoch 176/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.8311 - accuracy: 0.7110\n",
      "Epoch 177/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.2237 - accuracy: 0.8336\n",
      "Epoch 178/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.3627 - accuracy: 0.8056\n",
      "Epoch 179/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.2873 - accuracy: 0.7758\n",
      "Epoch 180/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.0188 - accuracy: 0.6025\n",
      "Epoch 181/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.8520 - accuracy: 0.6550\n",
      "Epoch 182/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.9250 - accuracy: 0.6848\n",
      "Epoch 183/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.3593 - accuracy: 0.7933\n",
      "Epoch 184/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.6710 - accuracy: 0.6953\n",
      "Epoch 185/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.6165 - accuracy: 0.6112\n",
      "Epoch 186/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.0796 - accuracy: 0.7566\n",
      "Epoch 187/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.2238 - accuracy: 0.7110\n",
      "Epoch 188/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.5365 - accuracy: 0.6760\n",
      "Epoch 189/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.6257 - accuracy: 0.7881\n",
      "Epoch 190/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.2116 - accuracy: 0.5989\n",
      "Epoch 191/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.1806 - accuracy: 0.6462\n",
      "Epoch 192/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.0659 - accuracy: 0.6620\n",
      "Epoch 193/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.4891 - accuracy: 0.6340\n",
      "Epoch 194/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.2414 - accuracy: 0.6655\n",
      "Epoch 195/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.7865 - accuracy: 0.5814\n",
      "Epoch 196/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.6709 - accuracy: 0.7198\n",
      "Epoch 197/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.6226 - accuracy: 0.7198\n",
      "Epoch 198/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.2861 - accuracy: 0.6725\n",
      "Epoch 199/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 17.4338 - accuracy: 0.6007\n",
      "Epoch 200/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.1923 - accuracy: 0.6602\n",
      "Epoch 201/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 28.5667 - accuracy: 0.6112\n",
      "Epoch 202/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.1631 - accuracy: 0.6462\n",
      "Epoch 203/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.7898 - accuracy: 0.5902\n",
      "Epoch 204/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.1990 - accuracy: 0.7513\n",
      "Epoch 205/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.8381 - accuracy: 0.7461\n",
      "Epoch 206/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.8802 - accuracy: 0.7005\n",
      "Epoch 207/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.5579 - accuracy: 0.6883\n",
      "Epoch 208/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.6350 - accuracy: 0.8056\n",
      "Epoch 209/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.0516 - accuracy: 0.7373\n",
      "Epoch 210/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.8786 - accuracy: 0.7180\n",
      "Epoch 211/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 24.3507 - accuracy: 0.5674\n",
      "Epoch 212/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.3816 - accuracy: 0.6725\n",
      "Epoch 213/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.6918 - accuracy: 0.6305\n",
      "Epoch 214/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.8427 - accuracy: 0.6935\n",
      "Epoch 215/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.5251 - accuracy: 0.7128\n",
      "Epoch 216/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.2127 - accuracy: 0.6918\n",
      "Epoch 217/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.4614 - accuracy: 0.6900\n",
      "Epoch 218/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.2024 - accuracy: 0.6988\n",
      "Epoch 219/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 29.9287 - accuracy: 0.5534\n",
      "Epoch 220/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.7098 - accuracy: 0.6252\n",
      "Epoch 221/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.2418 - accuracy: 0.8091\n",
      "Epoch 222/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.7969 - accuracy: 0.8074\n",
      "Epoch 223/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.3738 - accuracy: 0.7320\n",
      "Epoch 224/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.7167 - accuracy: 0.7671\n",
      "Epoch 225/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.0119 - accuracy: 0.7793\n",
      "Epoch 226/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 23.7477 - accuracy: 0.5657\n",
      "Epoch 227/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 20.4359 - accuracy: 0.6270\n",
      "Epoch 228/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.8963 - accuracy: 0.8196\n",
      "Epoch 229/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.6883 - accuracy: 0.8494\n",
      "Epoch 230/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.4120 - accuracy: 0.7846\n",
      "Epoch 231/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 8.4076 - accuracy: 0.7443\n",
      "Epoch 232/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.2873 - accuracy: 0.7093\n",
      "Epoch 233/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.3071 - accuracy: 0.7671\n",
      "Epoch 234/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.9179 - accuracy: 0.8091\n",
      "Epoch 235/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.5024 - accuracy: 0.6848\n",
      "Epoch 236/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.3904 - accuracy: 0.7583\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 2s 3ms/step - loss: 8.4477 - accuracy: 0.7356\n",
      "Epoch 238/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.9853 - accuracy: 0.6935\n",
      "Epoch 239/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 9.8510 - accuracy: 0.6865\n",
      "Epoch 240/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.1962 - accuracy: 0.7601\n",
      "Epoch 241/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.1477 - accuracy: 0.7758\n",
      "Epoch 242/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.3193 - accuracy: 0.7793\n",
      "Epoch 243/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.5622 - accuracy: 0.7285\n",
      "Epoch 244/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.9348 - accuracy: 0.7846\n",
      "Epoch 245/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.0225 - accuracy: 0.7443\n",
      "Epoch 246/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 13.9663 - accuracy: 0.7163\n",
      "Epoch 247/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.5091 - accuracy: 0.6883\n",
      "Epoch 248/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 19.4821 - accuracy: 0.6270\n",
      "Epoch 249/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 27.0530 - accuracy: 0.5779\n",
      "Epoch 250/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.3218 - accuracy: 0.6620\n",
      "Epoch 251/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.5958 - accuracy: 0.6778\n",
      "Epoch 252/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.6227 - accuracy: 0.6865\n",
      "Epoch 253/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.0887 - accuracy: 0.7391\n",
      "Epoch 254/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.5621 - accuracy: 0.6918\n",
      "Epoch 255/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.7791 - accuracy: 0.6497\n",
      "Epoch 256/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.2196 - accuracy: 0.7671\n",
      "Epoch 257/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.6213 - accuracy: 0.8459\n",
      "Epoch 258/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.1495 - accuracy: 0.7828\n",
      "Epoch 259/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.7760 - accuracy: 0.6813\n",
      "Epoch 260/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.6105 - accuracy: 0.6883\n",
      "Epoch 261/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.9044 - accuracy: 0.8406\n",
      "Epoch 262/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.0184 - accuracy: 0.8371\n",
      "Epoch 263/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.5856 - accuracy: 0.7566\n",
      "Epoch 264/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.2210 - accuracy: 0.7706\n",
      "Epoch 265/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.1247 - accuracy: 0.7863\n",
      "Epoch 266/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 18.2880 - accuracy: 0.6200\n",
      "Epoch 267/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 36.1466 - accuracy: 0.5289\n",
      "Epoch 268/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.5736 - accuracy: 0.7233\n",
      "Epoch 269/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.5335 - accuracy: 0.8564\n",
      "Epoch 270/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.2282 - accuracy: 0.7408\n",
      "Epoch 271/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.6759 - accuracy: 0.8161\n",
      "Epoch 272/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.8248 - accuracy: 0.8687\n",
      "Epoch 273/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.9682 - accuracy: 0.8056\n",
      "Epoch 274/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.2980 - accuracy: 0.7058\n",
      "Epoch 275/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.6451 - accuracy: 0.7058\n",
      "Epoch 276/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 11.5127 - accuracy: 0.6900\n",
      "Epoch 277/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 10.4742 - accuracy: 0.6970\n",
      "Epoch 278/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.1178 - accuracy: 0.6918\n",
      "Epoch 279/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.3790 - accuracy: 0.7671\n",
      "Epoch 280/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.3237 - accuracy: 0.8581\n",
      "Epoch 281/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 1.9070 - accuracy: 0.8932\n",
      "Epoch 282/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.9994 - accuracy: 0.7898\n",
      "Epoch 283/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 14.2793 - accuracy: 0.6795\n",
      "Epoch 284/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.3618 - accuracy: 0.8757\n",
      "Epoch 285/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 16.5807 - accuracy: 0.6848\n",
      "Epoch 286/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 12.3554 - accuracy: 0.6673\n",
      "Epoch 287/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 21.7195 - accuracy: 0.6130\n",
      "Epoch 288/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.3598 - accuracy: 0.7671\n",
      "Epoch 289/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.6237 - accuracy: 0.7986\n",
      "Epoch 290/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 7.7476 - accuracy: 0.7285\n",
      "Epoch 291/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 5.4674 - accuracy: 0.7811\n",
      "Epoch 292/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 2.3988 - accuracy: 0.8651\n",
      "Epoch 293/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 1.6602 - accuracy: 0.8932\n",
      "Epoch 294/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 1.5883 - accuracy: 0.9072\n",
      "Epoch 295/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.5713 - accuracy: 0.8389\n",
      "Epoch 296/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 4.8832 - accuracy: 0.7968\n",
      "Epoch 297/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 6.0363 - accuracy: 0.7881\n",
      "Epoch 298/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.6069 - accuracy: 0.8284\n",
      "Epoch 299/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.6878 - accuracy: 0.8021\n",
      "Epoch 300/300\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 3.1398 - accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# fit stacked model on test dataset\n",
    "fit_stacked_model(stacked_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with a stacked model\n",
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # make prediction\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Test Accracy : 0.891\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate\n",
    "yhat = predict_stacked_model(stacked_model, X)\n",
    "\n",
    "y_label=np.argmax(y,axis=1)\n",
    "predict=np.argmax(yhat,axis=1)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_label, predict)\n",
    "print('Stacked Test Accracy : %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894989314025899"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC 출력하기\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "roc_auc_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,   1,  16,   0],\n",
       "       [  9, 103,  21,   3],\n",
       "       [  1,   0, 128,   0],\n",
       "       [  1,   0,  10, 160]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix =confusion_matrix(y_label, predict)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x290da05fa88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "index = ['Calc_Benign','Calc_Malignant','mass_Benign','mass_Malignant']  \n",
    "columns = ['Calc_Benign','Calc_Malignant','mass_Benign','mass_Malignant']  \n",
    "cm_df = pd.DataFrame(matrix,columns,index)                      \n",
    "plt.figure(figsize=(15,10)) \n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
