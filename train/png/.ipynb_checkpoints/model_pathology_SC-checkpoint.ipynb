{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train_double_input/benign_malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) #수평방향 뒤집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1370 images belonging to 2 classes.\n",
      "Found 342 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
    "        target_size=(224,224),\n",
    "        batch_size=32,\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model.output\n",
    "x=layers.Flatten()(x)\n",
    "x=Dense(1024, activation='relu')(x)\n",
    "x=Dense(512, activation='relu')(x)\n",
    "x=Dense(264, activation='relu')(x)\n",
    "outputs=Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "additional_model=Model(inputs=model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='png_model_pathology_resnet2.hdf5', \n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-3),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/42 [==============================] - 34s 781ms/step - loss: 2.1363 - acc: 0.5288 - auc: 0.5443 - precision: 0.5386 - recall: 0.5489 - f1score: nan - val_loss: 0.7174 - val_acc: 0.4912 - val_auc: 0.5246 - val_precision: 0.5228 - val_recall: 0.5359 - val_f1score: 0.3272\n",
      "Epoch 2/5\n",
      "43/42 [==============================] - 15s 353ms/step - loss: 0.7017 - acc: 0.5190 - auc: 0.5211 - precision: 0.5191 - recall: 0.5196 - f1score: 0.3324 - val_loss: 0.6944 - val_acc: 0.5088 - val_auc: 0.5196 - val_precision: 0.5198 - val_recall: 0.5165 - val_f1score: 0.3336\n",
      "Epoch 3/5\n",
      "43/42 [==============================] - 15s 354ms/step - loss: 0.6968 - acc: 0.5164 - auc: 0.5179 - precision: 0.5180 - recall: 0.5170 - f1score: 0.3332 - val_loss: 0.6932 - val_acc: 0.5088 - val_auc: 0.5181 - val_precision: 0.5182 - val_recall: 0.5197 - val_f1score: 0.3337\n",
      "Epoch 4/5\n",
      "43/42 [==============================] - 15s 353ms/step - loss: 0.6976 - acc: 0.5223 - auc: 0.5204 - precision: 0.5177 - recall: 0.5241 - f1score: 0.3338 - val_loss: 0.6927 - val_acc: 0.5088 - val_auc: 0.5217 - val_precision: 0.5180 - val_recall: 0.5271 - val_f1score: 0.3337\n",
      "Epoch 5/5\n",
      "43/42 [==============================] - 15s 354ms/step - loss: 0.7060 - acc: 0.5197 - auc: 0.5230 - precision: 0.5184 - recall: 0.5272 - f1score: 0.3319 - val_loss: 0.6925 - val_acc: 0.5088 - val_auc: 0.5224 - val_precision: 0.5174 - val_recall: 0.5239 - val_f1score: 0.3336\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples /32,\n",
    "      epochs=5,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples/32,\n",
    "      callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in additional_model.layers[:46]:\n",
    "    layer.trainable=False\n",
    "\n",
    "for layer in additional_model.layers[46:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/42 [==============================] - 25s 570ms/step - loss: 0.6940 - acc: 0.5124 - auc_1: 0.5061 - precision_1: 0.4954 - recall_1: 0.4869 - f1score: 0.3333 - val_loss: 0.6933 - val_acc: 0.5088 - val_auc_1: 0.5187 - val_precision_1: 0.5090 - val_recall_1: 0.4998 - val_f1score: 0.3336\n",
      "Epoch 2/20\n",
      "43/42 [==============================] - 15s 353ms/step - loss: 0.6898 - acc: 0.5584 - auc_1: 0.5379 - precision_1: 0.5267 - recall_1: 0.5189 - f1score: 0.3349 - val_loss: 0.6931 - val_acc: 0.5000 - val_auc_1: 0.5435 - val_precision_1: 0.5293 - val_recall_1: 0.5532 - val_f1score: 0.3336\n",
      "Epoch 3/20\n",
      "43/42 [==============================] - 17s 385ms/step - loss: 0.6790 - acc: 0.5653 - auc_1: 0.5535 - precision_1: 0.5329 - recall_1: 0.5716 - f1score: 0.3377 - val_loss: 0.6931 - val_acc: 0.5000 - val_auc_1: 0.5580 - val_precision_1: 0.5347 - val_recall_1: 0.5864 - val_f1score: 0.3336\n",
      "Epoch 4/20\n",
      "43/42 [==============================] - 17s 386ms/step - loss: 0.6650 - acc: 0.5938 - auc_1: 0.5689 - precision_1: 0.5399 - recall_1: 0.5983 - f1score: 0.3414 - val_loss: 0.6936 - val_acc: 0.4912 - val_auc_1: 0.5746 - val_precision_1: 0.5434 - val_recall_1: 0.5946 - val_f1score: 0.3337\n",
      "Epoch 5/20\n",
      "43/42 [==============================] - 17s 387ms/step - loss: 0.6604 - acc: 0.6040 - auc_1: 0.5827 - precision_1: 0.5483 - recall_1: 0.5934 - f1score: 0.3427 - val_loss: 0.6932 - val_acc: 0.4912 - val_auc_1: 0.5859 - val_precision_1: 0.5506 - val_recall_1: 0.5902 - val_f1score: 0.3337\n",
      "Epoch 6/20\n",
      "43/42 [==============================] - 17s 384ms/step - loss: 0.6527 - acc: 0.6109 - auc_1: 0.5921 - precision_1: 0.5547 - recall_1: 0.5902 - f1score: 0.3454 - val_loss: 0.6922 - val_acc: 0.4912 - val_auc_1: 0.5949 - val_precision_1: 0.5565 - val_recall_1: 0.5880 - val_f1score: 0.3337\n",
      "Epoch 7/20\n",
      "43/42 [==============================] - 15s 356ms/step - loss: 0.6477 - acc: 0.6321 - auc_1: 0.5997 - precision_1: 0.5601 - recall_1: 0.5891 - f1score: 0.3469 - val_loss: 0.6938 - val_acc: 0.4912 - val_auc_1: 0.6037 - val_precision_1: 0.5627 - val_recall_1: 0.5896 - val_f1score: 0.3338\n",
      "Epoch 8/20\n",
      "43/42 [==============================] - 17s 385ms/step - loss: 0.6374 - acc: 0.6391 - auc_1: 0.6078 - precision_1: 0.5657 - recall_1: 0.5914 - f1score: 0.3495 - val_loss: 0.6908 - val_acc: 0.4912 - val_auc_1: 0.6123 - val_precision_1: 0.5684 - val_recall_1: 0.5928 - val_f1score: 0.3338\n",
      "Epoch 9/20\n",
      "43/42 [==============================] - 15s 355ms/step - loss: 0.6363 - acc: 0.6296 - auc_1: 0.6154 - precision_1: 0.5706 - recall_1: 0.5936 - f1score: 0.3506 - val_loss: 0.6932 - val_acc: 0.4912 - val_auc_1: 0.6178 - val_precision_1: 0.5722 - val_recall_1: 0.5939 - val_f1score: 0.3338\n",
      "Epoch 10/20\n",
      "43/42 [==============================] - 17s 386ms/step - loss: 0.6314 - acc: 0.6544 - auc_1: 0.6218 - precision_1: 0.5753 - recall_1: 0.5961 - f1score: 0.3516 - val_loss: 0.6870 - val_acc: 0.4912 - val_auc_1: 0.6242 - val_precision_1: 0.5771 - val_recall_1: 0.5966 - val_f1score: 0.3338\n",
      "Epoch 11/20\n",
      "43/42 [==============================] - 15s 355ms/step - loss: 0.6193 - acc: 0.6628 - auc_1: 0.6278 - precision_1: 0.5797 - recall_1: 0.5983 - f1score: 0.3546 - val_loss: 0.6903 - val_acc: 0.4912 - val_auc_1: 0.6305 - val_precision_1: 0.5815 - val_recall_1: 0.5992 - val_f1score: 0.3338\n",
      "Epoch 12/20\n",
      "43/42 [==============================] - 16s 384ms/step - loss: 0.6129 - acc: 0.6507 - auc_1: 0.6339 - precision_1: 0.5837 - recall_1: 0.6007 - f1score: 0.3566 - val_loss: 0.6917 - val_acc: 0.4912 - val_auc_1: 0.6358 - val_precision_1: 0.5848 - val_recall_1: 0.6015 - val_f1score: 0.3338\n",
      "Epoch 13/20\n",
      "43/42 [==============================] - 17s 386ms/step - loss: 0.6018 - acc: 0.6712 - auc_1: 0.6386 - precision_1: 0.5865 - recall_1: 0.6025 - f1score: 0.3587 - val_loss: 0.6953 - val_acc: 0.4912 - val_auc_1: 0.6416 - val_precision_1: 0.5885 - val_recall_1: 0.6037 - val_f1score: 0.3338\n",
      "Epoch 14/20\n",
      "43/42 [==============================] - 17s 386ms/step - loss: 0.5964 - acc: 0.6810 - auc_1: 0.6440 - precision_1: 0.5904 - recall_1: 0.6050 - f1score: 0.3604 - val_loss: 0.6979 - val_acc: 0.4912 - val_auc_1: 0.6469 - val_precision_1: 0.5922 - val_recall_1: 0.6061 - val_f1score: 0.3332\n",
      "Epoch 15/20\n",
      "43/42 [==============================] - 17s 385ms/step - loss: 0.5998 - acc: 0.6763 - auc_1: 0.6497 - precision_1: 0.5942 - recall_1: 0.6078 - f1score: 0.3619 - val_loss: 0.6841 - val_acc: 0.4912 - val_auc_1: 0.6514 - val_precision_1: 0.5954 - val_recall_1: 0.6087 - val_f1score: 0.3327\n",
      "Epoch 16/20\n",
      "43/42 [==============================] - 15s 356ms/step - loss: 0.5894 - acc: 0.6905 - auc_1: 0.6541 - precision_1: 0.5974 - recall_1: 0.6103 - f1score: 0.3627 - val_loss: 0.6756 - val_acc: 0.4912 - val_auc_1: 0.6564 - val_precision_1: 0.5990 - val_recall_1: 0.6116 - val_f1score: 0.3326\n",
      "Epoch 17/20\n",
      "43/42 [==============================] - 15s 354ms/step - loss: 0.5728 - acc: 0.7153 - auc_1: 0.6597 - precision_1: 0.6013 - recall_1: 0.6134 - f1score: 0.3678 - val_loss: 0.7732 - val_acc: 0.4912 - val_auc_1: 0.6620 - val_precision_1: 0.6032 - val_recall_1: 0.6149 - val_f1score: 0.3276\n",
      "Epoch 18/20\n",
      "43/42 [==============================] - 17s 384ms/step - loss: 0.5593 - acc: 0.7109 - auc_1: 0.6642 - precision_1: 0.6048 - recall_1: 0.6162 - f1score: 0.3712 - val_loss: 0.7894 - val_acc: 0.4912 - val_auc_1: 0.6668 - val_precision_1: 0.6067 - val_recall_1: 0.6177 - val_f1score: 0.3282\n",
      "Epoch 19/20\n",
      "43/42 [==============================] - 17s 384ms/step - loss: 0.5494 - acc: 0.7212 - auc_1: 0.6696 - precision_1: 0.6087 - recall_1: 0.6195 - f1score: 0.3748 - val_loss: 0.7580 - val_acc: 0.4912 - val_auc_1: 0.6718 - val_precision_1: 0.6102 - val_recall_1: 0.6208 - val_f1score: 0.3322\n",
      "Epoch 20/20\n",
      "43/42 [==============================] - 16s 383ms/step - loss: 0.5638 - acc: 0.7066 - auc_1: 0.6740 - precision_1: 0.6117 - recall_1: 0.6220 - f1score: 0.3707 - val_loss: 1.1671 - val_acc: 0.4912 - val_auc_1: 0.6747 - val_precision_1: 0.6128 - val_recall_1: 0.6229 - val_f1score: 0.3131\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples /32,\n",
    "      epochs=20,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples/32,\n",
    "      callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in additional_model.layers:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/42 [==============================] - 29s 681ms/step - loss: 0.5081 - acc: 0.7679 - auc_2: 0.8497 - precision_2: 0.7863 - recall_2: 0.7898 - f1score: 0.3820 - val_loss: 0.7914 - val_acc: 0.4912 - val_auc_2: 0.8106 - val_precision_2: 0.7351 - val_recall_2: 0.7354 - val_f1score: 0.3344\n",
      "Epoch 2/100\n",
      "43/42 [==============================] - 16s 361ms/step - loss: 0.4903 - acc: 0.7639 - auc_2: 0.8085 - precision_2: 0.7284 - recall_2: 0.7294 - f1score: 0.3863 - val_loss: 0.6613 - val_acc: 0.4985 - val_auc_2: 0.8062 - val_precision_2: 0.7218 - val_recall_2: 0.7226 - val_f1score: 0.3437\n",
      "Epoch 3/100\n",
      "43/42 [==============================] - 16s 362ms/step - loss: 0.4976 - acc: 0.7522 - auc_2: 0.8036 - precision_2: 0.7180 - recall_2: 0.7202 - f1score: 0.3862 - val_loss: 0.7001 - val_acc: 0.4751 - val_auc_2: 0.8027 - val_precision_2: 0.7122 - val_recall_2: 0.7184 - val_f1score: 0.3360\n",
      "Epoch 4/100\n",
      "43/42 [==============================] - 17s 394ms/step - loss: 0.4790 - acc: 0.7653 - auc_2: 0.8036 - precision_2: 0.7105 - recall_2: 0.7182 - f1score: 0.3904 - val_loss: 0.7108 - val_acc: 0.4605 - val_auc_2: 0.8046 - val_precision_2: 0.7089 - val_recall_2: 0.7181 - val_f1score: 0.3340\n",
      "Epoch 5/100\n",
      "43/42 [==============================] - 17s 397ms/step - loss: 0.4684 - acc: 0.7872 - auc_2: 0.8070 - precision_2: 0.7112 - recall_2: 0.7211 - f1score: 0.3928 - val_loss: 0.6915 - val_acc: 0.4561 - val_auc_2: 0.8074 - val_precision_2: 0.7111 - val_recall_2: 0.7200 - val_f1score: 0.3333\n",
      "Epoch 6/100\n",
      "43/42 [==============================] - 17s 397ms/step - loss: 0.4910 - acc: 0.7602 - auc_2: 0.8068 - precision_2: 0.7100 - recall_2: 0.7190 - f1score: 0.3891 - val_loss: 0.7850 - val_acc: 0.4693 - val_auc_2: 0.8055 - val_precision_2: 0.7086 - val_recall_2: 0.7178 - val_f1score: 0.3320\n",
      "Epoch 7/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4929 - acc: 0.7529 - auc_2: 0.8054 - precision_2: 0.7083 - recall_2: 0.7174 - f1score: 0.3885 - val_loss: 0.7060 - val_acc: 0.4868 - val_auc_2: 0.8038 - val_precision_2: 0.7070 - val_recall_2: 0.7158 - val_f1score: 0.3324\n",
      "Epoch 8/100\n",
      "43/42 [==============================] - 17s 397ms/step - loss: 0.4696 - acc: 0.7763 - auc_2: 0.8057 - precision_2: 0.7088 - recall_2: 0.7175 - f1score: 0.3935 - val_loss: 0.7503 - val_acc: 0.5102 - val_auc_2: 0.8053 - val_precision_2: 0.7087 - val_recall_2: 0.7173 - val_f1score: 0.3320\n",
      "Epoch 9/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4763 - acc: 0.7679 - auc_2: 0.8058 - precision_2: 0.7093 - recall_2: 0.7176 - f1score: 0.3927 - val_loss: 0.6936 - val_acc: 0.4912 - val_auc_2: 0.8056 - val_precision_2: 0.7092 - val_recall_2: 0.7171 - val_f1score: 0.3308\n",
      "Epoch 10/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4609 - acc: 0.7828 - auc_2: 0.8064 - precision_2: 0.7101 - recall_2: 0.7179 - f1score: 0.3951 - val_loss: 0.7561 - val_acc: 0.4474 - val_auc_2: 0.8067 - val_precision_2: 0.7101 - val_recall_2: 0.7177 - val_f1score: 0.3280\n",
      "Epoch 11/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4503 - acc: 0.7828 - auc_2: 0.8077 - precision_2: 0.7107 - recall_2: 0.7179 - f1score: 0.3976 - val_loss: 0.7525 - val_acc: 0.4839 - val_auc_2: 0.8078 - val_precision_2: 0.7108 - val_recall_2: 0.7178 - val_f1score: 0.3271\n",
      "Epoch 12/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4584 - acc: 0.7938 - auc_2: 0.8090 - precision_2: 0.7121 - recall_2: 0.7190 - f1score: 0.3979 - val_loss: 0.6853 - val_acc: 0.4664 - val_auc_2: 0.8088 - val_precision_2: 0.7123 - val_recall_2: 0.7189 - val_f1score: 0.3247\n",
      "Epoch 13/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4458 - acc: 0.7931 - auc_2: 0.8101 - precision_2: 0.7135 - recall_2: 0.7198 - f1score: 0.4008 - val_loss: 0.6822 - val_acc: 0.4868 - val_auc_2: 0.8103 - val_precision_2: 0.7137 - val_recall_2: 0.7198 - val_f1score: 0.3212\n",
      "Epoch 14/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4458 - acc: 0.7942 - auc_2: 0.8109 - precision_2: 0.7147 - recall_2: 0.7205 - f1score: 0.4006 - val_loss: 0.8080 - val_acc: 0.5161 - val_auc_2: 0.8114 - val_precision_2: 0.7154 - val_recall_2: 0.7213 - val_f1score: 0.3215\n",
      "Epoch 15/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4413 - acc: 0.8026 - auc_2: 0.8122 - precision_2: 0.7165 - recall_2: 0.7222 - f1score: 0.4013 - val_loss: 0.8142 - val_acc: 0.4825 - val_auc_2: 0.8121 - val_precision_2: 0.7171 - val_recall_2: 0.7227 - val_f1score: 0.3163\n",
      "Epoch 16/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4209 - acc: 0.8164 - auc_2: 0.8131 - precision_2: 0.7184 - recall_2: 0.7236 - f1score: 0.4054 - val_loss: 0.8085 - val_acc: 0.4708 - val_auc_2: 0.8137 - val_precision_2: 0.7191 - val_recall_2: 0.7243 - val_f1score: 0.3186\n",
      "Epoch 17/100\n",
      "43/42 [==============================] - 17s 394ms/step - loss: 0.4180 - acc: 0.8077 - auc_2: 0.8147 - precision_2: 0.7200 - recall_2: 0.7250 - f1score: 0.4062 - val_loss: 0.8155 - val_acc: 0.4708 - val_auc_2: 0.8146 - val_precision_2: 0.7203 - val_recall_2: 0.7250 - val_f1score: 0.3129\n",
      "Epoch 18/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4219 - acc: 0.8026 - auc_2: 0.8152 - precision_2: 0.7208 - recall_2: 0.7254 - f1score: 0.4058 - val_loss: 0.8020 - val_acc: 0.5029 - val_auc_2: 0.8155 - val_precision_2: 0.7214 - val_recall_2: 0.7259 - val_f1score: 0.3162\n",
      "Epoch 19/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4320 - acc: 0.8058 - auc_2: 0.8162 - precision_2: 0.7223 - recall_2: 0.7267 - f1score: 0.4044 - val_loss: 0.8252 - val_acc: 0.5161 - val_auc_2: 0.8163 - val_precision_2: 0.7227 - val_recall_2: 0.7271 - val_f1score: 0.3210\n",
      "Epoch 20/100\n",
      "43/42 [==============================] - 17s 395ms/step - loss: 0.4222 - acc: 0.8055 - auc_2: 0.8169 - precision_2: 0.7235 - recall_2: 0.7279 - f1score: 0.4060 - val_loss: 0.8404 - val_acc: 0.5058 - val_auc_2: 0.8172 - val_precision_2: 0.7239 - val_recall_2: 0.7284 - val_f1score: 0.3177\n",
      "Epoch 21/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4261 - acc: 0.8026 - auc_2: 0.8176 - precision_2: 0.7246 - recall_2: 0.7288 - f1score: 0.4054 - val_loss: 0.5513 - val_acc: 0.5249 - val_auc_2: 0.8177 - val_precision_2: 0.7247 - val_recall_2: 0.7290 - val_f1score: 0.3264\n",
      "Epoch 22/100\n",
      "43/42 [==============================] - 16s 363ms/step - loss: 0.4104 - acc: 0.8036 - auc_2: 0.8185 - precision_2: 0.7254 - recall_2: 0.7296 - f1score: 0.4082 - val_loss: 0.7148 - val_acc: 0.5599 - val_auc_2: 0.8190 - val_precision_2: 0.7261 - val_recall_2: 0.7301 - val_f1score: 0.3259\n",
      "Epoch 23/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4159 - acc: 0.8109 - auc_2: 0.8196 - precision_2: 0.7270 - recall_2: 0.7309 - f1score: 0.4071 - val_loss: 0.8714 - val_acc: 0.5526 - val_auc_2: 0.8198 - val_precision_2: 0.7276 - val_recall_2: 0.7315 - val_f1score: 0.3241\n",
      "Epoch 24/100\n",
      "43/42 [==============================] - 17s 398ms/step - loss: 0.4208 - acc: 0.8099 - auc_2: 0.8202 - precision_2: 0.7283 - recall_2: 0.7321 - f1score: 0.4064 - val_loss: 0.6790 - val_acc: 0.5789 - val_auc_2: 0.8205 - val_precision_2: 0.7289 - val_recall_2: 0.7327 - val_f1score: 0.3331\n",
      "Epoch 25/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.4177 - acc: 0.7996 - auc_2: 0.8211 - precision_2: 0.7296 - recall_2: 0.7334 - f1score: 0.4066 - val_loss: 0.7270 - val_acc: 0.5687 - val_auc_2: 0.8213 - val_precision_2: 0.7299 - val_recall_2: 0.7337 - val_f1score: 0.3326\n",
      "Epoch 26/100\n",
      "43/42 [==============================] - 17s 397ms/step - loss: 0.4018 - acc: 0.8161 - auc_2: 0.8222 - precision_2: 0.7307 - recall_2: 0.7346 - f1score: 0.4113 - val_loss: 0.5492 - val_acc: 0.6096 - val_auc_2: 0.8227 - val_precision_2: 0.7315 - val_recall_2: 0.7353 - val_f1score: 0.3408\n",
      "Epoch 27/100\n",
      "43/42 [==============================] - 16s 364ms/step - loss: 0.3776 - acc: 0.8274 - auc_2: 0.8237 - precision_2: 0.7325 - recall_2: 0.7362 - f1score: 0.4150 - val_loss: 0.4791 - val_acc: 0.5892 - val_auc_2: 0.8244 - val_precision_2: 0.7333 - val_recall_2: 0.7369 - val_f1score: 0.3396\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 16s 365ms/step - loss: 0.4032 - acc: 0.8157 - auc_2: 0.8251 - precision_2: 0.7341 - recall_2: 0.7377 - f1score: 0.4104 - val_loss: 0.9056 - val_acc: 0.6023 - val_auc_2: 0.8255 - val_precision_2: 0.7346 - val_recall_2: 0.7381 - val_f1score: 0.3425\n",
      "Epoch 29/100\n",
      "43/42 [==============================] - 17s 396ms/step - loss: 0.3932 - acc: 0.8332 - auc_2: 0.8263 - precision_2: 0.7356 - recall_2: 0.7391 - f1score: 0.4133 - val_loss: 0.6857 - val_acc: 0.6374 - val_auc_2: 0.8270 - val_precision_2: 0.7366 - val_recall_2: 0.7400 - val_f1score: 0.3523\n",
      "Epoch 30/100\n",
      "43/42 [==============================] - 18s 409ms/step - loss: 0.3736 - acc: 0.8372 - auc_2: 0.8279 - precision_2: 0.7375 - recall_2: 0.7409 - f1score: 0.4169 - val_loss: 1.0737 - val_acc: 0.6023 - val_auc_2: 0.8288 - val_precision_2: 0.7385 - val_recall_2: 0.7418 - val_f1score: 0.3438\n",
      "Epoch 31/100\n",
      "43/42 [==============================] - 18s 415ms/step - loss: 0.3922 - acc: 0.8277 - auc_2: 0.8296 - precision_2: 0.7393 - recall_2: 0.7426 - f1score: 0.4145 - val_loss: 0.7792 - val_acc: 0.6213 - val_auc_2: 0.8300 - val_precision_2: 0.7400 - val_recall_2: 0.7432 - val_f1score: 0.3485\n",
      "Epoch 32/100\n",
      "43/42 [==============================] - 17s 404ms/step - loss: 0.3695 - acc: 0.8321 - auc_2: 0.8309 - precision_2: 0.7408 - recall_2: 0.7439 - f1score: 0.4168 - val_loss: 0.7367 - val_acc: 0.5980 - val_auc_2: 0.8315 - val_precision_2: 0.7414 - val_recall_2: 0.7446 - val_f1score: 0.3469\n",
      "Epoch 33/100\n",
      "43/42 [==============================] - 17s 404ms/step - loss: 0.3813 - acc: 0.8358 - auc_2: 0.8323 - precision_2: 0.7422 - recall_2: 0.7453 - f1score: 0.4164 - val_loss: 0.7101 - val_acc: 0.6140 - val_auc_2: 0.8328 - val_precision_2: 0.7429 - val_recall_2: 0.7459 - val_f1score: 0.3452\n",
      "Epoch 34/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3662 - acc: 0.8259 - auc_2: 0.8334 - precision_2: 0.7435 - recall_2: 0.7465 - f1score: 0.4184 - val_loss: 0.8865 - val_acc: 0.6082 - val_auc_2: 0.8340 - val_precision_2: 0.7440 - val_recall_2: 0.7470 - val_f1score: 0.3439\n",
      "Epoch 35/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3816 - acc: 0.8296 - auc_2: 0.8346 - precision_2: 0.7448 - recall_2: 0.7477 - f1score: 0.4162 - val_loss: 0.7643 - val_acc: 0.5687 - val_auc_2: 0.8349 - val_precision_2: 0.7452 - val_recall_2: 0.7481 - val_f1score: 0.3335\n",
      "Epoch 36/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.3981 - acc: 0.8186 - auc_2: 0.8352 - precision_2: 0.7456 - recall_2: 0.7485 - f1score: 0.4121 - val_loss: 0.9743 - val_acc: 0.6038 - val_auc_2: 0.8354 - val_precision_2: 0.7459 - val_recall_2: 0.7488 - val_f1score: 0.3422\n",
      "Epoch 37/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.3684 - acc: 0.8339 - auc_2: 0.8361 - precision_2: 0.7466 - recall_2: 0.7495 - f1score: 0.4179 - val_loss: 0.7861 - val_acc: 0.6155 - val_auc_2: 0.8366 - val_precision_2: 0.7471 - val_recall_2: 0.7499 - val_f1score: 0.3489\n",
      "Epoch 38/100\n",
      "43/42 [==============================] - 17s 406ms/step - loss: 0.3626 - acc: 0.8339 - auc_2: 0.8374 - precision_2: 0.7478 - recall_2: 0.7506 - f1score: 0.4194 - val_loss: 0.5372 - val_acc: 0.6389 - val_auc_2: 0.8378 - val_precision_2: 0.7482 - val_recall_2: 0.7510 - val_f1score: 0.3561\n",
      "Epoch 39/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3481 - acc: 0.8464 - auc_2: 0.8388 - precision_2: 0.7491 - recall_2: 0.7519 - f1score: 0.4229 - val_loss: 0.4967 - val_acc: 0.6301 - val_auc_2: 0.8392 - val_precision_2: 0.7496 - val_recall_2: 0.7524 - val_f1score: 0.3437\n",
      "Epoch 40/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3448 - acc: 0.8445 - auc_2: 0.8399 - precision_2: 0.7504 - recall_2: 0.7531 - f1score: 0.4232 - val_loss: 1.2775 - val_acc: 0.5848 - val_auc_2: 0.8404 - val_precision_2: 0.7509 - val_recall_2: 0.7535 - val_f1score: 0.3387\n",
      "Epoch 41/100\n",
      "43/42 [==============================] - 18s 418ms/step - loss: 0.3401 - acc: 0.8522 - auc_2: 0.8411 - precision_2: 0.7516 - recall_2: 0.7543 - f1score: 0.4250 - val_loss: 0.9102 - val_acc: 0.6023 - val_auc_2: 0.8414 - val_precision_2: 0.7521 - val_recall_2: 0.7548 - val_f1score: 0.3366\n",
      "Epoch 42/100\n",
      "43/42 [==============================] - 18s 412ms/step - loss: 0.3244 - acc: 0.8588 - auc_2: 0.8421 - precision_2: 0.7527 - recall_2: 0.7554 - f1score: 0.4281 - val_loss: 0.7381 - val_acc: 0.5906 - val_auc_2: 0.8427 - val_precision_2: 0.7534 - val_recall_2: 0.7561 - val_f1score: 0.3357\n",
      "Epoch 43/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.3448 - acc: 0.8405 - auc_2: 0.8432 - precision_2: 0.7539 - recall_2: 0.7565 - f1score: 0.4237 - val_loss: 0.7570 - val_acc: 0.6155 - val_auc_2: 0.8435 - val_precision_2: 0.7542 - val_recall_2: 0.7569 - val_f1score: 0.3396\n",
      "Epoch 44/100\n",
      "43/42 [==============================] - 17s 404ms/step - loss: 0.3358 - acc: 0.8500 - auc_2: 0.8441 - precision_2: 0.7549 - recall_2: 0.7575 - f1score: 0.4263 - val_loss: 0.8895 - val_acc: 0.6096 - val_auc_2: 0.8445 - val_precision_2: 0.7553 - val_recall_2: 0.7578 - val_f1score: 0.3490\n",
      "Epoch 45/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3403 - acc: 0.8434 - auc_2: 0.8452 - precision_2: 0.7559 - recall_2: 0.7584 - f1score: 0.4247 - val_loss: 0.6475 - val_acc: 0.6126 - val_auc_2: 0.8456 - val_precision_2: 0.7563 - val_recall_2: 0.7587 - val_f1score: 0.3444\n",
      "Epoch 46/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.3251 - acc: 0.8547 - auc_2: 0.8461 - precision_2: 0.7568 - recall_2: 0.7593 - f1score: 0.4284 - val_loss: 0.7573 - val_acc: 0.6111 - val_auc_2: 0.8466 - val_precision_2: 0.7574 - val_recall_2: 0.7598 - val_f1score: 0.3442\n",
      "Epoch 47/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.3292 - acc: 0.8690 - auc_2: 0.8473 - precision_2: 0.7581 - recall_2: 0.7605 - f1score: 0.4293 - val_loss: 1.0059 - val_acc: 0.6345 - val_auc_2: 0.8478 - val_precision_2: 0.7587 - val_recall_2: 0.7611 - val_f1score: 0.3493\n",
      "Epoch 48/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.3249 - acc: 0.8631 - auc_2: 0.8484 - precision_2: 0.7594 - recall_2: 0.7617 - f1score: 0.4284 - val_loss: 1.2145 - val_acc: 0.5965 - val_auc_2: 0.8487 - val_precision_2: 0.7598 - val_recall_2: 0.7622 - val_f1score: 0.3385\n",
      "Epoch 49/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.3353 - acc: 0.8482 - auc_2: 0.8492 - precision_2: 0.7603 - recall_2: 0.7627 - f1score: 0.4272 - val_loss: 0.8489 - val_acc: 0.5789 - val_auc_2: 0.8496 - val_precision_2: 0.7606 - val_recall_2: 0.7630 - val_f1score: 0.3379\n",
      "Epoch 50/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.3075 - acc: 0.8555 - auc_2: 0.8500 - precision_2: 0.7609 - recall_2: 0.7633 - f1score: 0.4311 - val_loss: 0.8154 - val_acc: 0.5833 - val_auc_2: 0.8505 - val_precision_2: 0.7614 - val_recall_2: 0.7637 - val_f1score: 0.3385\n",
      "Epoch 51/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.3227 - acc: 0.8602 - auc_2: 0.8509 - precision_2: 0.7618 - recall_2: 0.7641 - f1score: 0.4297 - val_loss: 1.0212 - val_acc: 0.6316 - val_auc_2: 0.8514 - val_precision_2: 0.7624 - val_recall_2: 0.7646 - val_f1score: 0.3432\n",
      "Epoch 52/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.3181 - acc: 0.8624 - auc_2: 0.8518 - precision_2: 0.7629 - recall_2: 0.7651 - f1score: 0.4306 - val_loss: 1.2540 - val_acc: 0.5877 - val_auc_2: 0.8521 - val_precision_2: 0.7633 - val_recall_2: 0.7655 - val_f1score: 0.3329\n",
      "Epoch 53/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2914 - acc: 0.8774 - auc_2: 0.8526 - precision_2: 0.7638 - recall_2: 0.7660 - f1score: 0.4359 - val_loss: 0.9758 - val_acc: 0.5702 - val_auc_2: 0.8530 - val_precision_2: 0.7642 - val_recall_2: 0.7664 - val_f1score: 0.3290\n",
      "Epoch 54/100\n",
      "43/42 [==============================] - 17s 404ms/step - loss: 0.2776 - acc: 0.8814 - auc_2: 0.8535 - precision_2: 0.7648 - recall_2: 0.7670 - f1score: 0.4386 - val_loss: 0.9642 - val_acc: 0.6608 - val_auc_2: 0.8541 - val_precision_2: 0.7655 - val_recall_2: 0.7676 - val_f1score: 0.3514\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 17s 402ms/step - loss: 0.3144 - acc: 0.8726 - auc_2: 0.8546 - precision_2: 0.7660 - recall_2: 0.7682 - f1score: 0.4331 - val_loss: 0.9407 - val_acc: 0.6184 - val_auc_2: 0.8551 - val_precision_2: 0.7666 - val_recall_2: 0.7688 - val_f1score: 0.3456\n",
      "Epoch 56/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2967 - acc: 0.8745 - auc_2: 0.8556 - precision_2: 0.7671 - recall_2: 0.7693 - f1score: 0.4357 - val_loss: 0.7971 - val_acc: 0.5556 - val_auc_2: 0.8557 - val_precision_2: 0.7674 - val_recall_2: 0.7695 - val_f1score: 0.3184\n",
      "Epoch 57/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2895 - acc: 0.8664 - auc_2: 0.8562 - precision_2: 0.7678 - recall_2: 0.7700 - f1score: 0.4362 - val_loss: 1.0331 - val_acc: 0.6213 - val_auc_2: 0.8566 - val_precision_2: 0.7682 - val_recall_2: 0.7703 - val_f1score: 0.3440\n",
      "Epoch 58/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2999 - acc: 0.8690 - auc_2: 0.8570 - precision_2: 0.7687 - recall_2: 0.7708 - f1score: 0.4349 - val_loss: 1.0465 - val_acc: 0.6199 - val_auc_2: 0.8574 - val_precision_2: 0.7691 - val_recall_2: 0.7712 - val_f1score: 0.3393\n",
      "Epoch 59/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2925 - acc: 0.8792 - auc_2: 0.8579 - precision_2: 0.7696 - recall_2: 0.7717 - f1score: 0.4371 - val_loss: 0.6171 - val_acc: 0.5980 - val_auc_2: 0.8581 - val_precision_2: 0.7700 - val_recall_2: 0.7721 - val_f1score: 0.3363\n",
      "Epoch 60/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2493 - acc: 0.8971 - auc_2: 0.8588 - precision_2: 0.7706 - recall_2: 0.7727 - f1score: 0.4448 - val_loss: 0.6797 - val_acc: 0.5950 - val_auc_2: 0.8592 - val_precision_2: 0.7711 - val_recall_2: 0.7731 - val_f1score: 0.3305\n",
      "Epoch 61/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.2768 - acc: 0.8883 - auc_2: 0.8596 - precision_2: 0.7716 - recall_2: 0.7737 - f1score: 0.4405 - val_loss: 1.0759 - val_acc: 0.5614 - val_auc_2: 0.8599 - val_precision_2: 0.7720 - val_recall_2: 0.7740 - val_f1score: 0.3229\n",
      "Epoch 62/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2627 - acc: 0.8858 - auc_2: 0.8604 - precision_2: 0.7725 - recall_2: 0.7745 - f1score: 0.4435 - val_loss: 0.9603 - val_acc: 0.5804 - val_auc_2: 0.8608 - val_precision_2: 0.7728 - val_recall_2: 0.7749 - val_f1score: 0.3365\n",
      "Epoch 63/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2901 - acc: 0.8723 - auc_2: 0.8612 - precision_2: 0.7732 - recall_2: 0.7753 - f1score: 0.4381 - val_loss: 0.4993 - val_acc: 0.5746 - val_auc_2: 0.8614 - val_precision_2: 0.7734 - val_recall_2: 0.7755 - val_f1score: 0.3287\n",
      "Epoch 64/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2559 - acc: 0.8887 - auc_2: 0.8619 - precision_2: 0.7739 - recall_2: 0.7759 - f1score: 0.4439 - val_loss: 1.3723 - val_acc: 0.5848 - val_auc_2: 0.8623 - val_precision_2: 0.7743 - val_recall_2: 0.7764 - val_f1score: 0.3331\n",
      "Epoch 65/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.2489 - acc: 0.8945 - auc_2: 0.8628 - precision_2: 0.7748 - recall_2: 0.7768 - f1score: 0.4457 - val_loss: 1.1389 - val_acc: 0.6213 - val_auc_2: 0.8632 - val_precision_2: 0.7753 - val_recall_2: 0.7773 - val_f1score: 0.3405\n",
      "Epoch 66/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.2611 - acc: 0.8905 - auc_2: 0.8637 - precision_2: 0.7758 - recall_2: 0.7777 - f1score: 0.4437 - val_loss: 0.9521 - val_acc: 0.6184 - val_auc_2: 0.8640 - val_precision_2: 0.7762 - val_recall_2: 0.7781 - val_f1score: 0.3341\n",
      "Epoch 67/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2359 - acc: 0.9036 - auc_2: 0.8645 - precision_2: 0.7768 - recall_2: 0.7787 - f1score: 0.4478 - val_loss: 1.1018 - val_acc: 0.6053 - val_auc_2: 0.8649 - val_precision_2: 0.7772 - val_recall_2: 0.7791 - val_f1score: 0.3335\n",
      "Epoch 68/100\n",
      "43/42 [==============================] - 17s 404ms/step - loss: 0.2430 - acc: 0.8949 - auc_2: 0.8654 - precision_2: 0.7777 - recall_2: 0.7796 - f1score: 0.4475 - val_loss: 1.3066 - val_acc: 0.6082 - val_auc_2: 0.8657 - val_precision_2: 0.7781 - val_recall_2: 0.7800 - val_f1score: 0.3345\n",
      "Epoch 69/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2500 - acc: 0.8982 - auc_2: 0.8662 - precision_2: 0.7786 - recall_2: 0.7805 - f1score: 0.4459 - val_loss: 0.8777 - val_acc: 0.6009 - val_auc_2: 0.8665 - val_precision_2: 0.7790 - val_recall_2: 0.7809 - val_f1score: 0.3332\n",
      "Epoch 70/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2262 - acc: 0.9022 - auc_2: 0.8670 - precision_2: 0.7795 - recall_2: 0.7814 - f1score: 0.4496 - val_loss: 1.2729 - val_acc: 0.6023 - val_auc_2: 0.8674 - val_precision_2: 0.7799 - val_recall_2: 0.7818 - val_f1score: 0.3353\n",
      "Epoch 71/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2264 - acc: 0.9055 - auc_2: 0.8678 - precision_2: 0.7803 - recall_2: 0.7822 - f1score: 0.4508 - val_loss: 1.0203 - val_acc: 0.5775 - val_auc_2: 0.8682 - val_precision_2: 0.7807 - val_recall_2: 0.7826 - val_f1score: 0.3279\n",
      "Epoch 72/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2348 - acc: 0.9055 - auc_2: 0.8686 - precision_2: 0.7812 - recall_2: 0.7831 - f1score: 0.4499 - val_loss: 0.9094 - val_acc: 0.6170 - val_auc_2: 0.8689 - val_precision_2: 0.7816 - val_recall_2: 0.7835 - val_f1score: 0.3390\n",
      "Epoch 73/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2114 - acc: 0.9190 - auc_2: 0.8695 - precision_2: 0.7822 - recall_2: 0.7841 - f1score: 0.4542 - val_loss: 0.7869 - val_acc: 0.6111 - val_auc_2: 0.8699 - val_precision_2: 0.7826 - val_recall_2: 0.7846 - val_f1score: 0.3352\n",
      "Epoch 74/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.2102 - acc: 0.9164 - auc_2: 0.8703 - precision_2: 0.7832 - recall_2: 0.7851 - f1score: 0.4537 - val_loss: 0.6730 - val_acc: 0.6243 - val_auc_2: 0.8708 - val_precision_2: 0.7836 - val_recall_2: 0.7855 - val_f1score: 0.3381\n",
      "Epoch 75/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2122 - acc: 0.9095 - auc_2: 0.8712 - precision_2: 0.7842 - recall_2: 0.7861 - f1score: 0.4534 - val_loss: 0.8304 - val_acc: 0.5497 - val_auc_2: 0.8714 - val_precision_2: 0.7844 - val_recall_2: 0.7863 - val_f1score: 0.3118\n",
      "Epoch 76/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1908 - acc: 0.9248 - auc_2: 0.8719 - precision_2: 0.7849 - recall_2: 0.7868 - f1score: 0.4584 - val_loss: 0.9234 - val_acc: 0.6228 - val_auc_2: 0.8723 - val_precision_2: 0.7854 - val_recall_2: 0.7873 - val_f1score: 0.3355\n",
      "Epoch 77/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2272 - acc: 0.9066 - auc_2: 0.8727 - precision_2: 0.7859 - recall_2: 0.7878 - f1score: 0.4519 - val_loss: 1.4274 - val_acc: 0.5980 - val_auc_2: 0.8729 - val_precision_2: 0.7862 - val_recall_2: 0.7881 - val_f1score: 0.3279\n",
      "Epoch 78/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.2112 - acc: 0.9182 - auc_2: 0.8733 - precision_2: 0.7866 - recall_2: 0.7886 - f1score: 0.4555 - val_loss: 1.1918 - val_acc: 0.5687 - val_auc_2: 0.8736 - val_precision_2: 0.7870 - val_recall_2: 0.7889 - val_f1score: 0.3213\n",
      "Epoch 79/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.2069 - acc: 0.9182 - auc_2: 0.8740 - precision_2: 0.7874 - recall_2: 0.7894 - f1score: 0.4557 - val_loss: 1.7141 - val_acc: 0.6096 - val_auc_2: 0.8743 - val_precision_2: 0.7878 - val_recall_2: 0.7898 - val_f1score: 0.3356\n",
      "Epoch 80/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1830 - acc: 0.9274 - auc_2: 0.8748 - precision_2: 0.7883 - recall_2: 0.7903 - f1score: 0.4601 - val_loss: 1.2344 - val_acc: 0.6126 - val_auc_2: 0.8752 - val_precision_2: 0.7888 - val_recall_2: 0.7907 - val_f1score: 0.3362\n",
      "Epoch 81/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.1752 - acc: 0.9281 - auc_2: 0.8757 - precision_2: 0.7893 - recall_2: 0.7912 - f1score: 0.4609 - val_loss: 1.2284 - val_acc: 0.6155 - val_auc_2: 0.8761 - val_precision_2: 0.7897 - val_recall_2: 0.7916 - val_f1score: 0.3379\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 17s 400ms/step - loss: 0.1949 - acc: 0.9164 - auc_2: 0.8765 - precision_2: 0.7901 - recall_2: 0.7920 - f1score: 0.4582 - val_loss: 1.2391 - val_acc: 0.5863 - val_auc_2: 0.8768 - val_precision_2: 0.7905 - val_recall_2: 0.7923 - val_f1score: 0.3289\n",
      "Epoch 83/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.1639 - acc: 0.9391 - auc_2: 0.8773 - precision_2: 0.7910 - recall_2: 0.7929 - f1score: 0.4650 - val_loss: 1.5759 - val_acc: 0.6023 - val_auc_2: 0.8777 - val_precision_2: 0.7914 - val_recall_2: 0.7933 - val_f1score: 0.3288\n",
      "Epoch 84/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.1822 - acc: 0.9307 - auc_2: 0.8781 - precision_2: 0.7919 - recall_2: 0.7938 - f1score: 0.4615 - val_loss: 0.8331 - val_acc: 0.5731 - val_auc_2: 0.8783 - val_precision_2: 0.7922 - val_recall_2: 0.7941 - val_f1score: 0.3233\n",
      "Epoch 85/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.1933 - acc: 0.9197 - auc_2: 0.8787 - precision_2: 0.7926 - recall_2: 0.7945 - f1score: 0.4587 - val_loss: 0.8778 - val_acc: 0.6345 - val_auc_2: 0.8791 - val_precision_2: 0.7930 - val_recall_2: 0.7949 - val_f1score: 0.3425\n",
      "Epoch 86/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1730 - acc: 0.9277 - auc_2: 0.8795 - precision_2: 0.7935 - recall_2: 0.7954 - f1score: 0.4618 - val_loss: 0.7029 - val_acc: 0.6243 - val_auc_2: 0.8799 - val_precision_2: 0.7939 - val_recall_2: 0.7958 - val_f1score: 0.3358\n",
      "Epoch 87/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1920 - acc: 0.9215 - auc_2: 0.8803 - precision_2: 0.7943 - recall_2: 0.7962 - f1score: 0.4610 - val_loss: 0.8005 - val_acc: 0.5746 - val_auc_2: 0.8805 - val_precision_2: 0.7946 - val_recall_2: 0.7964 - val_f1score: 0.3236\n",
      "Epoch 88/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1599 - acc: 0.9372 - auc_2: 0.8809 - precision_2: 0.7951 - recall_2: 0.7969 - f1score: 0.4654 - val_loss: 0.9556 - val_acc: 0.6023 - val_auc_2: 0.8812 - val_precision_2: 0.7954 - val_recall_2: 0.7972 - val_f1score: 0.3307\n",
      "Epoch 89/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1743 - acc: 0.9255 - auc_2: 0.8816 - precision_2: 0.7959 - recall_2: 0.7977 - f1score: 0.4630 - val_loss: 0.7754 - val_acc: 0.5950 - val_auc_2: 0.8819 - val_precision_2: 0.7962 - val_recall_2: 0.7980 - val_f1score: 0.3260\n",
      "Epoch 90/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.1582 - acc: 0.9380 - auc_2: 0.8823 - precision_2: 0.7966 - recall_2: 0.7984 - f1score: 0.4663 - val_loss: 1.8485 - val_acc: 0.5892 - val_auc_2: 0.8826 - val_precision_2: 0.7970 - val_recall_2: 0.7988 - val_f1score: 0.3164\n",
      "Epoch 91/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1354 - acc: 0.9485 - auc_2: 0.8829 - precision_2: 0.7974 - recall_2: 0.7992 - f1score: 0.4699 - val_loss: 1.4030 - val_acc: 0.5863 - val_auc_2: 0.8832 - val_precision_2: 0.7978 - val_recall_2: 0.7996 - val_f1score: 0.3195\n",
      "Epoch 92/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1576 - acc: 0.9387 - auc_2: 0.8836 - precision_2: 0.7982 - recall_2: 0.8001 - f1score: 0.4669 - val_loss: 0.8048 - val_acc: 0.6330 - val_auc_2: 0.8839 - val_precision_2: 0.7987 - val_recall_2: 0.8005 - val_f1score: 0.3339\n",
      "Epoch 93/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1509 - acc: 0.9478 - auc_2: 0.8844 - precision_2: 0.7992 - recall_2: 0.8010 - f1score: 0.4686 - val_loss: 1.3729 - val_acc: 0.6126 - val_auc_2: 0.8847 - val_precision_2: 0.7996 - val_recall_2: 0.8014 - val_f1score: 0.3283\n",
      "Epoch 94/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1578 - acc: 0.9420 - auc_2: 0.8850 - precision_2: 0.8000 - recall_2: 0.8018 - f1score: 0.4676 - val_loss: 1.2008 - val_acc: 0.5731 - val_auc_2: 0.8852 - val_precision_2: 0.8003 - val_recall_2: 0.8021 - val_f1score: 0.3143\n",
      "Epoch 95/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1494 - acc: 0.9383 - auc_2: 0.8855 - precision_2: 0.8007 - recall_2: 0.8025 - f1score: 0.4669 - val_loss: 1.6437 - val_acc: 0.6243 - val_auc_2: 0.8859 - val_precision_2: 0.8011 - val_recall_2: 0.8029 - val_f1score: 0.3365\n",
      "Epoch 96/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1429 - acc: 0.9464 - auc_2: 0.8863 - precision_2: 0.8015 - recall_2: 0.8033 - f1score: 0.4703 - val_loss: 1.2489 - val_acc: 0.5877 - val_auc_2: 0.8865 - val_precision_2: 0.8018 - val_recall_2: 0.8037 - val_f1score: 0.3194\n",
      "Epoch 97/100\n",
      "43/42 [==============================] - 17s 401ms/step - loss: 0.1215 - acc: 0.9540 - auc_2: 0.8869 - precision_2: 0.8023 - recall_2: 0.8041 - f1score: 0.4733 - val_loss: 1.5804 - val_acc: 0.5556 - val_auc_2: 0.8871 - val_precision_2: 0.8026 - val_recall_2: 0.8044 - val_f1score: 0.3061\n",
      "Epoch 98/100\n",
      "43/42 [==============================] - 17s 400ms/step - loss: 0.1342 - acc: 0.9431 - auc_2: 0.8874 - precision_2: 0.8030 - recall_2: 0.8047 - f1score: 0.4708 - val_loss: 1.6902 - val_acc: 0.5804 - val_auc_2: 0.8877 - val_precision_2: 0.8033 - val_recall_2: 0.8050 - val_f1score: 0.3156\n",
      "Epoch 99/100\n",
      "43/42 [==============================] - 17s 403ms/step - loss: 0.1293 - acc: 0.9533 - auc_2: 0.8880 - precision_2: 0.8037 - recall_2: 0.8055 - f1score: 0.4722 - val_loss: 1.1361 - val_acc: 0.6316 - val_auc_2: 0.8883 - val_precision_2: 0.8041 - val_recall_2: 0.8059 - val_f1score: 0.3337\n",
      "Epoch 100/100\n",
      "43/42 [==============================] - 17s 402ms/step - loss: 0.1114 - acc: 0.9599 - auc_2: 0.8887 - precision_2: 0.8046 - recall_2: 0.8063 - f1score: 0.4755 - val_loss: 1.8569 - val_acc: 0.5877 - val_auc_2: 0.8890 - val_precision_2: 0.8050 - val_recall_2: 0.8067 - val_f1score: 0.3180\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])\n",
    "\n",
    "history = additional_model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples /32,\n",
    "      epochs=100,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples/32,\n",
    "      callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.065, accuracy: 0.609, auc: 0.888, precision: 0.804, recall: 0.806, f1score: 0.331\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score =  additional_model.evaluate_generator(validation_generator, steps=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'png_VGG16_finetuning.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-253311b9afbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'png_VGG16_finetuning.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras2\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras2\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'png_VGG16_finetuning.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "new_model = models.load_model('png_VGG16_finetuning.hdf5',compile=False)\n",
    "\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir='./test_without_callback'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score =new_model.evaluate_generator(test_generator, steps=test_generator.samples/32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
