{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 204804    \n",
      "=================================================================\n",
      "Total params: 22,007,588\n",
      "Trainable params: 21,973,156\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='Inception v3_transfer learning_1.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 66s 438ms/step - loss: 1.1630 - acc: 0.4489 - auc: 0.6619 - precision: 0.4404 - recall: 0.1883 - f1score: 0.1290 - val_loss: 1.3750 - val_acc: 0.3737 - val_auc: 0.7432 - val_precision: 0.5279 - val_recall: 0.2705 - val_f1score: 0.1135\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.8476 - acc: 0.5833 - auc: 0.7779 - precision: 0.5550 - recall: 0.3293 - f1score: 0.1586 - val_loss: 1.2433 - val_acc: 0.4046 - val_auc: 0.8045 - val_precision: 0.5769 - val_recall: 0.3767 - val_f1score: 0.1255\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.6979 - acc: 0.6646 - auc: 0.8230 - precision: 0.5970 - recall: 0.4147 - f1score: 0.1732 - val_loss: 0.9343 - val_acc: 0.5361 - val_auc: 0.8400 - val_precision: 0.6184 - val_recall: 0.4521 - val_f1score: 0.1527\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.6189 - acc: 0.7109 - auc: 0.8519 - precision: 0.6342 - recall: 0.4799 - f1score: 0.1815 - val_loss: 0.9170 - val_acc: 0.5851 - val_auc: 0.8630 - val_precision: 0.6492 - val_recall: 0.5064 - val_f1score: 0.1597\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.5294 - acc: 0.7586 - auc: 0.8727 - precision: 0.6627 - recall: 0.5297 - f1score: 0.1910 - val_loss: 0.9395 - val_acc: 0.5464 - val_auc: 0.8809 - val_precision: 0.6743 - val_recall: 0.5504 - val_f1score: 0.1578\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.4463 - acc: 0.8039 - auc: 0.8889 - precision: 0.6865 - recall: 0.5695 - f1score: 0.1999 - val_loss: 1.0008 - val_acc: 0.5335 - val_auc: 0.8959 - val_precision: 0.6978 - val_recall: 0.5872 - val_f1score: 0.1579\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.3979 - acc: 0.8255 - auc: 0.9020 - precision: 0.7074 - recall: 0.6021 - f1score: 0.2054 - val_loss: 0.9969 - val_acc: 0.5567 - val_auc: 0.9077 - val_precision: 0.7166 - val_recall: 0.6167 - val_f1score: 0.1595\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.3192 - acc: 0.8744 - auc: 0.9134 - precision: 0.7267 - recall: 0.6312 - f1score: 0.2143 - val_loss: 1.1471 - val_acc: 0.5567 - val_auc: 0.9184 - val_precision: 0.7362 - val_recall: 0.6450 - val_f1score: 0.1546\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.2718 - acc: 0.8908 - auc: 0.9232 - precision: 0.7454 - recall: 0.6578 - f1score: 0.2193 - val_loss: 1.0827 - val_acc: 0.5747 - val_auc: 0.9273 - val_precision: 0.7530 - val_recall: 0.6690 - val_f1score: 0.1566\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.2401 - acc: 0.9120 - auc: 0.9312 - precision: 0.7610 - recall: 0.6800 - f1score: 0.2234 - val_loss: 1.2042 - val_acc: 0.5670 - val_auc: 0.9347 - val_precision: 0.7683 - val_recall: 0.6904 - val_f1score: 0.1570\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.1894 - acc: 0.9358 - auc: 0.9382 - precision: 0.7756 - recall: 0.7004 - f1score: 0.2287 - val_loss: 1.2193 - val_acc: 0.5644 - val_auc: 0.9413 - val_precision: 0.7823 - val_recall: 0.7098 - val_f1score: 0.1553\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1599 - acc: 0.9442 - auc: 0.9442 - precision: 0.7887 - recall: 0.7186 - f1score: 0.2321 - val_loss: 1.2929 - val_acc: 0.5464 - val_auc: 0.9469 - val_precision: 0.7946 - val_recall: 0.7269 - val_f1score: 0.1537\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1437 - acc: 0.9519 - auc: 0.9494 - precision: 0.8002 - recall: 0.7345 - f1score: 0.2340 - val_loss: 1.3129 - val_acc: 0.5541 - val_auc: 0.9516 - val_precision: 0.8053 - val_recall: 0.7415 - val_f1score: 0.1532\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.1148 - acc: 0.9606 - auc: 0.9538 - precision: 0.8104 - recall: 0.7485 - f1score: 0.2370 - val_loss: 1.4062 - val_acc: 0.5773 - val_auc: 0.9556 - val_precision: 0.8150 - val_recall: 0.7549 - val_f1score: 0.1544\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.1107 - acc: 0.9625 - auc: 0.9575 - precision: 0.8196 - recall: 0.7611 - f1score: 0.2380 - val_loss: 1.4820 - val_acc: 0.5619 - val_auc: 0.9590 - val_precision: 0.8236 - val_recall: 0.7667 - val_f1score: 0.1518\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.0929 - acc: 0.9670 - auc: 0.9606 - precision: 0.8276 - recall: 0.7722 - f1score: 0.2398 - val_loss: 1.4663 - val_acc: 0.5567 - val_auc: 0.9620 - val_precision: 0.8312 - val_recall: 0.7773 - val_f1score: 0.1505\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 44s 290ms/step - loss: 0.0812 - acc: 0.9762 - auc: 0.9634 - precision: 0.8350 - recall: 0.7823 - f1score: 0.2411 - val_loss: 1.5667 - val_acc: 0.5696 - val_auc: 0.9646 - val_precision: 0.8385 - val_recall: 0.7871 - val_f1score: 0.1530\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0722 - acc: 0.9762 - auc: 0.9658 - precision: 0.8419 - recall: 0.7917 - f1score: 0.2418 - val_loss: 1.5652 - val_acc: 0.5515 - val_auc: 0.9668 - val_precision: 0.8448 - val_recall: 0.7958 - val_f1score: 0.1505\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0624 - acc: 0.9785 - auc: 0.9679 - precision: 0.8478 - recall: 0.7999 - f1score: 0.2431 - val_loss: 1.5664 - val_acc: 0.5902 - val_auc: 0.9689 - val_precision: 0.8505 - val_recall: 0.8037 - val_f1score: 0.1566\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0619 - acc: 0.9796 - auc: 0.9698 - precision: 0.8534 - recall: 0.8075 - f1score: 0.2433 - val_loss: 1.6277 - val_acc: 0.5799 - val_auc: 0.9706 - val_precision: 0.8559 - val_recall: 0.8110 - val_f1score: 0.1551\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0585 - acc: 0.9794 - auc: 0.9714 - precision: 0.8584 - recall: 0.8144 - f1score: 0.2437 - val_loss: 1.6582 - val_acc: 0.5773 - val_auc: 0.9721 - val_precision: 0.8606 - val_recall: 0.8176 - val_f1score: 0.1537\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0492 - acc: 0.9837 - auc: 0.9729 - precision: 0.8629 - recall: 0.8208 - f1score: 0.2447 - val_loss: 1.5998 - val_acc: 0.5670 - val_auc: 0.9735 - val_precision: 0.8650 - val_recall: 0.8237 - val_f1score: 0.1540\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0362 - acc: 0.9893 - auc: 0.9742 - precision: 0.8673 - recall: 0.8268 - f1score: 0.2459 - val_loss: 1.7549 - val_acc: 0.5438 - val_auc: 0.9748 - val_precision: 0.8692 - val_recall: 0.8295 - val_f1score: 0.1505\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0366 - acc: 0.9882 - auc: 0.9754 - precision: 0.8712 - recall: 0.8322 - f1score: 0.2459 - val_loss: 1.7339 - val_acc: 0.5747 - val_auc: 0.9759 - val_precision: 0.8730 - val_recall: 0.8347 - val_f1score: 0.1535\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0356 - acc: 0.9886 - auc: 0.9765 - precision: 0.8749 - recall: 0.8373 - f1score: 0.2462 - val_loss: 1.7946 - val_acc: 0.5515 - val_auc: 0.9769 - val_precision: 0.8765 - val_recall: 0.8396 - val_f1score: 0.1491\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0310 - acc: 0.9899 - auc: 0.9774 - precision: 0.8782 - recall: 0.8419 - f1score: 0.2466 - val_loss: 1.8680 - val_acc: 0.5619 - val_auc: 0.9778 - val_precision: 0.8797 - val_recall: 0.8441 - val_f1score: 0.1492\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0288 - acc: 0.9912 - auc: 0.9783 - precision: 0.8814 - recall: 0.8463 - f1score: 0.2468 - val_loss: 2.0336 - val_acc: 0.5541 - val_auc: 0.9786 - val_precision: 0.8828 - val_recall: 0.8483 - val_f1score: 0.1505\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0290 - acc: 0.9916 - auc: 0.9790 - precision: 0.8843 - recall: 0.8504 - f1score: 0.2469 - val_loss: 1.9536 - val_acc: 0.5773 - val_auc: 0.9793 - val_precision: 0.8857 - val_recall: 0.8523 - val_f1score: 0.1499\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0261 - acc: 0.9912 - auc: 0.9797 - precision: 0.8871 - recall: 0.8542 - f1score: 0.2472 - val_loss: 1.9034 - val_acc: 0.5619 - val_auc: 0.9800 - val_precision: 0.8883 - val_recall: 0.8559 - val_f1score: 0.1505\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0311 - acc: 0.9904 - auc: 0.9803 - precision: 0.8896 - recall: 0.8577 - f1score: 0.2467 - val_loss: 2.0586 - val_acc: 0.5490 - val_auc: 0.9805 - val_precision: 0.8907 - val_recall: 0.8593 - val_f1score: 0.1493\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.0259 - acc: 0.9922 - auc: 0.9808 - precision: 0.8919 - recall: 0.8610 - f1score: 0.2473 - val_loss: 2.1326 - val_acc: 0.5541 - val_auc: 0.9810 - val_precision: 0.8930 - val_recall: 0.8625 - val_f1score: 0.1457\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0245 - acc: 0.9916 - auc: 0.9813 - precision: 0.8942 - recall: 0.8641 - f1score: 0.2474 - val_loss: 2.0278 - val_acc: 0.5619 - val_auc: 0.9815 - val_precision: 0.8952 - val_recall: 0.8655 - val_f1score: 0.1492\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.0256 - acc: 0.9916 - auc: 0.9817 - precision: 0.8963 - recall: 0.8670 - f1score: 0.2472 - val_loss: 2.0932 - val_acc: 0.5619 - val_auc: 0.9819 - val_precision: 0.8972 - val_recall: 0.8683 - val_f1score: 0.1501\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0263 - acc: 0.9907 - auc: 0.9822 - precision: 0.8982 - recall: 0.8697 - f1score: 0.2472 - val_loss: 2.0762 - val_acc: 0.5670 - val_auc: 0.9823 - val_precision: 0.8991 - val_recall: 0.8710 - val_f1score: 0.1514\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.0215 - acc: 0.9943 - auc: 0.9825 - precision: 0.9001 - recall: 0.8723 - f1score: 0.2479 - val_loss: 2.2688 - val_acc: 0.5541 - val_auc: 0.9827 - val_precision: 0.9009 - val_recall: 0.8735 - val_f1score: 0.1482\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0292 - acc: 0.9895 - auc: 0.9829 - precision: 0.9018 - recall: 0.8747 - f1score: 0.2470 - val_loss: 2.1391 - val_acc: 0.5206 - val_auc: 0.9830 - val_precision: 0.9025 - val_recall: 0.8758 - val_f1score: 0.1427\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0245 - acc: 0.9912 - auc: 0.9832 - precision: 0.9033 - recall: 0.8769 - f1score: 0.2474 - val_loss: 2.0313 - val_acc: 0.5438 - val_auc: 0.9833 - val_precision: 0.9040 - val_recall: 0.8780 - val_f1score: 0.1456\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0182 - acc: 0.9943 - auc: 0.9835 - precision: 0.9048 - recall: 0.8791 - f1score: 0.2481 - val_loss: 1.9736 - val_acc: 0.5438 - val_auc: 0.9837 - val_precision: 0.9055 - val_recall: 0.8801 - val_f1score: 0.1518\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0180 - acc: 0.9937 - auc: 0.9839 - precision: 0.9063 - recall: 0.8812 - f1score: 0.2480 - val_loss: 2.2802 - val_acc: 0.5258 - val_auc: 0.9840 - val_precision: 0.9069 - val_recall: 0.8821 - val_f1score: 0.1424\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0193 - acc: 0.9935 - auc: 0.9841 - precision: 0.9077 - recall: 0.8832 - f1score: 0.2479 - val_loss: 2.4066 - val_acc: 0.5335 - val_auc: 0.9842 - val_precision: 0.9083 - val_recall: 0.8841 - val_f1score: 0.1426\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0221 - acc: 0.9935 - auc: 0.9843 - precision: 0.9090 - recall: 0.8850 - f1score: 0.2480 - val_loss: 2.2124 - val_acc: 0.5515 - val_auc: 0.9844 - val_precision: 0.9096 - val_recall: 0.8859 - val_f1score: 0.1470\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0213 - acc: 0.9924 - auc: 0.9846 - precision: 0.9103 - recall: 0.8868 - f1score: 0.2478 - val_loss: 2.3948 - val_acc: 0.5206 - val_auc: 0.9846 - val_precision: 0.9108 - val_recall: 0.8876 - val_f1score: 0.1408\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0203 - acc: 0.9920 - auc: 0.9847 - precision: 0.9114 - recall: 0.8884 - f1score: 0.2479 - val_loss: 2.1992 - val_acc: 0.5490 - val_auc: 0.9848 - val_precision: 0.9119 - val_recall: 0.8892 - val_f1score: 0.1492\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0191 - acc: 0.9941 - auc: 0.9849 - precision: 0.9125 - recall: 0.8901 - f1score: 0.2481 - val_loss: 2.3837 - val_acc: 0.5541 - val_auc: 0.9850 - val_precision: 0.9131 - val_recall: 0.8908 - val_f1score: 0.1465\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0150 - acc: 0.9939 - auc: 0.9851 - precision: 0.9137 - recall: 0.8916 - f1score: 0.2484 - val_loss: 2.2900 - val_acc: 0.5773 - val_auc: 0.9852 - val_precision: 0.9142 - val_recall: 0.8924 - val_f1score: 0.1508\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0191 - acc: 0.9945 - auc: 0.9853 - precision: 0.9148 - recall: 0.8932 - f1score: 0.2482 - val_loss: 2.3138 - val_acc: 0.5722 - val_auc: 0.9853 - val_precision: 0.9153 - val_recall: 0.8939 - val_f1score: 0.1507\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0169 - acc: 0.9931 - auc: 0.9855 - precision: 0.9158 - recall: 0.8947 - f1score: 0.2482 - val_loss: 2.2567 - val_acc: 0.5619 - val_auc: 0.9855 - val_precision: 0.9163 - val_recall: 0.8953 - val_f1score: 0.1487\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.0200 - acc: 0.9937 - auc: 0.9856 - precision: 0.9168 - recall: 0.8961 - f1score: 0.2481 - val_loss: 2.2428 - val_acc: 0.5619 - val_auc: 0.9857 - val_precision: 0.9172 - val_recall: 0.8967 - val_f1score: 0.1496\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.0179 - acc: 0.9939 - auc: 0.9857 - precision: 0.9178 - recall: 0.8974 - f1score: 0.2483 - val_loss: 2.5607 - val_acc: 0.5696 - val_auc: 0.9858 - val_precision: 0.9181 - val_recall: 0.8980 - val_f1score: 0.1482\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0237 - acc: 0.9922 - auc: 0.9859 - precision: 0.9186 - recall: 0.8987 - f1score: 0.2479 - val_loss: 2.2552 - val_acc: 0.5696 - val_auc: 0.9859 - val_precision: 0.9190 - val_recall: 0.8992 - val_f1score: 0.1491\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=150, \n",
    "            epochs=50, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=32, \n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('X_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 3ms/step\n",
      "loss: 2.255, accuracy: 0.570, auc: 0.986, precision: 0.918, recall: 0.899, f1score: 0.149\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 2s 3ms/step\n",
      "loss: 69448.482, accuracy: 0.233, auc: 0.985, precision: 0.917, recall: 0.898, f1score: nan\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_model.save('Inception v3_transfer learning_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
