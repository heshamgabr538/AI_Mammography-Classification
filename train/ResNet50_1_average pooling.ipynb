{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 26,212,740\n",
      "Trainable params: 26,159,620\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.GlobalAveragePooling2D(input_shape=(7,7,2048)))\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(512, activation='relu'))\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='ResNet_average_pooling.hdf5', \n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.1,\n",
    "                1: 1.1,\n",
    "                2: 1,\n",
    "                3: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/42 [==============================] - 32s 747ms/step - loss: 1.4382 - acc: 0.3163 - auc: 0.5673 - precision: 0.4012 - recall: 0.0258 - f1score: 0.1044 - val_loss: 2.4722 - val_acc: 0.2857 - val_auc: 0.5770 - val_precision: 0.3841 - val_recall: 0.0491 - val_f1score: 0.0946\n",
      "Epoch 2/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.3997 - acc: 0.3324 - auc: 0.5815 - precision: 0.3591 - recall: 0.0491 - f1score: 0.1067 - val_loss: 1.4383 - val_acc: 0.2332 - val_auc: 0.5855 - val_precision: 0.3642 - val_recall: 0.0390 - val_f1score: 0.0987\n",
      "Epoch 3/200\n",
      "43/42 [==============================] - 15s 345ms/step - loss: 1.3909 - acc: 0.3492 - auc: 0.5902 - precision: 0.3668 - recall: 0.0340 - f1score: 0.1085 - val_loss: 1.4527 - val_acc: 0.2478 - val_auc: 0.5942 - val_precision: 0.3840 - val_recall: 0.0324 - val_f1score: 0.0987\n",
      "Epoch 4/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.3765 - acc: 0.3879 - auc: 0.5972 - precision: 0.4048 - recall: 0.0344 - f1score: 0.1099 - val_loss: 1.5158 - val_acc: 0.2595 - val_auc: 0.6004 - val_precision: 0.4093 - val_recall: 0.0334 - val_f1score: 0.0975\n",
      "Epoch 5/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.3579 - acc: 0.3769 - auc: 0.6031 - precision: 0.4178 - recall: 0.0326 - f1score: 0.1115 - val_loss: 1.5483 - val_acc: 0.2682 - val_auc: 0.6061 - val_precision: 0.4284 - val_recall: 0.0324 - val_f1score: 0.0977\n",
      "Epoch 6/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.3371 - acc: 0.3813 - auc: 0.6090 - precision: 0.4346 - recall: 0.0313 - f1score: 0.1122 - val_loss: 1.5622 - val_acc: 0.2974 - val_auc: 0.6118 - val_precision: 0.4320 - val_recall: 0.0310 - val_f1score: 0.0983\n",
      "Epoch 7/200\n",
      "43/42 [==============================] - 15s 338ms/step - loss: 1.3364 - acc: 0.3806 - auc: 0.6136 - precision: 0.4377 - recall: 0.0319 - f1score: 0.1131 - val_loss: 1.5462 - val_acc: 0.2828 - val_auc: 0.6156 - val_precision: 0.4479 - val_recall: 0.0328 - val_f1score: 0.0983\n",
      "Epoch 8/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.3338 - acc: 0.3901 - auc: 0.6170 - precision: 0.4494 - recall: 0.0334 - f1score: 0.1135 - val_loss: 1.5383 - val_acc: 0.2799 - val_auc: 0.6189 - val_precision: 0.4495 - val_recall: 0.0362 - val_f1score: 0.0994\n",
      "Epoch 9/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.3228 - acc: 0.3806 - auc: 0.6208 - precision: 0.4450 - recall: 0.0388 - f1score: 0.1152 - val_loss: 1.4466 - val_acc: 0.2915 - val_auc: 0.6232 - val_precision: 0.4528 - val_recall: 0.0426 - val_f1score: 0.1042\n",
      "Epoch 10/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2958 - acc: 0.3857 - auc: 0.6264 - precision: 0.4559 - recall: 0.0458 - f1score: 0.1177 - val_loss: 1.6614 - val_acc: 0.2857 - val_auc: 0.6278 - val_precision: 0.4608 - val_recall: 0.0494 - val_f1score: 0.0995\n",
      "Epoch 11/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2812 - acc: 0.4207 - auc: 0.6303 - precision: 0.4651 - recall: 0.0523 - f1score: 0.1189 - val_loss: 1.3921 - val_acc: 0.3440 - val_auc: 0.6330 - val_precision: 0.4717 - val_recall: 0.0547 - val_f1score: 0.1095\n",
      "Epoch 12/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2667 - acc: 0.4222 - auc: 0.6360 - precision: 0.4805 - recall: 0.0574 - f1score: 0.1202 - val_loss: 1.3464 - val_acc: 0.3703 - val_auc: 0.6386 - val_precision: 0.4872 - val_recall: 0.0602 - val_f1score: 0.1124\n",
      "Epoch 13/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.2688 - acc: 0.4134 - auc: 0.6417 - precision: 0.4929 - recall: 0.0630 - f1score: 0.1207 - val_loss: 1.2738 - val_acc: 0.3907 - val_auc: 0.6442 - val_precision: 0.4975 - val_recall: 0.0660 - val_f1score: 0.1168\n",
      "Epoch 14/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2418 - acc: 0.4361 - auc: 0.6472 - precision: 0.5013 - recall: 0.0682 - f1score: 0.1230 - val_loss: 1.2711 - val_acc: 0.3965 - val_auc: 0.6504 - val_precision: 0.5043 - val_recall: 0.0707 - val_f1score: 0.1178\n",
      "Epoch 15/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2435 - acc: 0.4083 - auc: 0.6528 - precision: 0.5075 - recall: 0.0727 - f1score: 0.1229 - val_loss: 1.2171 - val_acc: 0.4315 - val_auc: 0.6557 - val_precision: 0.5093 - val_recall: 0.0753 - val_f1score: 0.1214\n",
      "Epoch 16/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.2420 - acc: 0.4405 - auc: 0.6581 - precision: 0.5137 - recall: 0.0775 - f1score: 0.1235 - val_loss: 1.2563 - val_acc: 0.3994 - val_auc: 0.6605 - val_precision: 0.5173 - val_recall: 0.0800 - val_f1score: 0.1191\n",
      "Epoch 17/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2370 - acc: 0.4178 - auc: 0.6627 - precision: 0.5184 - recall: 0.0819 - f1score: 0.1238 - val_loss: 1.1982 - val_acc: 0.4052 - val_auc: 0.6648 - val_precision: 0.5182 - val_recall: 0.0837 - val_f1score: 0.1228\n",
      "Epoch 18/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.2407 - acc: 0.4390 - auc: 0.6668 - precision: 0.5201 - recall: 0.0857 - f1score: 0.1239 - val_loss: 1.2022 - val_acc: 0.3878 - val_auc: 0.6688 - val_precision: 0.5217 - val_recall: 0.0876 - val_f1score: 0.1223\n",
      "Epoch 19/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2010 - acc: 0.4251 - auc: 0.6710 - precision: 0.5244 - recall: 0.0895 - f1score: 0.1266 - val_loss: 1.3632 - val_acc: 0.3936 - val_auc: 0.6727 - val_precision: 0.5252 - val_recall: 0.0917 - val_f1score: 0.1164\n",
      "Epoch 20/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1999 - acc: 0.4463 - auc: 0.6746 - precision: 0.5263 - recall: 0.0936 - f1score: 0.1277 - val_loss: 1.2472 - val_acc: 0.3994 - val_auc: 0.6763 - val_precision: 0.5284 - val_recall: 0.0958 - val_f1score: 0.1210\n",
      "Epoch 21/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.2073 - acc: 0.4332 - auc: 0.6780 - precision: 0.5303 - recall: 0.0979 - f1score: 0.1270 - val_loss: 1.3001 - val_acc: 0.3790 - val_auc: 0.6794 - val_precision: 0.5307 - val_recall: 0.0998 - val_f1score: 0.1185\n",
      "Epoch 22/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1828 - acc: 0.4536 - auc: 0.6813 - precision: 0.5309 - recall: 0.1014 - f1score: 0.1290 - val_loss: 1.2464 - val_acc: 0.4052 - val_auc: 0.6828 - val_precision: 0.5316 - val_recall: 0.1031 - val_f1score: 0.1218\n",
      "Epoch 23/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1900 - acc: 0.4631 - auc: 0.6846 - precision: 0.5317 - recall: 0.1054 - f1score: 0.1297 - val_loss: 1.2606 - val_acc: 0.3819 - val_auc: 0.6860 - val_precision: 0.5317 - val_recall: 0.1076 - val_f1score: 0.1217\n",
      "Epoch 24/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1823 - acc: 0.4551 - auc: 0.6874 - precision: 0.5326 - recall: 0.1095 - f1score: 0.1295 - val_loss: 1.2669 - val_acc: 0.3907 - val_auc: 0.6889 - val_precision: 0.5339 - val_recall: 0.1118 - val_f1score: 0.1216\n",
      "Epoch 25/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1668 - acc: 0.4792 - auc: 0.6903 - precision: 0.5347 - recall: 0.1140 - f1score: 0.1308 - val_loss: 1.2707 - val_acc: 0.4082 - val_auc: 0.6918 - val_precision: 0.5365 - val_recall: 0.1160 - val_f1score: 0.1224\n",
      "Epoch 26/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1703 - acc: 0.4587 - auc: 0.6932 - precision: 0.5377 - recall: 0.1181 - f1score: 0.1312 - val_loss: 1.4487 - val_acc: 0.3848 - val_auc: 0.6942 - val_precision: 0.5380 - val_recall: 0.1200 - val_f1score: 0.1158\n",
      "Epoch 27/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1745 - acc: 0.4543 - auc: 0.6952 - precision: 0.5391 - recall: 0.1220 - f1score: 0.1305 - val_loss: 1.3293 - val_acc: 0.4227 - val_auc: 0.6962 - val_precision: 0.5396 - val_recall: 0.1240 - val_f1score: 0.1211\n",
      "Epoch 28/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1816 - acc: 0.4595 - auc: 0.6972 - precision: 0.5391 - recall: 0.1257 - f1score: 0.1303 - val_loss: 1.2795 - val_acc: 0.3790 - val_auc: 0.6983 - val_precision: 0.5381 - val_recall: 0.1271 - val_f1score: 0.1220\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1620 - acc: 0.4660 - auc: 0.6994 - precision: 0.5379 - recall: 0.1286 - f1score: 0.1313 - val_loss: 1.2302 - val_acc: 0.3907 - val_auc: 0.7005 - val_precision: 0.5377 - val_recall: 0.1301 - val_f1score: 0.1238\n",
      "Epoch 30/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1558 - acc: 0.4646 - auc: 0.7017 - precision: 0.5372 - recall: 0.1318 - f1score: 0.1322 - val_loss: 1.1830 - val_acc: 0.3994 - val_auc: 0.7028 - val_precision: 0.5372 - val_recall: 0.1334 - val_f1score: 0.1264\n",
      "Epoch 31/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1772 - acc: 0.4522 - auc: 0.7037 - precision: 0.5378 - recall: 0.1346 - f1score: 0.1307 - val_loss: 1.2103 - val_acc: 0.4227 - val_auc: 0.7047 - val_precision: 0.5378 - val_recall: 0.1359 - val_f1score: 0.1247\n",
      "Epoch 32/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1432 - acc: 0.4697 - auc: 0.7058 - precision: 0.5390 - recall: 0.1376 - f1score: 0.1332 - val_loss: 1.1784 - val_acc: 0.4315 - val_auc: 0.7069 - val_precision: 0.5392 - val_recall: 0.1392 - val_f1score: 0.1277\n",
      "Epoch 33/200\n",
      "43/42 [==============================] - 15s 342ms/step - loss: 1.1541 - acc: 0.4755 - auc: 0.7080 - precision: 0.5391 - recall: 0.1408 - f1score: 0.1331 - val_loss: 1.2804 - val_acc: 0.4082 - val_auc: 0.7089 - val_precision: 0.5386 - val_recall: 0.1422 - val_f1score: 0.1224\n",
      "Epoch 34/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1330 - acc: 0.4711 - auc: 0.7097 - precision: 0.5388 - recall: 0.1436 - f1score: 0.1336 - val_loss: 1.2795 - val_acc: 0.3965 - val_auc: 0.7106 - val_precision: 0.5388 - val_recall: 0.1452 - val_f1score: 0.1223\n",
      "Epoch 35/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1330 - acc: 0.4624 - auc: 0.7115 - precision: 0.5389 - recall: 0.1466 - f1score: 0.1340 - val_loss: 1.2155 - val_acc: 0.4402 - val_auc: 0.7124 - val_precision: 0.5388 - val_recall: 0.1480 - val_f1score: 0.1256\n",
      "Epoch 36/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1344 - acc: 0.4806 - auc: 0.7133 - precision: 0.5395 - recall: 0.1496 - f1score: 0.1352 - val_loss: 1.2946 - val_acc: 0.3703 - val_auc: 0.7140 - val_precision: 0.5397 - val_recall: 0.1513 - val_f1score: 0.1207\n",
      "Epoch 37/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1355 - acc: 0.4821 - auc: 0.7148 - precision: 0.5401 - recall: 0.1529 - f1score: 0.1347 - val_loss: 1.1743 - val_acc: 0.3936 - val_auc: 0.7155 - val_precision: 0.5397 - val_recall: 0.1545 - val_f1score: 0.1273\n",
      "Epoch 38/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1360 - acc: 0.4770 - auc: 0.7164 - precision: 0.5400 - recall: 0.1559 - f1score: 0.1347 - val_loss: 1.1738 - val_acc: 0.4227 - val_auc: 0.7172 - val_precision: 0.5406 - val_recall: 0.1572 - val_f1score: 0.1285\n",
      "Epoch 39/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1502 - acc: 0.4763 - auc: 0.7179 - precision: 0.5402 - recall: 0.1583 - f1score: 0.1334 - val_loss: 1.1704 - val_acc: 0.4227 - val_auc: 0.7187 - val_precision: 0.5398 - val_recall: 0.1594 - val_f1score: 0.1289\n",
      "Epoch 40/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1388 - acc: 0.4682 - auc: 0.7193 - precision: 0.5400 - recall: 0.1605 - f1score: 0.1337 - val_loss: 1.1317 - val_acc: 0.4286 - val_auc: 0.7201 - val_precision: 0.5400 - val_recall: 0.1617 - val_f1score: 0.1301\n",
      "Epoch 41/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1285 - acc: 0.4865 - auc: 0.7209 - precision: 0.5403 - recall: 0.1628 - f1score: 0.1350 - val_loss: 1.1462 - val_acc: 0.4461 - val_auc: 0.7217 - val_precision: 0.5401 - val_recall: 0.1638 - val_f1score: 0.1325\n",
      "Epoch 42/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1255 - acc: 0.4828 - auc: 0.7225 - precision: 0.5404 - recall: 0.1649 - f1score: 0.1357 - val_loss: 1.2099 - val_acc: 0.3994 - val_auc: 0.7232 - val_precision: 0.5405 - val_recall: 0.1661 - val_f1score: 0.1271\n",
      "Epoch 43/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1561 - acc: 0.4551 - auc: 0.7237 - precision: 0.5408 - recall: 0.1674 - f1score: 0.1333 - val_loss: 1.2442 - val_acc: 0.4315 - val_auc: 0.7241 - val_precision: 0.5403 - val_recall: 0.1687 - val_f1score: 0.1265\n",
      "Epoch 44/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1516 - acc: 0.4741 - auc: 0.7246 - precision: 0.5403 - recall: 0.1698 - f1score: 0.1336 - val_loss: 1.3725 - val_acc: 0.3848 - val_auc: 0.7249 - val_precision: 0.5400 - val_recall: 0.1707 - val_f1score: 0.1194\n",
      "Epoch 45/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1567 - acc: 0.4799 - auc: 0.7253 - precision: 0.5401 - recall: 0.1717 - f1score: 0.1334 - val_loss: 1.2659 - val_acc: 0.3819 - val_auc: 0.7257 - val_precision: 0.5395 - val_recall: 0.1727 - val_f1score: 0.1228\n",
      "Epoch 46/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1213 - acc: 0.4777 - auc: 0.7262 - precision: 0.5390 - recall: 0.1737 - f1score: 0.1359 - val_loss: 1.1877 - val_acc: 0.4257 - val_auc: 0.7268 - val_precision: 0.5391 - val_recall: 0.1748 - val_f1score: 0.1302\n",
      "Epoch 47/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1241 - acc: 0.4806 - auc: 0.7274 - precision: 0.5399 - recall: 0.1760 - f1score: 0.1355 - val_loss: 1.2713 - val_acc: 0.4402 - val_auc: 0.7279 - val_precision: 0.5400 - val_recall: 0.1770 - val_f1score: 0.1265\n",
      "Epoch 48/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0985 - acc: 0.5062 - auc: 0.7285 - precision: 0.5408 - recall: 0.1781 - f1score: 0.1379 - val_loss: 1.1296 - val_acc: 0.4548 - val_auc: 0.7292 - val_precision: 0.5413 - val_recall: 0.1794 - val_f1score: 0.1342\n",
      "Epoch 49/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0972 - acc: 0.4872 - auc: 0.7300 - precision: 0.5417 - recall: 0.1807 - f1score: 0.1378 - val_loss: 1.1555 - val_acc: 0.4315 - val_auc: 0.7306 - val_precision: 0.5414 - val_recall: 0.1817 - val_f1score: 0.1326\n",
      "Epoch 50/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0968 - acc: 0.5084 - auc: 0.7312 - precision: 0.5419 - recall: 0.1828 - f1score: 0.1384 - val_loss: 1.2235 - val_acc: 0.4257 - val_auc: 0.7318 - val_precision: 0.5421 - val_recall: 0.1840 - val_f1score: 0.1287\n",
      "Epoch 51/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0829 - acc: 0.5113 - auc: 0.7325 - precision: 0.5425 - recall: 0.1852 - f1score: 0.1390 - val_loss: 1.2083 - val_acc: 0.4431 - val_auc: 0.7331 - val_precision: 0.5429 - val_recall: 0.1863 - val_f1score: 0.1306\n",
      "Epoch 52/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0979 - acc: 0.4931 - auc: 0.7336 - precision: 0.5429 - recall: 0.1873 - f1score: 0.1381 - val_loss: 1.1439 - val_acc: 0.4490 - val_auc: 0.7342 - val_precision: 0.5431 - val_recall: 0.1883 - val_f1score: 0.1319\n",
      "Epoch 53/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1287 - acc: 0.4821 - auc: 0.7347 - precision: 0.5431 - recall: 0.1892 - f1score: 0.1360 - val_loss: 1.2873 - val_acc: 0.4169 - val_auc: 0.7350 - val_precision: 0.5432 - val_recall: 0.1901 - val_f1score: 0.1249\n",
      "Epoch 54/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0952 - acc: 0.5172 - auc: 0.7355 - precision: 0.5437 - recall: 0.1912 - f1score: 0.1388 - val_loss: 1.2076 - val_acc: 0.4140 - val_auc: 0.7360 - val_precision: 0.5439 - val_recall: 0.1922 - val_f1score: 0.1305\n",
      "Epoch 55/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0958 - acc: 0.4836 - auc: 0.7365 - precision: 0.5440 - recall: 0.1930 - f1score: 0.1380 - val_loss: 1.4552 - val_acc: 0.3907 - val_auc: 0.7368 - val_precision: 0.5437 - val_recall: 0.1939 - val_f1score: 0.1187\n",
      "Epoch 56/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.0949 - acc: 0.4974 - auc: 0.7371 - precision: 0.5438 - recall: 0.1949 - f1score: 0.1388 - val_loss: 1.2808 - val_acc: 0.4052 - val_auc: 0.7376 - val_precision: 0.5439 - val_recall: 0.1958 - val_f1score: 0.1275\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 334ms/step - loss: 1.1055 - acc: 0.4967 - auc: 0.7379 - precision: 0.5440 - recall: 0.1968 - f1score: 0.1377 - val_loss: 1.3377 - val_acc: 0.3703 - val_auc: 0.7383 - val_precision: 0.5440 - val_recall: 0.1976 - val_f1score: 0.1227\n",
      "Epoch 58/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0651 - acc: 0.5332 - auc: 0.7388 - precision: 0.5443 - recall: 0.1988 - f1score: 0.1411 - val_loss: 1.2974 - val_acc: 0.4140 - val_auc: 0.7392 - val_precision: 0.5442 - val_recall: 0.1999 - val_f1score: 0.1259\n",
      "Epoch 59/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0818 - acc: 0.4989 - auc: 0.7396 - precision: 0.5439 - recall: 0.2008 - f1score: 0.1397 - val_loss: 1.1439 - val_acc: 0.4956 - val_auc: 0.7401 - val_precision: 0.5442 - val_recall: 0.2019 - val_f1score: 0.1335\n",
      "Epoch 60/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0691 - acc: 0.5047 - auc: 0.7407 - precision: 0.5445 - recall: 0.2029 - f1score: 0.1408 - val_loss: 1.3665 - val_acc: 0.3907 - val_auc: 0.7410 - val_precision: 0.5444 - val_recall: 0.2038 - val_f1score: 0.1235\n",
      "Epoch 61/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0702 - acc: 0.5106 - auc: 0.7415 - precision: 0.5446 - recall: 0.2049 - f1score: 0.1407 - val_loss: 1.2470 - val_acc: 0.4198 - val_auc: 0.7419 - val_precision: 0.5449 - val_recall: 0.2059 - val_f1score: 0.1292\n",
      "Epoch 62/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0959 - acc: 0.5047 - auc: 0.7423 - precision: 0.5452 - recall: 0.2070 - f1score: 0.1397 - val_loss: 1.2391 - val_acc: 0.4723 - val_auc: 0.7426 - val_precision: 0.5452 - val_recall: 0.2079 - val_f1score: 0.1299\n",
      "Epoch 63/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0733 - acc: 0.5106 - auc: 0.7431 - precision: 0.5456 - recall: 0.2089 - f1score: 0.1406 - val_loss: 1.2377 - val_acc: 0.4665 - val_auc: 0.7435 - val_precision: 0.5455 - val_recall: 0.2097 - val_f1score: 0.1291\n",
      "Epoch 64/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0767 - acc: 0.5164 - auc: 0.7439 - precision: 0.5461 - recall: 0.2105 - f1score: 0.1396 - val_loss: 1.1911 - val_acc: 0.4315 - val_auc: 0.7442 - val_precision: 0.5464 - val_recall: 0.2114 - val_f1score: 0.1307\n",
      "Epoch 65/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0950 - acc: 0.5113 - auc: 0.7446 - precision: 0.5466 - recall: 0.2122 - f1score: 0.1389 - val_loss: 1.2357 - val_acc: 0.4286 - val_auc: 0.7449 - val_precision: 0.5469 - val_recall: 0.2130 - val_f1score: 0.1295\n",
      "Epoch 66/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0898 - acc: 0.5186 - auc: 0.7453 - precision: 0.5473 - recall: 0.2139 - f1score: 0.1394 - val_loss: 1.2072 - val_acc: 0.4431 - val_auc: 0.7456 - val_precision: 0.5478 - val_recall: 0.2148 - val_f1score: 0.1314\n",
      "Epoch 67/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0591 - acc: 0.5179 - auc: 0.7461 - precision: 0.5482 - recall: 0.2157 - f1score: 0.1413 - val_loss: 1.2997 - val_acc: 0.3994 - val_auc: 0.7464 - val_precision: 0.5482 - val_recall: 0.2165 - val_f1score: 0.1266\n",
      "Epoch 68/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0701 - acc: 0.5150 - auc: 0.7467 - precision: 0.5485 - recall: 0.2174 - f1score: 0.1402 - val_loss: 1.1685 - val_acc: 0.4752 - val_auc: 0.7471 - val_precision: 0.5490 - val_recall: 0.2182 - val_f1score: 0.1346\n",
      "Epoch 69/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0594 - acc: 0.5040 - auc: 0.7475 - precision: 0.5493 - recall: 0.2191 - f1score: 0.1418 - val_loss: 1.1992 - val_acc: 0.4257 - val_auc: 0.7479 - val_precision: 0.5494 - val_recall: 0.2199 - val_f1score: 0.1311\n",
      "Epoch 70/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0598 - acc: 0.5215 - auc: 0.7483 - precision: 0.5497 - recall: 0.2206 - f1score: 0.1419 - val_loss: 1.1097 - val_acc: 0.4694 - val_auc: 0.7487 - val_precision: 0.5500 - val_recall: 0.2215 - val_f1score: 0.1365\n",
      "Epoch 71/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0436 - acc: 0.5157 - auc: 0.7492 - precision: 0.5504 - recall: 0.2224 - f1score: 0.1431 - val_loss: 1.1273 - val_acc: 0.4227 - val_auc: 0.7496 - val_precision: 0.5503 - val_recall: 0.2232 - val_f1score: 0.1343\n",
      "Epoch 72/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0502 - acc: 0.5245 - auc: 0.7500 - precision: 0.5506 - recall: 0.2241 - f1score: 0.1428 - val_loss: 1.1094 - val_acc: 0.4490 - val_auc: 0.7504 - val_precision: 0.5508 - val_recall: 0.2249 - val_f1score: 0.1359\n",
      "Epoch 73/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0745 - acc: 0.5142 - auc: 0.7508 - precision: 0.5511 - recall: 0.2258 - f1score: 0.1414 - val_loss: 1.1229 - val_acc: 0.4840 - val_auc: 0.7511 - val_precision: 0.5513 - val_recall: 0.2266 - val_f1score: 0.1364\n",
      "Epoch 74/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0253 - acc: 0.5420 - auc: 0.7516 - precision: 0.5519 - recall: 0.2276 - f1score: 0.1444 - val_loss: 1.1356 - val_acc: 0.4956 - val_auc: 0.7521 - val_precision: 0.5526 - val_recall: 0.2286 - val_f1score: 0.1367\n",
      "Epoch 75/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0538 - acc: 0.5237 - auc: 0.7525 - precision: 0.5532 - recall: 0.2296 - f1score: 0.1435 - val_loss: 1.1587 - val_acc: 0.4490 - val_auc: 0.7528 - val_precision: 0.5533 - val_recall: 0.2304 - val_f1score: 0.1337\n",
      "Epoch 76/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0648 - acc: 0.5121 - auc: 0.7532 - precision: 0.5537 - recall: 0.2313 - f1score: 0.1420 - val_loss: 1.0870 - val_acc: 0.4723 - val_auc: 0.7535 - val_precision: 0.5539 - val_recall: 0.2320 - val_f1score: 0.1382\n",
      "Epoch 77/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0738 - acc: 0.5208 - auc: 0.7539 - precision: 0.5542 - recall: 0.2328 - f1score: 0.1414 - val_loss: 1.1019 - val_acc: 0.4869 - val_auc: 0.7542 - val_precision: 0.5543 - val_recall: 0.2335 - val_f1score: 0.1372\n",
      "Epoch 78/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.0582 - acc: 0.5194 - auc: 0.7546 - precision: 0.5549 - recall: 0.2343 - f1score: 0.1421 - val_loss: 1.0685 - val_acc: 0.5073 - val_auc: 0.7549 - val_precision: 0.5550 - val_recall: 0.2350 - val_f1score: 0.1399\n",
      "Epoch 79/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0542 - acc: 0.5201 - auc: 0.7553 - precision: 0.5554 - recall: 0.2357 - f1score: 0.1418 - val_loss: 1.2326 - val_acc: 0.4227 - val_auc: 0.7555 - val_precision: 0.5554 - val_recall: 0.2363 - val_f1score: 0.1293\n",
      "Epoch 80/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0372 - acc: 0.5318 - auc: 0.7558 - precision: 0.5557 - recall: 0.2370 - f1score: 0.1434 - val_loss: 1.1315 - val_acc: 0.4810 - val_auc: 0.7562 - val_precision: 0.5562 - val_recall: 0.2378 - val_f1score: 0.1366\n",
      "Epoch 81/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0536 - acc: 0.5026 - auc: 0.7566 - precision: 0.5563 - recall: 0.2385 - f1score: 0.1426 - val_loss: 1.2118 - val_acc: 0.4257 - val_auc: 0.7568 - val_precision: 0.5561 - val_recall: 0.2391 - val_f1score: 0.1319\n",
      "Epoch 82/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0662 - acc: 0.5194 - auc: 0.7570 - precision: 0.5562 - recall: 0.2397 - f1score: 0.1412 - val_loss: 1.1037 - val_acc: 0.4869 - val_auc: 0.7573 - val_precision: 0.5564 - val_recall: 0.2404 - val_f1score: 0.1371\n",
      "Epoch 83/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0280 - acc: 0.5172 - auc: 0.7577 - precision: 0.5568 - recall: 0.2411 - f1score: 0.1437 - val_loss: 1.1090 - val_acc: 0.4402 - val_auc: 0.7580 - val_precision: 0.5568 - val_recall: 0.2417 - val_f1score: 0.1368\n",
      "Epoch 84/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0473 - acc: 0.5172 - auc: 0.7583 - precision: 0.5569 - recall: 0.2424 - f1score: 0.1432 - val_loss: 1.2926 - val_acc: 0.3907 - val_auc: 0.7585 - val_precision: 0.5570 - val_recall: 0.2430 - val_f1score: 0.1261\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0756 - acc: 0.5106 - auc: 0.7587 - precision: 0.5568 - recall: 0.2435 - f1score: 0.1407 - val_loss: 1.1780 - val_acc: 0.4198 - val_auc: 0.7589 - val_precision: 0.5567 - val_recall: 0.2439 - val_f1score: 0.1311\n",
      "Epoch 86/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0334 - acc: 0.5179 - auc: 0.7592 - precision: 0.5568 - recall: 0.2446 - f1score: 0.1440 - val_loss: 1.1124 - val_acc: 0.4723 - val_auc: 0.7595 - val_precision: 0.5570 - val_recall: 0.2453 - val_f1score: 0.1381\n",
      "Epoch 87/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0281 - acc: 0.5522 - auc: 0.7599 - precision: 0.5575 - recall: 0.2461 - f1score: 0.1455 - val_loss: 1.1606 - val_acc: 0.4519 - val_auc: 0.7602 - val_precision: 0.5578 - val_recall: 0.2469 - val_f1score: 0.1342\n",
      "Epoch 88/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0215 - acc: 0.5310 - auc: 0.7605 - precision: 0.5579 - recall: 0.2475 - f1score: 0.1451 - val_loss: 1.3407 - val_acc: 0.4023 - val_auc: 0.7607 - val_precision: 0.5579 - val_recall: 0.2482 - val_f1score: 0.1254\n",
      "Epoch 89/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0337 - acc: 0.5230 - auc: 0.7610 - precision: 0.5578 - recall: 0.2488 - f1score: 0.1442 - val_loss: 1.3439 - val_acc: 0.3994 - val_auc: 0.7612 - val_precision: 0.5577 - val_recall: 0.2494 - val_f1score: 0.1261\n",
      "Epoch 90/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0270 - acc: 0.5237 - auc: 0.7614 - precision: 0.5578 - recall: 0.2501 - f1score: 0.1447 - val_loss: 1.2434 - val_acc: 0.4402 - val_auc: 0.7616 - val_precision: 0.5579 - val_recall: 0.2508 - val_f1score: 0.1317\n",
      "Epoch 91/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0284 - acc: 0.5310 - auc: 0.7619 - precision: 0.5581 - recall: 0.2515 - f1score: 0.1458 - val_loss: 1.3729 - val_acc: 0.4111 - val_auc: 0.7621 - val_precision: 0.5581 - val_recall: 0.2522 - val_f1score: 0.1246\n",
      "Epoch 92/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0281 - acc: 0.5303 - auc: 0.7623 - precision: 0.5581 - recall: 0.2527 - f1score: 0.1446 - val_loss: 1.3214 - val_acc: 0.4140 - val_auc: 0.7625 - val_precision: 0.5582 - val_recall: 0.2533 - val_f1score: 0.1276\n",
      "Epoch 93/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0383 - acc: 0.5310 - auc: 0.7628 - precision: 0.5584 - recall: 0.2539 - f1score: 0.1446 - val_loss: 1.3126 - val_acc: 0.3790 - val_auc: 0.7629 - val_precision: 0.5583 - val_recall: 0.2545 - val_f1score: 0.1265\n",
      "Epoch 94/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0423 - acc: 0.5340 - auc: 0.7632 - precision: 0.5581 - recall: 0.2550 - f1score: 0.1440 - val_loss: 1.1017 - val_acc: 0.4461 - val_auc: 0.7634 - val_precision: 0.5582 - val_recall: 0.2555 - val_f1score: 0.1357\n",
      "Epoch 95/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0386 - acc: 0.5172 - auc: 0.7637 - precision: 0.5583 - recall: 0.2561 - f1score: 0.1443 - val_loss: 1.2862 - val_acc: 0.4344 - val_auc: 0.7638 - val_precision: 0.5582 - val_recall: 0.2566 - val_f1score: 0.1285\n",
      "Epoch 96/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0268 - acc: 0.5398 - auc: 0.7641 - precision: 0.5584 - recall: 0.2573 - f1score: 0.1453 - val_loss: 1.1493 - val_acc: 0.5015 - val_auc: 0.7643 - val_precision: 0.5586 - val_recall: 0.2580 - val_f1score: 0.1371\n",
      "Epoch 97/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0029 - acc: 0.5500 - auc: 0.7646 - precision: 0.5590 - recall: 0.2587 - f1score: 0.1469 - val_loss: 1.2831 - val_acc: 0.4694 - val_auc: 0.7649 - val_precision: 0.5593 - val_recall: 0.2594 - val_f1score: 0.1321\n",
      "Epoch 98/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0139 - acc: 0.5252 - auc: 0.7651 - precision: 0.5594 - recall: 0.2601 - f1score: 0.1464 - val_loss: 1.1601 - val_acc: 0.4694 - val_auc: 0.7654 - val_precision: 0.5595 - val_recall: 0.2607 - val_f1score: 0.1375\n",
      "Epoch 99/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9946 - acc: 0.5515 - auc: 0.7657 - precision: 0.5598 - recall: 0.2614 - f1score: 0.1482 - val_loss: 1.4810 - val_acc: 0.4111 - val_auc: 0.7659 - val_precision: 0.5599 - val_recall: 0.2621 - val_f1score: 0.1243\n",
      "Epoch 100/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0284 - acc: 0.5325 - auc: 0.7661 - precision: 0.5600 - recall: 0.2627 - f1score: 0.1458 - val_loss: 1.4590 - val_acc: 0.3936 - val_auc: 0.7662 - val_precision: 0.5601 - val_recall: 0.2634 - val_f1score: 0.1241\n",
      "Epoch 101/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9992 - acc: 0.5296 - auc: 0.7664 - precision: 0.5602 - recall: 0.2639 - f1score: 0.1465 - val_loss: 1.3588 - val_acc: 0.4373 - val_auc: 0.7666 - val_precision: 0.5603 - val_recall: 0.2645 - val_f1score: 0.1276\n",
      "Epoch 102/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0354 - acc: 0.5245 - auc: 0.7668 - precision: 0.5604 - recall: 0.2651 - f1score: 0.1449 - val_loss: 1.2283 - val_acc: 0.4257 - val_auc: 0.7670 - val_precision: 0.5605 - val_recall: 0.2656 - val_f1score: 0.1311\n",
      "Epoch 103/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0221 - acc: 0.5237 - auc: 0.7672 - precision: 0.5605 - recall: 0.2662 - f1score: 0.1457 - val_loss: 1.1120 - val_acc: 0.4636 - val_auc: 0.7674 - val_precision: 0.5607 - val_recall: 0.2668 - val_f1score: 0.1383\n",
      "Epoch 104/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9868 - acc: 0.5551 - auc: 0.7677 - precision: 0.5610 - recall: 0.2673 - f1score: 0.1485 - val_loss: 1.1399 - val_acc: 0.4781 - val_auc: 0.7680 - val_precision: 0.5612 - val_recall: 0.2680 - val_f1score: 0.1376\n",
      "Epoch 105/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0539 - acc: 0.5362 - auc: 0.7682 - precision: 0.5615 - recall: 0.2686 - f1score: 0.1445 - val_loss: 1.1508 - val_acc: 0.4519 - val_auc: 0.7684 - val_precision: 0.5617 - val_recall: 0.2692 - val_f1score: 0.1353\n",
      "Epoch 106/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0263 - acc: 0.5376 - auc: 0.7686 - precision: 0.5619 - recall: 0.2698 - f1score: 0.1450 - val_loss: 1.1206 - val_acc: 0.4665 - val_auc: 0.7688 - val_precision: 0.5620 - val_recall: 0.2703 - val_f1score: 0.1371\n",
      "Epoch 107/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9982 - acc: 0.5493 - auc: 0.7691 - precision: 0.5622 - recall: 0.2708 - f1score: 0.1470 - val_loss: 1.2013 - val_acc: 0.4286 - val_auc: 0.7693 - val_precision: 0.5622 - val_recall: 0.2712 - val_f1score: 0.1331\n",
      "Epoch 108/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0139 - acc: 0.5508 - auc: 0.7695 - precision: 0.5624 - recall: 0.2718 - f1score: 0.1472 - val_loss: 1.1634 - val_acc: 0.4927 - val_auc: 0.7698 - val_precision: 0.5625 - val_recall: 0.2724 - val_f1score: 0.1373\n",
      "Epoch 109/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0361 - acc: 0.5252 - auc: 0.7700 - precision: 0.5627 - recall: 0.2730 - f1score: 0.1454 - val_loss: 1.1143 - val_acc: 0.4723 - val_auc: 0.7702 - val_precision: 0.5628 - val_recall: 0.2735 - val_f1score: 0.1386\n",
      "Epoch 110/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0253 - acc: 0.5340 - auc: 0.7704 - precision: 0.5629 - recall: 0.2741 - f1score: 0.1457 - val_loss: 1.5464 - val_acc: 0.4052 - val_auc: 0.7705 - val_precision: 0.5628 - val_recall: 0.2745 - val_f1score: 0.1214\n",
      "Epoch 111/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9952 - acc: 0.5544 - auc: 0.7706 - precision: 0.5629 - recall: 0.2749 - f1score: 0.1476 - val_loss: 1.2878 - val_acc: 0.4402 - val_auc: 0.7708 - val_precision: 0.5631 - val_recall: 0.2754 - val_f1score: 0.1299\n",
      "Epoch 112/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9911 - acc: 0.5537 - auc: 0.7710 - precision: 0.5633 - recall: 0.2760 - f1score: 0.1484 - val_loss: 1.1272 - val_acc: 0.4636 - val_auc: 0.7713 - val_precision: 0.5635 - val_recall: 0.2766 - val_f1score: 0.1380\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9775 - acc: 0.5588 - auc: 0.7715 - precision: 0.5638 - recall: 0.2772 - f1score: 0.1494 - val_loss: 1.1652 - val_acc: 0.4431 - val_auc: 0.7718 - val_precision: 0.5640 - val_recall: 0.2778 - val_f1score: 0.1353\n",
      "Epoch 114/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9988 - acc: 0.5610 - auc: 0.7720 - precision: 0.5642 - recall: 0.2784 - f1score: 0.1487 - val_loss: 1.1108 - val_acc: 0.4694 - val_auc: 0.7723 - val_precision: 0.5644 - val_recall: 0.2790 - val_f1score: 0.1395\n",
      "Epoch 115/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0101 - acc: 0.5281 - auc: 0.7725 - precision: 0.5646 - recall: 0.2795 - f1score: 0.1473 - val_loss: 1.2612 - val_acc: 0.4111 - val_auc: 0.7726 - val_precision: 0.5645 - val_recall: 0.2799 - val_f1score: 0.1307\n",
      "Epoch 116/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9900 - acc: 0.5354 - auc: 0.7729 - precision: 0.5647 - recall: 0.2804 - f1score: 0.1483 - val_loss: 1.0538 - val_acc: 0.4840 - val_auc: 0.7731 - val_precision: 0.5649 - val_recall: 0.2809 - val_f1score: 0.1430\n",
      "Epoch 117/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0056 - acc: 0.5413 - auc: 0.7733 - precision: 0.5651 - recall: 0.2814 - f1score: 0.1475 - val_loss: 1.1362 - val_acc: 0.4869 - val_auc: 0.7735 - val_precision: 0.5653 - val_recall: 0.2819 - val_f1score: 0.1375\n",
      "Epoch 118/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9892 - acc: 0.5413 - auc: 0.7738 - precision: 0.5655 - recall: 0.2824 - f1score: 0.1484 - val_loss: 1.0921 - val_acc: 0.4840 - val_auc: 0.7740 - val_precision: 0.5657 - val_recall: 0.2829 - val_f1score: 0.1413\n",
      "Epoch 119/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9794 - acc: 0.5486 - auc: 0.7742 - precision: 0.5658 - recall: 0.2835 - f1score: 0.1495 - val_loss: 1.1349 - val_acc: 0.4606 - val_auc: 0.7745 - val_precision: 0.5660 - val_recall: 0.2841 - val_f1score: 0.1385\n",
      "Epoch 120/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.0075 - acc: 0.5522 - auc: 0.7747 - precision: 0.5662 - recall: 0.2846 - f1score: 0.1476 - val_loss: 1.1784 - val_acc: 0.4694 - val_auc: 0.7748 - val_precision: 0.5664 - val_recall: 0.2851 - val_f1score: 0.1352\n",
      "Epoch 121/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9621 - acc: 0.5720 - auc: 0.7751 - precision: 0.5667 - recall: 0.2857 - f1score: 0.1507 - val_loss: 1.4425 - val_acc: 0.4169 - val_auc: 0.7753 - val_precision: 0.5668 - val_recall: 0.2862 - val_f1score: 0.1260\n",
      "Epoch 122/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0000 - acc: 0.5632 - auc: 0.7754 - precision: 0.5669 - recall: 0.2868 - f1score: 0.1489 - val_loss: 1.3112 - val_acc: 0.4286 - val_auc: 0.7756 - val_precision: 0.5671 - val_recall: 0.2873 - val_f1score: 0.1310\n",
      "Epoch 123/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9747 - acc: 0.5683 - auc: 0.7758 - precision: 0.5673 - recall: 0.2879 - f1score: 0.1502 - val_loss: 1.6225 - val_acc: 0.3265 - val_auc: 0.7759 - val_precision: 0.5672 - val_recall: 0.2883 - val_f1score: 0.1131\n",
      "Epoch 124/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9679 - acc: 0.5457 - auc: 0.7760 - precision: 0.5673 - recall: 0.2888 - f1score: 0.1503 - val_loss: 1.3733 - val_acc: 0.3994 - val_auc: 0.7761 - val_precision: 0.5673 - val_recall: 0.2893 - val_f1score: 0.1254\n",
      "Epoch 125/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9645 - acc: 0.5566 - auc: 0.7763 - precision: 0.5674 - recall: 0.2898 - f1score: 0.1509 - val_loss: 1.3105 - val_acc: 0.4431 - val_auc: 0.7765 - val_precision: 0.5676 - val_recall: 0.2903 - val_f1score: 0.1309\n",
      "Epoch 126/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9930 - acc: 0.5530 - auc: 0.7767 - precision: 0.5678 - recall: 0.2908 - f1score: 0.1490 - val_loss: 1.2347 - val_acc: 0.4636 - val_auc: 0.7768 - val_precision: 0.5678 - val_recall: 0.2913 - val_f1score: 0.1345\n",
      "Epoch 127/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9975 - acc: 0.5486 - auc: 0.7770 - precision: 0.5680 - recall: 0.2918 - f1score: 0.1487 - val_loss: 1.4218 - val_acc: 0.3848 - val_auc: 0.7771 - val_precision: 0.5679 - val_recall: 0.2921 - val_f1score: 0.1236\n",
      "Epoch 128/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9885 - acc: 0.5588 - auc: 0.7772 - precision: 0.5679 - recall: 0.2926 - f1score: 0.1489 - val_loss: 1.0815 - val_acc: 0.4956 - val_auc: 0.7774 - val_precision: 0.5681 - val_recall: 0.2931 - val_f1score: 0.1413\n",
      "Epoch 129/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9575 - acc: 0.5712 - auc: 0.7777 - precision: 0.5683 - recall: 0.2937 - f1score: 0.1521 - val_loss: 1.1262 - val_acc: 0.5190 - val_auc: 0.7779 - val_precision: 0.5686 - val_recall: 0.2943 - val_f1score: 0.1417\n",
      "Epoch 130/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9728 - acc: 0.5698 - auc: 0.7781 - precision: 0.5688 - recall: 0.2948 - f1score: 0.1506 - val_loss: 1.0738 - val_acc: 0.4781 - val_auc: 0.7783 - val_precision: 0.5691 - val_recall: 0.2953 - val_f1score: 0.1407\n",
      "Epoch 131/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9651 - acc: 0.5749 - auc: 0.7786 - precision: 0.5693 - recall: 0.2959 - f1score: 0.1511 - val_loss: 1.0663 - val_acc: 0.4665 - val_auc: 0.7788 - val_precision: 0.5695 - val_recall: 0.2963 - val_f1score: 0.1415\n",
      "Epoch 132/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9923 - acc: 0.5515 - auc: 0.7790 - precision: 0.5697 - recall: 0.2968 - f1score: 0.1493 - val_loss: 1.0636 - val_acc: 0.5277 - val_auc: 0.7792 - val_precision: 0.5699 - val_recall: 0.2973 - val_f1score: 0.1439\n",
      "Epoch 133/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9707 - acc: 0.5639 - auc: 0.7794 - precision: 0.5701 - recall: 0.2978 - f1score: 0.1509 - val_loss: 1.0750 - val_acc: 0.4956 - val_auc: 0.7796 - val_precision: 0.5702 - val_recall: 0.2982 - val_f1score: 0.1425\n",
      "Epoch 134/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9453 - acc: 0.5705 - auc: 0.7799 - precision: 0.5706 - recall: 0.2988 - f1score: 0.1531 - val_loss: 1.1182 - val_acc: 0.4810 - val_auc: 0.7801 - val_precision: 0.5708 - val_recall: 0.2994 - val_f1score: 0.1413\n",
      "Epoch 135/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9792 - acc: 0.5559 - auc: 0.7803 - precision: 0.5709 - recall: 0.2998 - f1score: 0.1502 - val_loss: 1.1813 - val_acc: 0.4606 - val_auc: 0.7804 - val_precision: 0.5711 - val_recall: 0.3003 - val_f1score: 0.1363\n",
      "Epoch 136/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9689 - acc: 0.5712 - auc: 0.7806 - precision: 0.5713 - recall: 0.3007 - f1score: 0.1512 - val_loss: 1.0937 - val_acc: 0.5015 - val_auc: 0.7808 - val_precision: 0.5714 - val_recall: 0.3012 - val_f1score: 0.1408\n",
      "Epoch 137/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9847 - acc: 0.5588 - auc: 0.7810 - precision: 0.5716 - recall: 0.3017 - f1score: 0.1498 - val_loss: 1.0914 - val_acc: 0.5102 - val_auc: 0.7812 - val_precision: 0.5717 - val_recall: 0.3021 - val_f1score: 0.1408\n",
      "Epoch 138/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9742 - acc: 0.5625 - auc: 0.7814 - precision: 0.5720 - recall: 0.3026 - f1score: 0.1502 - val_loss: 1.1302 - val_acc: 0.4694 - val_auc: 0.7816 - val_precision: 0.5721 - val_recall: 0.3030 - val_f1score: 0.1386\n",
      "Epoch 139/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9625 - acc: 0.5530 - auc: 0.7818 - precision: 0.5722 - recall: 0.3035 - f1score: 0.1509 - val_loss: 1.3757 - val_acc: 0.4198 - val_auc: 0.7819 - val_precision: 0.5722 - val_recall: 0.3039 - val_f1score: 0.1290\n",
      "Epoch 140/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9618 - acc: 0.5720 - auc: 0.7821 - precision: 0.5724 - recall: 0.3044 - f1score: 0.1518 - val_loss: 1.2566 - val_acc: 0.4869 - val_auc: 0.7822 - val_precision: 0.5724 - val_recall: 0.3048 - val_f1score: 0.1336\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9592 - acc: 0.5866 - auc: 0.7824 - precision: 0.5727 - recall: 0.3052 - f1score: 0.1517 - val_loss: 1.0734 - val_acc: 0.4869 - val_auc: 0.7826 - val_precision: 0.5730 - val_recall: 0.3058 - val_f1score: 0.1428\n",
      "Epoch 142/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9743 - acc: 0.5515 - auc: 0.7828 - precision: 0.5731 - recall: 0.3062 - f1score: 0.1506 - val_loss: 1.2716 - val_acc: 0.4636 - val_auc: 0.7829 - val_precision: 0.5731 - val_recall: 0.3066 - val_f1score: 0.1330\n",
      "Epoch 143/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9622 - acc: 0.5785 - auc: 0.7831 - precision: 0.5733 - recall: 0.3071 - f1score: 0.1520 - val_loss: 1.4928 - val_acc: 0.4140 - val_auc: 0.7832 - val_precision: 0.5735 - val_recall: 0.3076 - val_f1score: 0.1253\n",
      "Epoch 144/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9697 - acc: 0.5793 - auc: 0.7833 - precision: 0.5736 - recall: 0.3080 - f1score: 0.1516 - val_loss: 1.5698 - val_acc: 0.4198 - val_auc: 0.7834 - val_precision: 0.5736 - val_recall: 0.3084 - val_f1score: 0.1250\n",
      "Epoch 145/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9493 - acc: 0.5763 - auc: 0.7835 - precision: 0.5738 - recall: 0.3088 - f1score: 0.1526 - val_loss: 1.5035 - val_acc: 0.4373 - val_auc: 0.7837 - val_precision: 0.5739 - val_recall: 0.3093 - val_f1score: 0.1256\n",
      "Epoch 146/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9633 - acc: 0.5698 - auc: 0.7838 - precision: 0.5740 - recall: 0.3097 - f1score: 0.1524 - val_loss: 1.5609 - val_acc: 0.4140 - val_auc: 0.7839 - val_precision: 0.5740 - val_recall: 0.3101 - val_f1score: 0.1223\n",
      "Epoch 147/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9647 - acc: 0.5705 - auc: 0.7840 - precision: 0.5741 - recall: 0.3105 - f1score: 0.1512 - val_loss: 1.2995 - val_acc: 0.4227 - val_auc: 0.7841 - val_precision: 0.5741 - val_recall: 0.3109 - val_f1score: 0.1302\n",
      "Epoch 148/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9450 - acc: 0.5880 - auc: 0.7843 - precision: 0.5743 - recall: 0.3114 - f1score: 0.1523 - val_loss: 1.2121 - val_acc: 0.4927 - val_auc: 0.7844 - val_precision: 0.5746 - val_recall: 0.3118 - val_f1score: 0.1376\n",
      "Epoch 149/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9688 - acc: 0.5741 - auc: 0.7846 - precision: 0.5747 - recall: 0.3122 - f1score: 0.1511 - val_loss: 1.5012 - val_acc: 0.4082 - val_auc: 0.7847 - val_precision: 0.5748 - val_recall: 0.3126 - val_f1score: 0.1262\n",
      "Epoch 150/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9415 - acc: 0.5829 - auc: 0.7848 - precision: 0.5750 - recall: 0.3130 - f1score: 0.1534 - val_loss: 1.3691 - val_acc: 0.4636 - val_auc: 0.7850 - val_precision: 0.5752 - val_recall: 0.3135 - val_f1score: 0.1309\n",
      "Epoch 151/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9447 - acc: 0.5785 - auc: 0.7851 - precision: 0.5753 - recall: 0.3139 - f1score: 0.1526 - val_loss: 1.4948 - val_acc: 0.4373 - val_auc: 0.7852 - val_precision: 0.5755 - val_recall: 0.3143 - val_f1score: 0.1274\n",
      "Epoch 152/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9751 - acc: 0.5654 - auc: 0.7853 - precision: 0.5755 - recall: 0.3146 - f1score: 0.1508 - val_loss: 1.1898 - val_acc: 0.4548 - val_auc: 0.7855 - val_precision: 0.5757 - val_recall: 0.3150 - val_f1score: 0.1361\n",
      "Epoch 153/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9666 - acc: 0.5800 - auc: 0.7856 - precision: 0.5759 - recall: 0.3155 - f1score: 0.1518 - val_loss: 1.1836 - val_acc: 0.4840 - val_auc: 0.7858 - val_precision: 0.5760 - val_recall: 0.3158 - val_f1score: 0.1378\n",
      "Epoch 154/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9836 - acc: 0.5610 - auc: 0.7859 - precision: 0.5761 - recall: 0.3162 - f1score: 0.1501 - val_loss: 1.3093 - val_acc: 0.4023 - val_auc: 0.7860 - val_precision: 0.5762 - val_recall: 0.3165 - val_f1score: 0.1300\n",
      "Epoch 155/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9597 - acc: 0.5814 - auc: 0.7861 - precision: 0.5763 - recall: 0.3169 - f1score: 0.1518 - val_loss: 1.1580 - val_acc: 0.4956 - val_auc: 0.7863 - val_precision: 0.5765 - val_recall: 0.3172 - val_f1score: 0.1375\n",
      "Epoch 156/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9532 - acc: 0.5727 - auc: 0.7865 - precision: 0.5767 - recall: 0.3177 - f1score: 0.1526 - val_loss: 1.0998 - val_acc: 0.4752 - val_auc: 0.7866 - val_precision: 0.5769 - val_recall: 0.3180 - val_f1score: 0.1411\n",
      "Epoch 157/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9508 - acc: 0.5690 - auc: 0.7868 - precision: 0.5770 - recall: 0.3184 - f1score: 0.1519 - val_loss: 1.0644 - val_acc: 0.4985 - val_auc: 0.7869 - val_precision: 0.5772 - val_recall: 0.3188 - val_f1score: 0.1422\n",
      "Epoch 158/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9579 - acc: 0.5829 - auc: 0.7871 - precision: 0.5773 - recall: 0.3192 - f1score: 0.1526 - val_loss: 1.1259 - val_acc: 0.4373 - val_auc: 0.7873 - val_precision: 0.5774 - val_recall: 0.3195 - val_f1score: 0.1382\n",
      "Epoch 159/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9395 - acc: 0.5873 - auc: 0.7874 - precision: 0.5777 - recall: 0.3200 - f1score: 0.1530 - val_loss: 1.1011 - val_acc: 0.5073 - val_auc: 0.7876 - val_precision: 0.5778 - val_recall: 0.3204 - val_f1score: 0.1421\n",
      "Epoch 160/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9496 - acc: 0.5829 - auc: 0.7878 - precision: 0.5780 - recall: 0.3208 - f1score: 0.1535 - val_loss: 1.1866 - val_acc: 0.4490 - val_auc: 0.7879 - val_precision: 0.5782 - val_recall: 0.3212 - val_f1score: 0.1356\n",
      "Epoch 161/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9642 - acc: 0.5632 - auc: 0.7881 - precision: 0.5783 - recall: 0.3216 - f1score: 0.1523 - val_loss: 1.0758 - val_acc: 0.5394 - val_auc: 0.7882 - val_precision: 0.5784 - val_recall: 0.3220 - val_f1score: 0.1428\n",
      "Epoch 162/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9630 - acc: 0.5617 - auc: 0.7884 - precision: 0.5785 - recall: 0.3224 - f1score: 0.1518 - val_loss: 1.1500 - val_acc: 0.4781 - val_auc: 0.7885 - val_precision: 0.5785 - val_recall: 0.3227 - val_f1score: 0.1387\n",
      "Epoch 163/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9599 - acc: 0.5851 - auc: 0.7887 - precision: 0.5787 - recall: 0.3231 - f1score: 0.1520 - val_loss: 1.0677 - val_acc: 0.5073 - val_auc: 0.7888 - val_precision: 0.5788 - val_recall: 0.3235 - val_f1score: 0.1437\n",
      "Epoch 164/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9579 - acc: 0.5785 - auc: 0.7890 - precision: 0.5790 - recall: 0.3239 - f1score: 0.1521 - val_loss: 1.0657 - val_acc: 0.5394 - val_auc: 0.7891 - val_precision: 0.5792 - val_recall: 0.3242 - val_f1score: 0.1435\n",
      "Epoch 165/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9353 - acc: 0.5851 - auc: 0.7893 - precision: 0.5795 - recall: 0.3247 - f1score: 0.1537 - val_loss: 1.0779 - val_acc: 0.4956 - val_auc: 0.7894 - val_precision: 0.5797 - val_recall: 0.3251 - val_f1score: 0.1421\n",
      "Epoch 166/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9376 - acc: 0.5975 - auc: 0.7896 - precision: 0.5800 - recall: 0.3255 - f1score: 0.1543 - val_loss: 1.0828 - val_acc: 0.5248 - val_auc: 0.7898 - val_precision: 0.5801 - val_recall: 0.3258 - val_f1score: 0.1417\n",
      "Epoch 167/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9303 - acc: 0.5829 - auc: 0.7899 - precision: 0.5803 - recall: 0.3262 - f1score: 0.1540 - val_loss: 1.0414 - val_acc: 0.4869 - val_auc: 0.7901 - val_precision: 0.5805 - val_recall: 0.3266 - val_f1score: 0.1440\n",
      "Epoch 168/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9359 - acc: 0.5778 - auc: 0.7903 - precision: 0.5806 - recall: 0.3269 - f1score: 0.1535 - val_loss: 1.0442 - val_acc: 0.4985 - val_auc: 0.7905 - val_precision: 0.5808 - val_recall: 0.3273 - val_f1score: 0.1440\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9381 - acc: 0.5858 - auc: 0.7906 - precision: 0.5809 - recall: 0.3277 - f1score: 0.1546 - val_loss: 1.1140 - val_acc: 0.4606 - val_auc: 0.7908 - val_precision: 0.5811 - val_recall: 0.3281 - val_f1score: 0.1407\n",
      "Epoch 170/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9304 - acc: 0.5822 - auc: 0.7910 - precision: 0.5812 - recall: 0.3285 - f1score: 0.1546 - val_loss: 1.4287 - val_acc: 0.3848 - val_auc: 0.7910 - val_precision: 0.5812 - val_recall: 0.3288 - val_f1score: 0.1249\n",
      "Epoch 171/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9161 - acc: 0.5844 - auc: 0.7912 - precision: 0.5813 - recall: 0.3292 - f1score: 0.1558 - val_loss: 1.1642 - val_acc: 0.4898 - val_auc: 0.7913 - val_precision: 0.5815 - val_recall: 0.3296 - val_f1score: 0.1391\n",
      "Epoch 172/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9356 - acc: 0.5676 - auc: 0.7915 - precision: 0.5816 - recall: 0.3299 - f1score: 0.1538 - val_loss: 1.4468 - val_acc: 0.4315 - val_auc: 0.7916 - val_precision: 0.5816 - val_recall: 0.3302 - val_f1score: 0.1264\n",
      "Epoch 173/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9247 - acc: 0.5931 - auc: 0.7917 - precision: 0.5818 - recall: 0.3306 - f1score: 0.1559 - val_loss: 1.5455 - val_acc: 0.4082 - val_auc: 0.7918 - val_precision: 0.5818 - val_recall: 0.3310 - val_f1score: 0.1261\n",
      "Epoch 174/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9290 - acc: 0.5807 - auc: 0.7919 - precision: 0.5820 - recall: 0.3313 - f1score: 0.1552 - val_loss: 1.5486 - val_acc: 0.4315 - val_auc: 0.7920 - val_precision: 0.5821 - val_recall: 0.3317 - val_f1score: 0.1267\n",
      "Epoch 175/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9255 - acc: 0.5741 - auc: 0.7921 - precision: 0.5822 - recall: 0.3321 - f1score: 0.1555 - val_loss: 1.6813 - val_acc: 0.3557 - val_auc: 0.7922 - val_precision: 0.5821 - val_recall: 0.3324 - val_f1score: 0.1176\n",
      "Epoch 176/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9117 - acc: 0.5917 - auc: 0.7923 - precision: 0.5822 - recall: 0.3327 - f1score: 0.1563 - val_loss: 1.7161 - val_acc: 0.3936 - val_auc: 0.7923 - val_precision: 0.5822 - val_recall: 0.3330 - val_f1score: 0.1192\n",
      "Epoch 177/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9268 - acc: 0.5953 - auc: 0.7924 - precision: 0.5823 - recall: 0.3334 - f1score: 0.1551 - val_loss: 1.5970 - val_acc: 0.3848 - val_auc: 0.7925 - val_precision: 0.5823 - val_recall: 0.3337 - val_f1score: 0.1236\n",
      "Epoch 178/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9197 - acc: 0.5771 - auc: 0.7926 - precision: 0.5824 - recall: 0.3340 - f1score: 0.1553 - val_loss: 1.8029 - val_acc: 0.3965 - val_auc: 0.7926 - val_precision: 0.5824 - val_recall: 0.3343 - val_f1score: 0.1205\n",
      "Epoch 179/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9368 - acc: 0.5785 - auc: 0.7927 - precision: 0.5825 - recall: 0.3347 - f1score: 0.1549 - val_loss: 1.4414 - val_acc: 0.4169 - val_auc: 0.7928 - val_precision: 0.5825 - val_recall: 0.3350 - val_f1score: 0.1277\n",
      "Epoch 180/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9166 - acc: 0.5961 - auc: 0.7929 - precision: 0.5826 - recall: 0.3353 - f1score: 0.1557 - val_loss: 1.3752 - val_acc: 0.4840 - val_auc: 0.7930 - val_precision: 0.5828 - val_recall: 0.3357 - val_f1score: 0.1328\n",
      "Epoch 181/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9034 - acc: 0.5924 - auc: 0.7932 - precision: 0.5830 - recall: 0.3361 - f1score: 0.1567 - val_loss: 1.3574 - val_acc: 0.4344 - val_auc: 0.7933 - val_precision: 0.5831 - val_recall: 0.3365 - val_f1score: 0.1320\n",
      "Epoch 182/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9161 - acc: 0.6070 - auc: 0.7934 - precision: 0.5833 - recall: 0.3369 - f1score: 0.1569 - val_loss: 1.1471 - val_acc: 0.4781 - val_auc: 0.7936 - val_precision: 0.5835 - val_recall: 0.3372 - val_f1score: 0.1395\n",
      "Epoch 183/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9106 - acc: 0.5924 - auc: 0.7937 - precision: 0.5836 - recall: 0.3376 - f1score: 0.1563 - val_loss: 1.1178 - val_acc: 0.4723 - val_auc: 0.7939 - val_precision: 0.5838 - val_recall: 0.3379 - val_f1score: 0.1410\n",
      "Epoch 184/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9070 - acc: 0.6048 - auc: 0.7941 - precision: 0.5840 - recall: 0.3383 - f1score: 0.1576 - val_loss: 1.1339 - val_acc: 0.5219 - val_auc: 0.7942 - val_precision: 0.5842 - val_recall: 0.3387 - val_f1score: 0.1428\n",
      "Epoch 185/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9268 - acc: 0.6048 - auc: 0.7944 - precision: 0.5844 - recall: 0.3391 - f1score: 0.1560 - val_loss: 1.2700 - val_acc: 0.4810 - val_auc: 0.7945 - val_precision: 0.5845 - val_recall: 0.3395 - val_f1score: 0.1353\n",
      "Epoch 186/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9112 - acc: 0.6063 - auc: 0.7946 - precision: 0.5847 - recall: 0.3398 - f1score: 0.1570 - val_loss: 1.1289 - val_acc: 0.4810 - val_auc: 0.7948 - val_precision: 0.5848 - val_recall: 0.3402 - val_f1score: 0.1401\n",
      "Epoch 187/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9205 - acc: 0.5851 - auc: 0.7949 - precision: 0.5849 - recall: 0.3406 - f1score: 0.1557 - val_loss: 1.1583 - val_acc: 0.5015 - val_auc: 0.7950 - val_precision: 0.5850 - val_recall: 0.3409 - val_f1score: 0.1407\n",
      "Epoch 188/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9051 - acc: 0.6004 - auc: 0.7952 - precision: 0.5852 - recall: 0.3412 - f1score: 0.1570 - val_loss: 1.1107 - val_acc: 0.5335 - val_auc: 0.7953 - val_precision: 0.5854 - val_recall: 0.3416 - val_f1score: 0.1438\n",
      "Epoch 189/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9228 - acc: 0.5902 - auc: 0.7955 - precision: 0.5855 - recall: 0.3419 - f1score: 0.1563 - val_loss: 1.1093 - val_acc: 0.5015 - val_auc: 0.7956 - val_precision: 0.5857 - val_recall: 0.3423 - val_f1score: 0.1417\n",
      "Epoch 190/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9151 - acc: 0.5931 - auc: 0.7958 - precision: 0.5858 - recall: 0.3427 - f1score: 0.1565 - val_loss: 1.0853 - val_acc: 0.5015 - val_auc: 0.7959 - val_precision: 0.5859 - val_recall: 0.3430 - val_f1score: 0.1435\n",
      "Epoch 191/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9053 - acc: 0.5997 - auc: 0.7961 - precision: 0.5861 - recall: 0.3433 - f1score: 0.1572 - val_loss: 1.1582 - val_acc: 0.4519 - val_auc: 0.7962 - val_precision: 0.5863 - val_recall: 0.3437 - val_f1score: 0.1389\n",
      "Epoch 192/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9162 - acc: 0.5895 - auc: 0.7963 - precision: 0.5864 - recall: 0.3440 - f1score: 0.1558 - val_loss: 1.1744 - val_acc: 0.4781 - val_auc: 0.7964 - val_precision: 0.5866 - val_recall: 0.3444 - val_f1score: 0.1391\n",
      "Epoch 193/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9153 - acc: 0.5851 - auc: 0.7966 - precision: 0.5867 - recall: 0.3447 - f1score: 0.1558 - val_loss: 1.2393 - val_acc: 0.4781 - val_auc: 0.7967 - val_precision: 0.5868 - val_recall: 0.3450 - val_f1score: 0.1368\n",
      "Epoch 194/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.8906 - acc: 0.6165 - auc: 0.7968 - precision: 0.5870 - recall: 0.3453 - f1score: 0.1586 - val_loss: 1.0587 - val_acc: 0.5248 - val_auc: 0.7970 - val_precision: 0.5872 - val_recall: 0.3457 - val_f1score: 0.1451\n",
      "Epoch 195/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9075 - acc: 0.6150 - auc: 0.7972 - precision: 0.5874 - recall: 0.3461 - f1score: 0.1577 - val_loss: 1.0804 - val_acc: 0.5248 - val_auc: 0.7973 - val_precision: 0.5876 - val_recall: 0.3465 - val_f1score: 0.1444\n",
      "Epoch 196/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.8837 - acc: 0.5997 - auc: 0.7975 - precision: 0.5878 - recall: 0.3468 - f1score: 0.1588 - val_loss: 1.1224 - val_acc: 0.4636 - val_auc: 0.7976 - val_precision: 0.5879 - val_recall: 0.3471 - val_f1score: 0.1413\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 335ms/step - loss: 0.8833 - acc: 0.6129 - auc: 0.7978 - precision: 0.5881 - recall: 0.3475 - f1score: 0.1596 - val_loss: 1.2712 - val_acc: 0.4636 - val_auc: 0.7979 - val_precision: 0.5882 - val_recall: 0.3478 - val_f1score: 0.1353\n",
      "Epoch 198/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.8912 - acc: 0.5953 - auc: 0.7980 - precision: 0.5882 - recall: 0.3482 - f1score: 0.1580 - val_loss: 1.1537 - val_acc: 0.4781 - val_auc: 0.7982 - val_precision: 0.5884 - val_recall: 0.3485 - val_f1score: 0.1426\n",
      "Epoch 199/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.8954 - acc: 0.6019 - auc: 0.7983 - precision: 0.5885 - recall: 0.3489 - f1score: 0.1590 - val_loss: 1.1754 - val_acc: 0.4636 - val_auc: 0.7984 - val_precision: 0.5886 - val_recall: 0.3492 - val_f1score: 0.1388\n",
      "Epoch 200/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.8998 - acc: 0.6004 - auc: 0.7986 - precision: 0.5888 - recall: 0.3496 - f1score: 0.1582 - val_loss: 1.0831 - val_acc: 0.5044 - val_auc: 0.7987 - val_precision: 0.5890 - val_recall: 0.3500 - val_f1score: 0.1451\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=len(X_train)/32, \n",
    "            epochs=200, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=len(X_val)/32, \n",
    "            callbacks=[checkpoint],\n",
    "            class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 3ms/step\n",
      "loss: 1.083, accuracy: 0.504, auc: 0.799, precision: 0.589, recall: 0.350, f1score: 0.145\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "new_model = models.load_model('ResNet_average_pooling.hdf5',compile=False)\n",
    "\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 3s 7ms/step\n",
      "loss: 1.041, accuracy: 0.487, auc: 0.791, precision: 0.525, recall: 0.403, f1score: 0.144\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = new_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
