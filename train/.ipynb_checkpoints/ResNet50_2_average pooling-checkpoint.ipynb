{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 23,542,788\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.GlobalAveragePooling2D(input_shape=(7,7,2048)))\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='ResNet_average_pooling_2.hdf5', \n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.1,\n",
    "                1: 1.1,\n",
    "                2: 1,\n",
    "                3: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/42 [==============================] - 33s 762ms/step - loss: 1.5449 - acc: 0.3083 - auc_1: 0.5666 - precision_1: 0.3027 - recall_1: 0.0805 - f1score: 0.1041 - val_loss: 9.2114 - val_acc: 0.2857 - val_auc_1: 0.5689 - val_precision_1: 0.3311 - val_recall_1: 0.0839 - val_f1score: 0.0777\n",
      "Epoch 2/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.4063 - acc: 0.3324 - auc_1: 0.5704 - precision_1: 0.3186 - recall_1: 0.0769 - f1score: 0.1061 - val_loss: 1.3972 - val_acc: 0.2595 - val_auc_1: 0.5773 - val_precision_1: 0.3240 - val_recall_1: 0.0600 - val_f1score: 0.1013\n",
      "Epoch 3/200\n",
      "43/42 [==============================] - 15s 337ms/step - loss: 1.3700 - acc: 0.3579 - auc_1: 0.5853 - precision_1: 0.3313 - recall_1: 0.0521 - f1score: 0.1093 - val_loss: 1.3985 - val_acc: 0.2799 - val_auc_1: 0.5929 - val_precision_1: 0.3420 - val_recall_1: 0.0472 - val_f1score: 0.1019\n",
      "Epoch 4/200\n",
      "43/42 [==============================] - 15s 347ms/step - loss: 1.3536 - acc: 0.3682 - auc_1: 0.5992 - precision_1: 0.3471 - recall_1: 0.0435 - f1score: 0.1110 - val_loss: 1.4760 - val_acc: 0.2449 - val_auc_1: 0.6034 - val_precision_1: 0.3572 - val_recall_1: 0.0416 - val_f1score: 0.0972\n",
      "Epoch 5/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.3341 - acc: 0.3703 - auc_1: 0.6083 - precision_1: 0.3697 - recall_1: 0.0411 - f1score: 0.1128 - val_loss: 1.4482 - val_acc: 0.2886 - val_auc_1: 0.6118 - val_precision_1: 0.3810 - val_recall_1: 0.0403 - val_f1score: 0.0998\n",
      "Epoch 6/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.3232 - acc: 0.3776 - auc_1: 0.6171 - precision_1: 0.3890 - recall_1: 0.0402 - f1score: 0.1139 - val_loss: 1.4480 - val_acc: 0.2828 - val_auc_1: 0.6200 - val_precision_1: 0.3901 - val_recall_1: 0.0400 - val_f1score: 0.1005\n",
      "Epoch 7/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.3040 - acc: 0.3966 - auc_1: 0.6233 - precision_1: 0.3947 - recall_1: 0.0406 - f1score: 0.1155 - val_loss: 1.4370 - val_acc: 0.2741 - val_auc_1: 0.6272 - val_precision_1: 0.4060 - val_recall_1: 0.0416 - val_f1score: 0.1012\n",
      "Epoch 8/200\n",
      "43/42 [==============================] - 15s 338ms/step - loss: 1.2811 - acc: 0.4010 - auc_1: 0.6305 - precision_1: 0.4172 - recall_1: 0.0443 - f1score: 0.1178 - val_loss: 1.4949 - val_acc: 0.3061 - val_auc_1: 0.6336 - val_precision_1: 0.4281 - val_recall_1: 0.0472 - val_f1score: 0.1011\n",
      "Epoch 9/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.2474 - acc: 0.4280 - auc_1: 0.6375 - precision_1: 0.4319 - recall_1: 0.0495 - f1score: 0.1211 - val_loss: 1.4440 - val_acc: 0.3061 - val_auc_1: 0.6413 - val_precision_1: 0.4405 - val_recall_1: 0.0519 - val_f1score: 0.1047\n",
      "Epoch 10/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.2518 - acc: 0.4427 - auc_1: 0.6439 - precision_1: 0.4493 - recall_1: 0.0546 - f1score: 0.1212 - val_loss: 1.3413 - val_acc: 0.3615 - val_auc_1: 0.6476 - val_precision_1: 0.4586 - val_recall_1: 0.0573 - val_f1score: 0.1103\n",
      "Epoch 11/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2585 - acc: 0.4171 - auc_1: 0.6510 - precision_1: 0.4662 - recall_1: 0.0609 - f1score: 0.1223 - val_loss: 1.3414 - val_acc: 0.3703 - val_auc_1: 0.6532 - val_precision_1: 0.4688 - val_recall_1: 0.0639 - val_f1score: 0.1124\n",
      "Epoch 12/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.2300 - acc: 0.4259 - auc_1: 0.6565 - precision_1: 0.4748 - recall_1: 0.0667 - f1score: 0.1238 - val_loss: 1.3204 - val_acc: 0.3878 - val_auc_1: 0.6592 - val_precision_1: 0.4782 - val_recall_1: 0.0693 - val_f1score: 0.1160\n",
      "Epoch 13/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.2310 - acc: 0.4412 - auc_1: 0.6618 - precision_1: 0.4827 - recall_1: 0.0721 - f1score: 0.1244 - val_loss: 1.2531 - val_acc: 0.3703 - val_auc_1: 0.6648 - val_precision_1: 0.4882 - val_recall_1: 0.0751 - val_f1score: 0.1182\n",
      "Epoch 14/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.2110 - acc: 0.4478 - auc_1: 0.6678 - precision_1: 0.4914 - recall_1: 0.0773 - f1score: 0.1259 - val_loss: 1.2092 - val_acc: 0.4023 - val_auc_1: 0.6707 - val_precision_1: 0.4957 - val_recall_1: 0.0798 - val_f1score: 0.1215\n",
      "Epoch 15/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1990 - acc: 0.4361 - auc_1: 0.6733 - precision_1: 0.4996 - recall_1: 0.0825 - f1score: 0.1272 - val_loss: 1.1800 - val_acc: 0.4111 - val_auc_1: 0.6763 - val_precision_1: 0.5041 - val_recall_1: 0.0852 - val_f1score: 0.1233\n",
      "Epoch 16/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2019 - acc: 0.4339 - auc_1: 0.6789 - precision_1: 0.5082 - recall_1: 0.0877 - f1score: 0.1271 - val_loss: 1.2263 - val_acc: 0.4052 - val_auc_1: 0.6809 - val_precision_1: 0.5097 - val_recall_1: 0.0899 - val_f1score: 0.1216\n",
      "Epoch 17/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2092 - acc: 0.4441 - auc_1: 0.6829 - precision_1: 0.5115 - recall_1: 0.0924 - f1score: 0.1273 - val_loss: 1.1763 - val_acc: 0.4315 - val_auc_1: 0.6850 - val_precision_1: 0.5142 - val_recall_1: 0.0949 - val_f1score: 0.1249\n",
      "Epoch 18/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.2023 - acc: 0.4463 - auc_1: 0.6868 - precision_1: 0.5157 - recall_1: 0.0973 - f1score: 0.1271 - val_loss: 1.1844 - val_acc: 0.4023 - val_auc_1: 0.6887 - val_precision_1: 0.5169 - val_recall_1: 0.0994 - val_f1score: 0.1247\n",
      "Epoch 19/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1954 - acc: 0.4492 - auc_1: 0.6905 - precision_1: 0.5183 - recall_1: 0.1017 - f1score: 0.1283 - val_loss: 1.1693 - val_acc: 0.4082 - val_auc_1: 0.6922 - val_precision_1: 0.5206 - val_recall_1: 0.1042 - val_f1score: 0.1278\n",
      "Epoch 20/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.1902 - acc: 0.4492 - auc_1: 0.6940 - precision_1: 0.5208 - recall_1: 0.1063 - f1score: 0.1288 - val_loss: 1.2084 - val_acc: 0.4082 - val_auc_1: 0.6954 - val_precision_1: 0.5216 - val_recall_1: 0.1084 - val_f1score: 0.1247\n",
      "Epoch 21/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.1768 - acc: 0.4624 - auc_1: 0.6970 - precision_1: 0.5229 - recall_1: 0.1106 - f1score: 0.1302 - val_loss: 1.2271 - val_acc: 0.3965 - val_auc_1: 0.6985 - val_precision_1: 0.5228 - val_recall_1: 0.1131 - val_f1score: 0.1236\n",
      "Epoch 22/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1932 - acc: 0.4478 - auc_1: 0.6997 - precision_1: 0.5230 - recall_1: 0.1150 - f1score: 0.1286 - val_loss: 1.1493 - val_acc: 0.4373 - val_auc_1: 0.7011 - val_precision_1: 0.5239 - val_recall_1: 0.1169 - val_f1score: 0.1280\n",
      "Epoch 23/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.1629 - acc: 0.4697 - auc_1: 0.7024 - precision_1: 0.5255 - recall_1: 0.1189 - f1score: 0.1313 - val_loss: 1.1958 - val_acc: 0.4315 - val_auc_1: 0.7040 - val_precision_1: 0.5280 - val_recall_1: 0.1211 - val_f1score: 0.1263\n",
      "Epoch 24/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1700 - acc: 0.4617 - auc_1: 0.7054 - precision_1: 0.5284 - recall_1: 0.1229 - f1score: 0.1309 - val_loss: 1.2391 - val_acc: 0.4373 - val_auc_1: 0.7065 - val_precision_1: 0.5289 - val_recall_1: 0.1248 - val_f1score: 0.1259\n",
      "Epoch 25/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1669 - acc: 0.4529 - auc_1: 0.7073 - precision_1: 0.5293 - recall_1: 0.1267 - f1score: 0.1310 - val_loss: 1.2585 - val_acc: 0.4198 - val_auc_1: 0.7086 - val_precision_1: 0.5306 - val_recall_1: 0.1289 - val_f1score: 0.1237\n",
      "Epoch 26/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1512 - acc: 0.4711 - auc_1: 0.7098 - precision_1: 0.5322 - recall_1: 0.1309 - f1score: 0.1323 - val_loss: 1.2902 - val_acc: 0.3878 - val_auc_1: 0.7108 - val_precision_1: 0.5317 - val_recall_1: 0.1325 - val_f1score: 0.1220\n",
      "Epoch 27/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1489 - acc: 0.4748 - auc_1: 0.7119 - precision_1: 0.5318 - recall_1: 0.1342 - f1score: 0.1328 - val_loss: 1.2832 - val_acc: 0.4082 - val_auc_1: 0.7128 - val_precision_1: 0.5318 - val_recall_1: 0.1359 - val_f1score: 0.1230\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1559 - acc: 0.4690 - auc_1: 0.7137 - precision_1: 0.5323 - recall_1: 0.1374 - f1score: 0.1323 - val_loss: 1.4669 - val_acc: 0.3324 - val_auc_1: 0.7143 - val_precision_1: 0.5305 - val_recall_1: 0.1388 - val_f1score: 0.1129\n",
      "Epoch 29/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1418 - acc: 0.4792 - auc_1: 0.7151 - precision_1: 0.5296 - recall_1: 0.1403 - f1score: 0.1333 - val_loss: 1.3657 - val_acc: 0.3790 - val_auc_1: 0.7158 - val_precision_1: 0.5302 - val_recall_1: 0.1420 - val_f1score: 0.1192\n",
      "Epoch 30/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1592 - acc: 0.4726 - auc_1: 0.7166 - precision_1: 0.5300 - recall_1: 0.1433 - f1score: 0.1325 - val_loss: 1.2546 - val_acc: 0.3994 - val_auc_1: 0.7172 - val_precision_1: 0.5304 - val_recall_1: 0.1449 - val_f1score: 0.1242\n",
      "Epoch 31/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.1581 - acc: 0.4967 - auc_1: 0.7180 - precision_1: 0.5310 - recall_1: 0.1462 - f1score: 0.1326 - val_loss: 1.2331 - val_acc: 0.4373 - val_auc_1: 0.7188 - val_precision_1: 0.5320 - val_recall_1: 0.1477 - val_f1score: 0.1270\n",
      "Epoch 32/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1328 - acc: 0.4821 - auc_1: 0.7198 - precision_1: 0.5331 - recall_1: 0.1493 - f1score: 0.1344 - val_loss: 1.1526 - val_acc: 0.4898 - val_auc_1: 0.7207 - val_precision_1: 0.5336 - val_recall_1: 0.1507 - val_f1score: 0.1307\n",
      "Epoch 33/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1213 - acc: 0.4945 - auc_1: 0.7218 - precision_1: 0.5349 - recall_1: 0.1523 - f1score: 0.1351 - val_loss: 1.2168 - val_acc: 0.4344 - val_auc_1: 0.7226 - val_precision_1: 0.5355 - val_recall_1: 0.1537 - val_f1score: 0.1273\n",
      "Epoch 34/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.1309 - acc: 0.4785 - auc_1: 0.7234 - precision_1: 0.5368 - recall_1: 0.1553 - f1score: 0.1345 - val_loss: 1.1776 - val_acc: 0.4315 - val_auc_1: 0.7241 - val_precision_1: 0.5366 - val_recall_1: 0.1565 - val_f1score: 0.1293\n",
      "Epoch 35/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 1.1240 - acc: 0.4960 - auc_1: 0.7250 - precision_1: 0.5375 - recall_1: 0.1583 - f1score: 0.1357 - val_loss: 1.2616 - val_acc: 0.4052 - val_auc_1: 0.7257 - val_precision_1: 0.5380 - val_recall_1: 0.1598 - val_f1score: 0.1242\n",
      "Epoch 36/200\n",
      "43/42 [==============================] - 15s 341ms/step - loss: 1.1499 - acc: 0.4668 - auc_1: 0.7263 - precision_1: 0.5387 - recall_1: 0.1611 - f1score: 0.1336 - val_loss: 1.2302 - val_acc: 0.4490 - val_auc_1: 0.7268 - val_precision_1: 0.5383 - val_recall_1: 0.1621 - val_f1score: 0.1279\n",
      "Epoch 37/200\n",
      "43/42 [==============================] - 15s 342ms/step - loss: 1.1469 - acc: 0.4821 - auc_1: 0.7274 - precision_1: 0.5387 - recall_1: 0.1632 - f1score: 0.1333 - val_loss: 1.1742 - val_acc: 0.4402 - val_auc_1: 0.7280 - val_precision_1: 0.5395 - val_recall_1: 0.1644 - val_f1score: 0.1289\n",
      "Epoch 38/200\n",
      "43/42 [==============================] - 15s 343ms/step - loss: 1.1316 - acc: 0.4850 - auc_1: 0.7287 - precision_1: 0.5404 - recall_1: 0.1658 - f1score: 0.1344 - val_loss: 1.2533 - val_acc: 0.4344 - val_auc_1: 0.7292 - val_precision_1: 0.5409 - val_recall_1: 0.1672 - val_f1score: 0.1267\n",
      "Epoch 39/200\n",
      "43/42 [==============================] - 15s 337ms/step - loss: 1.1230 - acc: 0.4843 - auc_1: 0.7299 - precision_1: 0.5414 - recall_1: 0.1687 - f1score: 0.1358 - val_loss: 1.2459 - val_acc: 0.4373 - val_auc_1: 0.7305 - val_precision_1: 0.5420 - val_recall_1: 0.1702 - val_f1score: 0.1281\n",
      "Epoch 40/200\n",
      "43/42 [==============================] - 15s 337ms/step - loss: 1.1215 - acc: 0.5011 - auc_1: 0.7310 - precision_1: 0.5425 - recall_1: 0.1715 - f1score: 0.1356 - val_loss: 1.4399 - val_acc: 0.3732 - val_auc_1: 0.7315 - val_precision_1: 0.5429 - val_recall_1: 0.1728 - val_f1score: 0.1171\n",
      "Epoch 41/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.1259 - acc: 0.4741 - auc_1: 0.7319 - precision_1: 0.5425 - recall_1: 0.1740 - f1score: 0.1351 - val_loss: 1.2126 - val_acc: 0.4111 - val_auc_1: 0.7323 - val_precision_1: 0.5421 - val_recall_1: 0.1751 - val_f1score: 0.1262\n",
      "Epoch 42/200\n",
      "43/42 [==============================] - 15s 338ms/step - loss: 1.0962 - acc: 0.4945 - auc_1: 0.7330 - precision_1: 0.5423 - recall_1: 0.1764 - f1score: 0.1380 - val_loss: 1.1512 - val_acc: 0.4577 - val_auc_1: 0.7337 - val_precision_1: 0.5425 - val_recall_1: 0.1777 - val_f1score: 0.1327\n",
      "Epoch 43/200\n",
      "43/42 [==============================] - 15s 337ms/step - loss: 1.1174 - acc: 0.5084 - auc_1: 0.7344 - precision_1: 0.5436 - recall_1: 0.1791 - f1score: 0.1367 - val_loss: 1.2380 - val_acc: 0.4082 - val_auc_1: 0.7348 - val_precision_1: 0.5439 - val_recall_1: 0.1804 - val_f1score: 0.1268\n",
      "Epoch 44/200\n",
      "43/42 [==============================] - 15s 339ms/step - loss: 1.1112 - acc: 0.4996 - auc_1: 0.7355 - precision_1: 0.5449 - recall_1: 0.1818 - f1score: 0.1375 - val_loss: 1.1480 - val_acc: 0.4431 - val_auc_1: 0.7360 - val_precision_1: 0.5453 - val_recall_1: 0.1831 - val_f1score: 0.1318\n",
      "Epoch 45/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.1052 - acc: 0.4945 - auc_1: 0.7366 - precision_1: 0.5465 - recall_1: 0.1845 - f1score: 0.1372 - val_loss: 1.1256 - val_acc: 0.4840 - val_auc_1: 0.7372 - val_precision_1: 0.5468 - val_recall_1: 0.1856 - val_f1score: 0.1348\n",
      "Epoch 46/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 1.1043 - acc: 0.4989 - auc_1: 0.7379 - precision_1: 0.5474 - recall_1: 0.1869 - f1score: 0.1380 - val_loss: 1.2933 - val_acc: 0.4169 - val_auc_1: 0.7383 - val_precision_1: 0.5476 - val_recall_1: 0.1881 - val_f1score: 0.1263\n",
      "Epoch 47/200\n",
      "43/42 [==============================] - 15s 339ms/step - loss: 1.1041 - acc: 0.4923 - auc_1: 0.7388 - precision_1: 0.5479 - recall_1: 0.1893 - f1score: 0.1376 - val_loss: 1.3102 - val_acc: 0.4082 - val_auc_1: 0.7392 - val_precision_1: 0.5478 - val_recall_1: 0.1904 - val_f1score: 0.1260\n",
      "Epoch 48/200\n",
      "43/42 [==============================] - 16s 366ms/step - loss: 1.1047 - acc: 0.5091 - auc_1: 0.7397 - precision_1: 0.5483 - recall_1: 0.1917 - f1score: 0.1379 - val_loss: 1.2919 - val_acc: 0.4198 - val_auc_1: 0.7401 - val_precision_1: 0.5484 - val_recall_1: 0.1927 - val_f1score: 0.1276\n",
      "Epoch 49/200\n",
      "43/42 [==============================] - 15s 351ms/step - loss: 1.1018 - acc: 0.5150 - auc_1: 0.7405 - precision_1: 0.5490 - recall_1: 0.1939 - f1score: 0.1381 - val_loss: 1.2075 - val_acc: 0.4461 - val_auc_1: 0.7410 - val_precision_1: 0.5494 - val_recall_1: 0.1952 - val_f1score: 0.1290\n",
      "Epoch 50/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 1.0736 - acc: 0.5099 - auc_1: 0.7415 - precision_1: 0.5497 - recall_1: 0.1963 - f1score: 0.1398 - val_loss: 1.2607 - val_acc: 0.4402 - val_auc_1: 0.7421 - val_precision_1: 0.5504 - val_recall_1: 0.1976 - val_f1score: 0.1308\n",
      "Epoch 51/200\n",
      "43/42 [==============================] - 15s 346ms/step - loss: 1.1111 - acc: 0.4872 - auc_1: 0.7425 - precision_1: 0.5507 - recall_1: 0.1987 - f1score: 0.1375 - val_loss: 1.3578 - val_acc: 0.4286 - val_auc_1: 0.7427 - val_precision_1: 0.5509 - val_recall_1: 0.1998 - val_f1score: 0.1242\n",
      "Epoch 52/200\n",
      "43/42 [==============================] - 15s 355ms/step - loss: 1.0958 - acc: 0.5026 - auc_1: 0.7432 - precision_1: 0.5515 - recall_1: 0.2009 - f1score: 0.1392 - val_loss: 1.2828 - val_acc: 0.4198 - val_auc_1: 0.7435 - val_precision_1: 0.5515 - val_recall_1: 0.2020 - val_f1score: 0.1273\n",
      "Epoch 53/200\n",
      "43/42 [==============================] - 15s 352ms/step - loss: 1.1013 - acc: 0.4989 - auc_1: 0.7440 - precision_1: 0.5512 - recall_1: 0.2030 - f1score: 0.1389 - val_loss: 1.2600 - val_acc: 0.4052 - val_auc_1: 0.7443 - val_precision_1: 0.5505 - val_recall_1: 0.2039 - val_f1score: 0.1270\n",
      "Epoch 54/200\n",
      "43/42 [==============================] - 15s 356ms/step - loss: 1.0941 - acc: 0.5106 - auc_1: 0.7447 - precision_1: 0.5507 - recall_1: 0.2048 - f1score: 0.1386 - val_loss: 1.3234 - val_acc: 0.3673 - val_auc_1: 0.7450 - val_precision_1: 0.5510 - val_recall_1: 0.2057 - val_f1score: 0.1235\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 343ms/step - loss: 1.0853 - acc: 0.4916 - auc_1: 0.7454 - precision_1: 0.5510 - recall_1: 0.2066 - f1score: 0.1392 - val_loss: 1.1602 - val_acc: 0.4431 - val_auc_1: 0.7458 - val_precision_1: 0.5515 - val_recall_1: 0.2075 - val_f1score: 0.1332\n",
      "Epoch 56/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0885 - acc: 0.5055 - auc_1: 0.7463 - precision_1: 0.5519 - recall_1: 0.2085 - f1score: 0.1395 - val_loss: 1.1407 - val_acc: 0.4723 - val_auc_1: 0.7467 - val_precision_1: 0.5521 - val_recall_1: 0.2093 - val_f1score: 0.1326\n",
      "Epoch 57/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0890 - acc: 0.5142 - auc_1: 0.7471 - precision_1: 0.5526 - recall_1: 0.2102 - f1score: 0.1393 - val_loss: 1.1251 - val_acc: 0.4723 - val_auc_1: 0.7476 - val_precision_1: 0.5533 - val_recall_1: 0.2113 - val_f1score: 0.1355\n",
      "Epoch 58/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0819 - acc: 0.5040 - auc_1: 0.7480 - precision_1: 0.5537 - recall_1: 0.2123 - f1score: 0.1397 - val_loss: 1.2510 - val_acc: 0.4286 - val_auc_1: 0.7484 - val_precision_1: 0.5536 - val_recall_1: 0.2132 - val_f1score: 0.1282\n",
      "Epoch 59/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0791 - acc: 0.5026 - auc_1: 0.7488 - precision_1: 0.5536 - recall_1: 0.2141 - f1score: 0.1407 - val_loss: 1.1183 - val_acc: 0.5015 - val_auc_1: 0.7493 - val_precision_1: 0.5538 - val_recall_1: 0.2151 - val_f1score: 0.1372\n",
      "Epoch 60/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0831 - acc: 0.5018 - auc_1: 0.7498 - precision_1: 0.5542 - recall_1: 0.2161 - f1score: 0.1400 - val_loss: 1.1192 - val_acc: 0.4810 - val_auc_1: 0.7501 - val_precision_1: 0.5546 - val_recall_1: 0.2171 - val_f1score: 0.1368\n",
      "Epoch 61/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0658 - acc: 0.5223 - auc_1: 0.7507 - precision_1: 0.5552 - recall_1: 0.2181 - f1score: 0.1413 - val_loss: 1.1154 - val_acc: 0.4927 - val_auc_1: 0.7511 - val_precision_1: 0.5557 - val_recall_1: 0.2191 - val_f1score: 0.1380\n",
      "Epoch 62/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0811 - acc: 0.4938 - auc_1: 0.7516 - precision_1: 0.5562 - recall_1: 0.2200 - f1score: 0.1399 - val_loss: 1.1147 - val_acc: 0.4869 - val_auc_1: 0.7519 - val_precision_1: 0.5564 - val_recall_1: 0.2208 - val_f1score: 0.1364\n",
      "Epoch 63/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0763 - acc: 0.5077 - auc_1: 0.7523 - precision_1: 0.5569 - recall_1: 0.2217 - f1score: 0.1404 - val_loss: 1.1893 - val_acc: 0.4490 - val_auc_1: 0.7526 - val_precision_1: 0.5570 - val_recall_1: 0.2225 - val_f1score: 0.1313\n",
      "Epoch 64/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0490 - acc: 0.5274 - auc_1: 0.7530 - precision_1: 0.5574 - recall_1: 0.2233 - f1score: 0.1422 - val_loss: 1.2160 - val_acc: 0.4257 - val_auc_1: 0.7534 - val_precision_1: 0.5577 - val_recall_1: 0.2243 - val_f1score: 0.1300\n",
      "Epoch 65/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0612 - acc: 0.5164 - auc_1: 0.7538 - precision_1: 0.5579 - recall_1: 0.2252 - f1score: 0.1419 - val_loss: 1.1428 - val_acc: 0.4519 - val_auc_1: 0.7542 - val_precision_1: 0.5581 - val_recall_1: 0.2260 - val_f1score: 0.1339\n",
      "Epoch 66/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 1.0623 - acc: 0.5121 - auc_1: 0.7546 - precision_1: 0.5582 - recall_1: 0.2268 - f1score: 0.1414 - val_loss: 1.2359 - val_acc: 0.4431 - val_auc_1: 0.7548 - val_precision_1: 0.5583 - val_recall_1: 0.2276 - val_f1score: 0.1301\n",
      "Epoch 67/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 1.0986 - acc: 0.5091 - auc_1: 0.7551 - precision_1: 0.5584 - recall_1: 0.2283 - f1score: 0.1397 - val_loss: 1.1836 - val_acc: 0.4548 - val_auc_1: 0.7553 - val_precision_1: 0.5584 - val_recall_1: 0.2290 - val_f1score: 0.1333\n",
      "Epoch 68/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0746 - acc: 0.5062 - auc_1: 0.7556 - precision_1: 0.5586 - recall_1: 0.2296 - f1score: 0.1399 - val_loss: 1.1310 - val_acc: 0.4606 - val_auc_1: 0.7560 - val_precision_1: 0.5588 - val_recall_1: 0.2302 - val_f1score: 0.1358\n",
      "Epoch 69/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0654 - acc: 0.5164 - auc_1: 0.7564 - precision_1: 0.5589 - recall_1: 0.2310 - f1score: 0.1421 - val_loss: 1.0794 - val_acc: 0.4752 - val_auc_1: 0.7567 - val_precision_1: 0.5592 - val_recall_1: 0.2318 - val_f1score: 0.1370\n",
      "Epoch 70/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0378 - acc: 0.5420 - auc_1: 0.7572 - precision_1: 0.5596 - recall_1: 0.2327 - f1score: 0.1437 - val_loss: 1.0986 - val_acc: 0.4606 - val_auc_1: 0.7576 - val_precision_1: 0.5599 - val_recall_1: 0.2336 - val_f1score: 0.1358\n",
      "Epoch 71/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 1.0659 - acc: 0.5201 - auc_1: 0.7579 - precision_1: 0.5601 - recall_1: 0.2344 - f1score: 0.1416 - val_loss: 1.1000 - val_acc: 0.4781 - val_auc_1: 0.7582 - val_precision_1: 0.5604 - val_recall_1: 0.2351 - val_f1score: 0.1371\n",
      "Epoch 72/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0619 - acc: 0.5121 - auc_1: 0.7586 - precision_1: 0.5606 - recall_1: 0.2358 - f1score: 0.1420 - val_loss: 1.0686 - val_acc: 0.5044 - val_auc_1: 0.7589 - val_precision_1: 0.5608 - val_recall_1: 0.2366 - val_f1score: 0.1390\n",
      "Epoch 73/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0529 - acc: 0.5237 - auc_1: 0.7593 - precision_1: 0.5613 - recall_1: 0.2374 - f1score: 0.1423 - val_loss: 1.2231 - val_acc: 0.4431 - val_auc_1: 0.7595 - val_precision_1: 0.5613 - val_recall_1: 0.2381 - val_f1score: 0.1316\n",
      "Epoch 74/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0478 - acc: 0.5274 - auc_1: 0.7599 - precision_1: 0.5614 - recall_1: 0.2389 - f1score: 0.1435 - val_loss: 1.2861 - val_acc: 0.4431 - val_auc_1: 0.7601 - val_precision_1: 0.5616 - val_recall_1: 0.2397 - val_f1score: 0.1304\n",
      "Epoch 75/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0457 - acc: 0.5296 - auc_1: 0.7604 - precision_1: 0.5616 - recall_1: 0.2404 - f1score: 0.1437 - val_loss: 1.3137 - val_acc: 0.4140 - val_auc_1: 0.7607 - val_precision_1: 0.5616 - val_recall_1: 0.2412 - val_f1score: 0.1279\n",
      "Epoch 76/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 1.0517 - acc: 0.5267 - auc_1: 0.7609 - precision_1: 0.5617 - recall_1: 0.2418 - f1score: 0.1431 - val_loss: 1.3139 - val_acc: 0.4402 - val_auc_1: 0.7612 - val_precision_1: 0.5619 - val_recall_1: 0.2425 - val_f1score: 0.1290\n",
      "Epoch 77/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0425 - acc: 0.5245 - auc_1: 0.7614 - precision_1: 0.5620 - recall_1: 0.2432 - f1score: 0.1436 - val_loss: 1.0923 - val_acc: 0.4898 - val_auc_1: 0.7617 - val_precision_1: 0.5623 - val_recall_1: 0.2439 - val_f1score: 0.1379\n",
      "Epoch 78/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0657 - acc: 0.5237 - auc_1: 0.7620 - precision_1: 0.5626 - recall_1: 0.2447 - f1score: 0.1424 - val_loss: 1.3291 - val_acc: 0.4344 - val_auc_1: 0.7622 - val_precision_1: 0.5627 - val_recall_1: 0.2454 - val_f1score: 0.1269\n",
      "Epoch 79/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0573 - acc: 0.5230 - auc_1: 0.7624 - precision_1: 0.5626 - recall_1: 0.2460 - f1score: 0.1422 - val_loss: 1.3654 - val_acc: 0.4344 - val_auc_1: 0.7626 - val_precision_1: 0.5628 - val_recall_1: 0.2467 - val_f1score: 0.1268\n",
      "Epoch 80/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0552 - acc: 0.5142 - auc_1: 0.7628 - precision_1: 0.5630 - recall_1: 0.2474 - f1score: 0.1428 - val_loss: 1.6045 - val_acc: 0.3790 - val_auc_1: 0.7629 - val_precision_1: 0.5630 - val_recall_1: 0.2480 - val_f1score: 0.1167\n",
      "Epoch 81/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0615 - acc: 0.5340 - auc_1: 0.7630 - precision_1: 0.5630 - recall_1: 0.2487 - f1score: 0.1425 - val_loss: 1.5152 - val_acc: 0.4169 - val_auc_1: 0.7631 - val_precision_1: 0.5629 - val_recall_1: 0.2492 - val_f1score: 0.1218\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0444 - acc: 0.5435 - auc_1: 0.7633 - precision_1: 0.5632 - recall_1: 0.2500 - f1score: 0.1440 - val_loss: 1.4992 - val_acc: 0.4052 - val_auc_1: 0.7635 - val_precision_1: 0.5634 - val_recall_1: 0.2507 - val_f1score: 0.1219\n",
      "Epoch 83/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0520 - acc: 0.5215 - auc_1: 0.7636 - precision_1: 0.5635 - recall_1: 0.2514 - f1score: 0.1435 - val_loss: 1.2990 - val_acc: 0.4344 - val_auc_1: 0.7638 - val_precision_1: 0.5636 - val_recall_1: 0.2521 - val_f1score: 0.1276\n",
      "Epoch 84/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0436 - acc: 0.5413 - auc_1: 0.7641 - precision_1: 0.5638 - recall_1: 0.2528 - f1score: 0.1440 - val_loss: 1.2438 - val_acc: 0.4402 - val_auc_1: 0.7643 - val_precision_1: 0.5639 - val_recall_1: 0.2535 - val_f1score: 0.1298\n",
      "Epoch 85/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0383 - acc: 0.5332 - auc_1: 0.7646 - precision_1: 0.5641 - recall_1: 0.2541 - f1score: 0.1441 - val_loss: 1.2954 - val_acc: 0.4490 - val_auc_1: 0.7647 - val_precision_1: 0.5642 - val_recall_1: 0.2548 - val_f1score: 0.1286\n",
      "Epoch 86/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0419 - acc: 0.5354 - auc_1: 0.7650 - precision_1: 0.5644 - recall_1: 0.2555 - f1score: 0.1437 - val_loss: 1.3072 - val_acc: 0.4606 - val_auc_1: 0.7652 - val_precision_1: 0.5646 - val_recall_1: 0.2561 - val_f1score: 0.1320\n",
      "Epoch 87/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0415 - acc: 0.5274 - auc_1: 0.7654 - precision_1: 0.5647 - recall_1: 0.2568 - f1score: 0.1440 - val_loss: 1.2395 - val_acc: 0.4344 - val_auc_1: 0.7656 - val_precision_1: 0.5647 - val_recall_1: 0.2573 - val_f1score: 0.1306\n",
      "Epoch 88/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0362 - acc: 0.5245 - auc_1: 0.7658 - precision_1: 0.5648 - recall_1: 0.2580 - f1score: 0.1444 - val_loss: 1.1276 - val_acc: 0.4490 - val_auc_1: 0.7661 - val_precision_1: 0.5649 - val_recall_1: 0.2586 - val_f1score: 0.1347\n",
      "Epoch 89/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0360 - acc: 0.5442 - auc_1: 0.7663 - precision_1: 0.5653 - recall_1: 0.2593 - f1score: 0.1453 - val_loss: 1.1330 - val_acc: 0.4694 - val_auc_1: 0.7666 - val_precision_1: 0.5656 - val_recall_1: 0.2600 - val_f1score: 0.1355\n",
      "Epoch 90/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0092 - acc: 0.5581 - auc_1: 0.7669 - precision_1: 0.5660 - recall_1: 0.2607 - f1score: 0.1470 - val_loss: 1.2806 - val_acc: 0.4723 - val_auc_1: 0.7672 - val_precision_1: 0.5664 - val_recall_1: 0.2614 - val_f1score: 0.1327\n",
      "Epoch 91/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0216 - acc: 0.5420 - auc_1: 0.7674 - precision_1: 0.5666 - recall_1: 0.2621 - f1score: 0.1459 - val_loss: 1.2453 - val_acc: 0.4402 - val_auc_1: 0.7677 - val_precision_1: 0.5668 - val_recall_1: 0.2627 - val_f1score: 0.1319\n",
      "Epoch 92/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0214 - acc: 0.5413 - auc_1: 0.7679 - precision_1: 0.5668 - recall_1: 0.2633 - f1score: 0.1463 - val_loss: 1.4115 - val_acc: 0.4548 - val_auc_1: 0.7681 - val_precision_1: 0.5670 - val_recall_1: 0.2640 - val_f1score: 0.1277\n",
      "Epoch 93/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0346 - acc: 0.5376 - auc_1: 0.7683 - precision_1: 0.5670 - recall_1: 0.2646 - f1score: 0.1448 - val_loss: 1.2774 - val_acc: 0.4286 - val_auc_1: 0.7685 - val_precision_1: 0.5670 - val_recall_1: 0.2652 - val_f1score: 0.1304\n",
      "Epoch 94/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0223 - acc: 0.5427 - auc_1: 0.7687 - precision_1: 0.5673 - recall_1: 0.2658 - f1score: 0.1455 - val_loss: 1.2790 - val_acc: 0.4490 - val_auc_1: 0.7689 - val_precision_1: 0.5674 - val_recall_1: 0.2663 - val_f1score: 0.1316\n",
      "Epoch 95/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0207 - acc: 0.5464 - auc_1: 0.7691 - precision_1: 0.5678 - recall_1: 0.2671 - f1score: 0.1461 - val_loss: 1.1400 - val_acc: 0.4985 - val_auc_1: 0.7694 - val_precision_1: 0.5680 - val_recall_1: 0.2677 - val_f1score: 0.1394\n",
      "Epoch 96/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0301 - acc: 0.5427 - auc_1: 0.7696 - precision_1: 0.5682 - recall_1: 0.2683 - f1score: 0.1452 - val_loss: 1.1195 - val_acc: 0.4898 - val_auc_1: 0.7699 - val_precision_1: 0.5685 - val_recall_1: 0.2689 - val_f1score: 0.1371\n",
      "Epoch 97/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0238 - acc: 0.5391 - auc_1: 0.7701 - precision_1: 0.5688 - recall_1: 0.2695 - f1score: 0.1457 - val_loss: 1.3667 - val_acc: 0.4315 - val_auc_1: 0.7703 - val_precision_1: 0.5690 - val_recall_1: 0.2701 - val_f1score: 0.1270\n",
      "Epoch 98/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0340 - acc: 0.5310 - auc_1: 0.7704 - precision_1: 0.5691 - recall_1: 0.2707 - f1score: 0.1448 - val_loss: 1.3994 - val_acc: 0.4373 - val_auc_1: 0.7706 - val_precision_1: 0.5691 - val_recall_1: 0.2712 - val_f1score: 0.1267\n",
      "Epoch 99/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9957 - acc: 0.5478 - auc_1: 0.7708 - precision_1: 0.5693 - recall_1: 0.2718 - f1score: 0.1473 - val_loss: 1.3741 - val_acc: 0.4257 - val_auc_1: 0.7710 - val_precision_1: 0.5695 - val_recall_1: 0.2725 - val_f1score: 0.1298\n",
      "Epoch 100/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0389 - acc: 0.5281 - auc_1: 0.7711 - precision_1: 0.5696 - recall_1: 0.2730 - f1score: 0.1449 - val_loss: 1.3278 - val_acc: 0.4577 - val_auc_1: 0.7713 - val_precision_1: 0.5697 - val_recall_1: 0.2736 - val_f1score: 0.1310\n",
      "Epoch 101/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0311 - acc: 0.5405 - auc_1: 0.7714 - precision_1: 0.5699 - recall_1: 0.2742 - f1score: 0.1455 - val_loss: 1.2950 - val_acc: 0.4286 - val_auc_1: 0.7716 - val_precision_1: 0.5700 - val_recall_1: 0.2747 - val_f1score: 0.1297\n",
      "Epoch 102/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0339 - acc: 0.5274 - auc_1: 0.7718 - precision_1: 0.5702 - recall_1: 0.2753 - f1score: 0.1456 - val_loss: 1.2133 - val_acc: 0.4606 - val_auc_1: 0.7719 - val_precision_1: 0.5702 - val_recall_1: 0.2757 - val_f1score: 0.1326\n",
      "Epoch 103/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 1.0324 - acc: 0.5318 - auc_1: 0.7721 - precision_1: 0.5703 - recall_1: 0.2762 - f1score: 0.1452 - val_loss: 1.1037 - val_acc: 0.4606 - val_auc_1: 0.7723 - val_precision_1: 0.5704 - val_recall_1: 0.2767 - val_f1score: 0.1386\n",
      "Epoch 104/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0208 - acc: 0.5369 - auc_1: 0.7726 - precision_1: 0.5706 - recall_1: 0.2772 - f1score: 0.1455 - val_loss: 1.1427 - val_acc: 0.4694 - val_auc_1: 0.7728 - val_precision_1: 0.5707 - val_recall_1: 0.2777 - val_f1score: 0.1365\n",
      "Epoch 105/200\n",
      "43/42 [==============================] - 14s 329ms/step - loss: 1.0287 - acc: 0.5464 - auc_1: 0.7730 - precision_1: 0.5709 - recall_1: 0.2782 - f1score: 0.1460 - val_loss: 1.1702 - val_acc: 0.4665 - val_auc_1: 0.7731 - val_precision_1: 0.5711 - val_recall_1: 0.2787 - val_f1score: 0.1349\n",
      "Epoch 106/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0271 - acc: 0.5296 - auc_1: 0.7734 - precision_1: 0.5713 - recall_1: 0.2792 - f1score: 0.1452 - val_loss: 1.6213 - val_acc: 0.3907 - val_auc_1: 0.7734 - val_precision_1: 0.5712 - val_recall_1: 0.2796 - val_f1score: 0.1179\n",
      "Epoch 107/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0248 - acc: 0.5376 - auc_1: 0.7735 - precision_1: 0.5713 - recall_1: 0.2800 - f1score: 0.1454 - val_loss: 1.3967 - val_acc: 0.4490 - val_auc_1: 0.7736 - val_precision_1: 0.5714 - val_recall_1: 0.2805 - val_f1score: 0.1280\n",
      "Epoch 108/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0244 - acc: 0.5544 - auc_1: 0.7738 - precision_1: 0.5716 - recall_1: 0.2810 - f1score: 0.1456 - val_loss: 1.1418 - val_acc: 0.4840 - val_auc_1: 0.7739 - val_precision_1: 0.5718 - val_recall_1: 0.2814 - val_f1score: 0.1371\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9981 - acc: 0.5362 - auc_1: 0.7742 - precision_1: 0.5721 - recall_1: 0.2820 - f1score: 0.1475 - val_loss: 1.1398 - val_acc: 0.4810 - val_auc_1: 0.7744 - val_precision_1: 0.5723 - val_recall_1: 0.2824 - val_f1score: 0.1378\n",
      "Epoch 110/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0014 - acc: 0.5588 - auc_1: 0.7746 - precision_1: 0.5725 - recall_1: 0.2829 - f1score: 0.1482 - val_loss: 1.3054 - val_acc: 0.4694 - val_auc_1: 0.7748 - val_precision_1: 0.5728 - val_recall_1: 0.2835 - val_f1score: 0.1317\n",
      "Epoch 111/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0016 - acc: 0.5522 - auc_1: 0.7750 - precision_1: 0.5731 - recall_1: 0.2842 - f1score: 0.1482 - val_loss: 1.1625 - val_acc: 0.4810 - val_auc_1: 0.7752 - val_precision_1: 0.5734 - val_recall_1: 0.2848 - val_f1score: 0.1385\n",
      "Epoch 112/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0143 - acc: 0.5471 - auc_1: 0.7755 - precision_1: 0.5737 - recall_1: 0.2853 - f1score: 0.1472 - val_loss: 1.5714 - val_acc: 0.3907 - val_auc_1: 0.7755 - val_precision_1: 0.5736 - val_recall_1: 0.2857 - val_f1score: 0.1198\n",
      "Epoch 113/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9989 - acc: 0.5435 - auc_1: 0.7757 - precision_1: 0.5737 - recall_1: 0.2862 - f1score: 0.1476 - val_loss: 1.3781 - val_acc: 0.4548 - val_auc_1: 0.7758 - val_precision_1: 0.5737 - val_recall_1: 0.2866 - val_f1score: 0.1292\n",
      "Epoch 114/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9978 - acc: 0.5588 - auc_1: 0.7760 - precision_1: 0.5739 - recall_1: 0.2871 - f1score: 0.1486 - val_loss: 1.3620 - val_acc: 0.4227 - val_auc_1: 0.7761 - val_precision_1: 0.5740 - val_recall_1: 0.2877 - val_f1score: 0.1280\n",
      "Epoch 115/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0034 - acc: 0.5464 - auc_1: 0.7763 - precision_1: 0.5741 - recall_1: 0.2882 - f1score: 0.1479 - val_loss: 1.0947 - val_acc: 0.5015 - val_auc_1: 0.7765 - val_precision_1: 0.5744 - val_recall_1: 0.2888 - val_f1score: 0.1408\n",
      "Epoch 116/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9759 - acc: 0.5793 - auc_1: 0.7767 - precision_1: 0.5747 - recall_1: 0.2893 - f1score: 0.1500 - val_loss: 1.2105 - val_acc: 0.4636 - val_auc_1: 0.7770 - val_precision_1: 0.5749 - val_recall_1: 0.2899 - val_f1score: 0.1350\n",
      "Epoch 117/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0130 - acc: 0.5405 - auc_1: 0.7771 - precision_1: 0.5750 - recall_1: 0.2904 - f1score: 0.1474 - val_loss: 1.0817 - val_acc: 0.4898 - val_auc_1: 0.7773 - val_precision_1: 0.5750 - val_recall_1: 0.2908 - val_f1score: 0.1383\n",
      "Epoch 118/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 1.0086 - acc: 0.5551 - auc_1: 0.7775 - precision_1: 0.5753 - recall_1: 0.2913 - f1score: 0.1478 - val_loss: 1.1094 - val_acc: 0.4927 - val_auc_1: 0.7777 - val_precision_1: 0.5755 - val_recall_1: 0.2918 - val_f1score: 0.1403\n",
      "Epoch 119/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9863 - acc: 0.5471 - auc_1: 0.7780 - precision_1: 0.5757 - recall_1: 0.2923 - f1score: 0.1493 - val_loss: 1.1019 - val_acc: 0.4723 - val_auc_1: 0.7782 - val_precision_1: 0.5758 - val_recall_1: 0.2927 - val_f1score: 0.1384\n",
      "Epoch 120/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9936 - acc: 0.5515 - auc_1: 0.7784 - precision_1: 0.5759 - recall_1: 0.2931 - f1score: 0.1477 - val_loss: 1.3250 - val_acc: 0.4227 - val_auc_1: 0.7785 - val_precision_1: 0.5760 - val_recall_1: 0.2935 - val_f1score: 0.1288\n",
      "Epoch 121/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9882 - acc: 0.5500 - auc_1: 0.7786 - precision_1: 0.5760 - recall_1: 0.2940 - f1score: 0.1490 - val_loss: 1.5802 - val_acc: 0.4257 - val_auc_1: 0.7787 - val_precision_1: 0.5760 - val_recall_1: 0.2944 - val_f1score: 0.1215\n",
      "Epoch 122/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0070 - acc: 0.5515 - auc_1: 0.7789 - precision_1: 0.5760 - recall_1: 0.2948 - f1score: 0.1484 - val_loss: 1.3195 - val_acc: 0.4373 - val_auc_1: 0.7790 - val_precision_1: 0.5760 - val_recall_1: 0.2953 - val_f1score: 0.1294\n",
      "Epoch 123/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9792 - acc: 0.5610 - auc_1: 0.7791 - precision_1: 0.5761 - recall_1: 0.2957 - f1score: 0.1497 - val_loss: 1.2330 - val_acc: 0.4519 - val_auc_1: 0.7793 - val_precision_1: 0.5762 - val_recall_1: 0.2961 - val_f1score: 0.1339\n",
      "Epoch 124/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9766 - acc: 0.5646 - auc_1: 0.7795 - precision_1: 0.5763 - recall_1: 0.2966 - f1score: 0.1503 - val_loss: 1.2797 - val_acc: 0.4286 - val_auc_1: 0.7797 - val_precision_1: 0.5765 - val_recall_1: 0.2971 - val_f1score: 0.1303\n",
      "Epoch 125/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0008 - acc: 0.5471 - auc_1: 0.7798 - precision_1: 0.5765 - recall_1: 0.2975 - f1score: 0.1484 - val_loss: 1.2175 - val_acc: 0.4606 - val_auc_1: 0.7800 - val_precision_1: 0.5766 - val_recall_1: 0.2980 - val_f1score: 0.1333\n",
      "Epoch 126/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 1.0102 - acc: 0.5544 - auc_1: 0.7801 - precision_1: 0.5767 - recall_1: 0.2984 - f1score: 0.1479 - val_loss: 1.2373 - val_acc: 0.4519 - val_auc_1: 0.7803 - val_precision_1: 0.5767 - val_recall_1: 0.2988 - val_f1score: 0.1316\n",
      "Epoch 127/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9628 - acc: 0.5712 - auc_1: 0.7805 - precision_1: 0.5769 - recall_1: 0.2993 - f1score: 0.1508 - val_loss: 1.3724 - val_acc: 0.4082 - val_auc_1: 0.7806 - val_precision_1: 0.5770 - val_recall_1: 0.2997 - val_f1score: 0.1257\n",
      "Epoch 128/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9753 - acc: 0.5632 - auc_1: 0.7808 - precision_1: 0.5772 - recall_1: 0.3002 - f1score: 0.1506 - val_loss: 1.3838 - val_acc: 0.4169 - val_auc_1: 0.7809 - val_precision_1: 0.5773 - val_recall_1: 0.3006 - val_f1score: 0.1288\n",
      "Epoch 129/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9825 - acc: 0.5639 - auc_1: 0.7810 - precision_1: 0.5775 - recall_1: 0.3011 - f1score: 0.1499 - val_loss: 1.3001 - val_acc: 0.4519 - val_auc_1: 0.7812 - val_precision_1: 0.5776 - val_recall_1: 0.3015 - val_f1score: 0.1308\n",
      "Epoch 130/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9593 - acc: 0.5698 - auc_1: 0.7814 - precision_1: 0.5778 - recall_1: 0.3020 - f1score: 0.1521 - val_loss: 1.2469 - val_acc: 0.4548 - val_auc_1: 0.7815 - val_precision_1: 0.5780 - val_recall_1: 0.3025 - val_f1score: 0.1348\n",
      "Epoch 131/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 0.9834 - acc: 0.5522 - auc_1: 0.7817 - precision_1: 0.5781 - recall_1: 0.3029 - f1score: 0.1491 - val_loss: 1.2117 - val_acc: 0.4636 - val_auc_1: 0.7818 - val_precision_1: 0.5782 - val_recall_1: 0.3034 - val_f1score: 0.1342\n",
      "Epoch 132/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9981 - acc: 0.5603 - auc_1: 0.7820 - precision_1: 0.5783 - recall_1: 0.3039 - f1score: 0.1490 - val_loss: 1.0902 - val_acc: 0.5190 - val_auc_1: 0.7822 - val_precision_1: 0.5785 - val_recall_1: 0.3043 - val_f1score: 0.1409\n",
      "Epoch 133/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9715 - acc: 0.5617 - auc_1: 0.7824 - precision_1: 0.5786 - recall_1: 0.3048 - f1score: 0.1506 - val_loss: 1.1332 - val_acc: 0.4636 - val_auc_1: 0.7825 - val_precision_1: 0.5788 - val_recall_1: 0.3052 - val_f1score: 0.1365\n",
      "Epoch 134/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9754 - acc: 0.5654 - auc_1: 0.7827 - precision_1: 0.5789 - recall_1: 0.3056 - f1score: 0.1505 - val_loss: 1.0694 - val_acc: 0.4869 - val_auc_1: 0.7829 - val_precision_1: 0.5791 - val_recall_1: 0.3061 - val_f1score: 0.1401\n",
      "Epoch 135/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9822 - acc: 0.5610 - auc_1: 0.7831 - precision_1: 0.5793 - recall_1: 0.3066 - f1score: 0.1507 - val_loss: 1.1601 - val_acc: 0.5131 - val_auc_1: 0.7833 - val_precision_1: 0.5794 - val_recall_1: 0.3071 - val_f1score: 0.1390\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9868 - acc: 0.5668 - auc_1: 0.7835 - precision_1: 0.5796 - recall_1: 0.3074 - f1score: 0.1497 - val_loss: 1.1157 - val_acc: 0.4636 - val_auc_1: 0.7836 - val_precision_1: 0.5797 - val_recall_1: 0.3078 - val_f1score: 0.1374\n",
      "Epoch 137/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9702 - acc: 0.5646 - auc_1: 0.7838 - precision_1: 0.5798 - recall_1: 0.3082 - f1score: 0.1508 - val_loss: 1.0937 - val_acc: 0.4956 - val_auc_1: 0.7840 - val_precision_1: 0.5799 - val_recall_1: 0.3087 - val_f1score: 0.1394\n",
      "Epoch 138/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9817 - acc: 0.5500 - auc_1: 0.7841 - precision_1: 0.5801 - recall_1: 0.3091 - f1score: 0.1495 - val_loss: 1.4304 - val_acc: 0.4286 - val_auc_1: 0.7842 - val_precision_1: 0.5800 - val_recall_1: 0.3094 - val_f1score: 0.1264\n",
      "Epoch 139/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9704 - acc: 0.5741 - auc_1: 0.7844 - precision_1: 0.5801 - recall_1: 0.3098 - f1score: 0.1511 - val_loss: 1.6115 - val_acc: 0.4052 - val_auc_1: 0.7844 - val_precision_1: 0.5801 - val_recall_1: 0.3101 - val_f1score: 0.1220\n",
      "Epoch 140/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9604 - acc: 0.5610 - auc_1: 0.7845 - precision_1: 0.5802 - recall_1: 0.3105 - f1score: 0.1512 - val_loss: 1.2453 - val_acc: 0.4927 - val_auc_1: 0.7847 - val_precision_1: 0.5803 - val_recall_1: 0.3109 - val_f1score: 0.1364\n",
      "Epoch 141/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9744 - acc: 0.5683 - auc_1: 0.7849 - precision_1: 0.5804 - recall_1: 0.3114 - f1score: 0.1513 - val_loss: 1.1484 - val_acc: 0.4840 - val_auc_1: 0.7850 - val_precision_1: 0.5805 - val_recall_1: 0.3118 - val_f1score: 0.1392\n",
      "Epoch 142/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9735 - acc: 0.5858 - auc_1: 0.7852 - precision_1: 0.5808 - recall_1: 0.3123 - f1score: 0.1509 - val_loss: 1.2047 - val_acc: 0.4752 - val_auc_1: 0.7853 - val_precision_1: 0.5809 - val_recall_1: 0.3127 - val_f1score: 0.1349\n",
      "Epoch 143/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 0.9580 - acc: 0.5749 - auc_1: 0.7855 - precision_1: 0.5811 - recall_1: 0.3131 - f1score: 0.1515 - val_loss: 1.4583 - val_acc: 0.4606 - val_auc_1: 0.7856 - val_precision_1: 0.5812 - val_recall_1: 0.3135 - val_f1score: 0.1298\n",
      "Epoch 144/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9624 - acc: 0.5793 - auc_1: 0.7858 - precision_1: 0.5815 - recall_1: 0.3140 - f1score: 0.1525 - val_loss: 1.1553 - val_acc: 0.4840 - val_auc_1: 0.7860 - val_precision_1: 0.5816 - val_recall_1: 0.3144 - val_f1score: 0.1378\n",
      "Epoch 145/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9848 - acc: 0.5559 - auc_1: 0.7861 - precision_1: 0.5817 - recall_1: 0.3148 - f1score: 0.1497 - val_loss: 1.1715 - val_acc: 0.4810 - val_auc_1: 0.7862 - val_precision_1: 0.5819 - val_recall_1: 0.3151 - val_f1score: 0.1370\n",
      "Epoch 146/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9671 - acc: 0.5522 - auc_1: 0.7864 - precision_1: 0.5820 - recall_1: 0.3155 - f1score: 0.1506 - val_loss: 1.1371 - val_acc: 0.4781 - val_auc_1: 0.7865 - val_precision_1: 0.5821 - val_recall_1: 0.3159 - val_f1score: 0.1381\n",
      "Epoch 147/200\n",
      "43/42 [==============================] - 14s 332ms/step - loss: 0.9773 - acc: 0.5595 - auc_1: 0.7867 - precision_1: 0.5822 - recall_1: 0.3163 - f1score: 0.1506 - val_loss: 1.1793 - val_acc: 0.4606 - val_auc_1: 0.7868 - val_precision_1: 0.5823 - val_recall_1: 0.3167 - val_f1score: 0.1372\n",
      "Epoch 148/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9571 - acc: 0.5836 - auc_1: 0.7870 - precision_1: 0.5825 - recall_1: 0.3171 - f1score: 0.1518 - val_loss: 1.2356 - val_acc: 0.4490 - val_auc_1: 0.7871 - val_precision_1: 0.5826 - val_recall_1: 0.3174 - val_f1score: 0.1349\n",
      "Epoch 149/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9791 - acc: 0.5654 - auc_1: 0.7873 - precision_1: 0.5827 - recall_1: 0.3178 - f1score: 0.1508 - val_loss: 1.1827 - val_acc: 0.4636 - val_auc_1: 0.7874 - val_precision_1: 0.5827 - val_recall_1: 0.3182 - val_f1score: 0.1357\n",
      "Epoch 150/200\n",
      "43/42 [==============================] - 14s 329ms/step - loss: 0.9645 - acc: 0.5698 - auc_1: 0.7875 - precision_1: 0.5828 - recall_1: 0.3185 - f1score: 0.1517 - val_loss: 1.1787 - val_acc: 0.4723 - val_auc_1: 0.7877 - val_precision_1: 0.5828 - val_recall_1: 0.3189 - val_f1score: 0.1364\n",
      "Epoch 151/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9777 - acc: 0.5537 - auc_1: 0.7878 - precision_1: 0.5829 - recall_1: 0.3193 - f1score: 0.1506 - val_loss: 1.2376 - val_acc: 0.4781 - val_auc_1: 0.7879 - val_precision_1: 0.5830 - val_recall_1: 0.3196 - val_f1score: 0.1358\n",
      "Epoch 152/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9623 - acc: 0.5778 - auc_1: 0.7881 - precision_1: 0.5832 - recall_1: 0.3200 - f1score: 0.1519 - val_loss: 1.5535 - val_acc: 0.4140 - val_auc_1: 0.7881 - val_precision_1: 0.5832 - val_recall_1: 0.3204 - val_f1score: 0.1215\n",
      "Epoch 153/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9628 - acc: 0.5836 - auc_1: 0.7882 - precision_1: 0.5833 - recall_1: 0.3208 - f1score: 0.1523 - val_loss: 1.3896 - val_acc: 0.4169 - val_auc_1: 0.7883 - val_precision_1: 0.5834 - val_recall_1: 0.3211 - val_f1score: 0.1268\n",
      "Epoch 154/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9405 - acc: 0.5822 - auc_1: 0.7885 - precision_1: 0.5835 - recall_1: 0.3215 - f1score: 0.1530 - val_loss: 1.5779 - val_acc: 0.3994 - val_auc_1: 0.7885 - val_precision_1: 0.5836 - val_recall_1: 0.3219 - val_f1score: 0.1210\n",
      "Epoch 155/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9507 - acc: 0.5720 - auc_1: 0.7886 - precision_1: 0.5837 - recall_1: 0.3223 - f1score: 0.1525 - val_loss: 1.5828 - val_acc: 0.3819 - val_auc_1: 0.7887 - val_precision_1: 0.5837 - val_recall_1: 0.3226 - val_f1score: 0.1208\n",
      "Epoch 156/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9472 - acc: 0.5720 - auc_1: 0.7888 - precision_1: 0.5838 - recall_1: 0.3230 - f1score: 0.1529 - val_loss: 1.5357 - val_acc: 0.3878 - val_auc_1: 0.7889 - val_precision_1: 0.5839 - val_recall_1: 0.3233 - val_f1score: 0.1209\n",
      "Epoch 157/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9332 - acc: 0.5917 - auc_1: 0.7890 - precision_1: 0.5840 - recall_1: 0.3237 - f1score: 0.1541 - val_loss: 1.4442 - val_acc: 0.4257 - val_auc_1: 0.7891 - val_precision_1: 0.5841 - val_recall_1: 0.3241 - val_f1score: 0.1251\n",
      "Epoch 158/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9489 - acc: 0.5771 - auc_1: 0.7892 - precision_1: 0.5841 - recall_1: 0.3245 - f1score: 0.1534 - val_loss: 1.4663 - val_acc: 0.4111 - val_auc_1: 0.7893 - val_precision_1: 0.5841 - val_recall_1: 0.3248 - val_f1score: 0.1249\n",
      "Epoch 159/200\n",
      "43/42 [==============================] - 14s 329ms/step - loss: 0.9536 - acc: 0.5646 - auc_1: 0.7894 - precision_1: 0.5842 - recall_1: 0.3252 - f1score: 0.1526 - val_loss: 1.2101 - val_acc: 0.4781 - val_auc_1: 0.7895 - val_precision_1: 0.5842 - val_recall_1: 0.3255 - val_f1score: 0.1374\n",
      "Epoch 160/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9481 - acc: 0.5851 - auc_1: 0.7897 - precision_1: 0.5844 - recall_1: 0.3260 - f1score: 0.1533 - val_loss: 1.1994 - val_acc: 0.4694 - val_auc_1: 0.7898 - val_precision_1: 0.5846 - val_recall_1: 0.3263 - val_f1score: 0.1384\n",
      "Epoch 161/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9252 - acc: 0.5800 - auc_1: 0.7900 - precision_1: 0.5847 - recall_1: 0.3268 - f1score: 0.1551 - val_loss: 1.0602 - val_acc: 0.5073 - val_auc_1: 0.7902 - val_precision_1: 0.5849 - val_recall_1: 0.3272 - val_f1score: 0.1430\n",
      "Epoch 162/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9480 - acc: 0.5917 - auc_1: 0.7903 - precision_1: 0.5851 - recall_1: 0.3276 - f1score: 0.1536 - val_loss: 1.2679 - val_acc: 0.4752 - val_auc_1: 0.7905 - val_precision_1: 0.5853 - val_recall_1: 0.3280 - val_f1score: 0.1353\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9633 - acc: 0.5625 - auc_1: 0.7906 - precision_1: 0.5854 - recall_1: 0.3284 - f1score: 0.1525 - val_loss: 1.2162 - val_acc: 0.4781 - val_auc_1: 0.7907 - val_precision_1: 0.5854 - val_recall_1: 0.3287 - val_f1score: 0.1346\n",
      "Epoch 164/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9385 - acc: 0.5822 - auc_1: 0.7909 - precision_1: 0.5856 - recall_1: 0.3291 - f1score: 0.1539 - val_loss: 1.1823 - val_acc: 0.4869 - val_auc_1: 0.7910 - val_precision_1: 0.5857 - val_recall_1: 0.3294 - val_f1score: 0.1376\n",
      "Epoch 165/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9520 - acc: 0.5800 - auc_1: 0.7912 - precision_1: 0.5858 - recall_1: 0.3297 - f1score: 0.1526 - val_loss: 1.1175 - val_acc: 0.4898 - val_auc_1: 0.7913 - val_precision_1: 0.5859 - val_recall_1: 0.3300 - val_f1score: 0.1396\n",
      "Epoch 166/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9462 - acc: 0.5698 - auc_1: 0.7914 - precision_1: 0.5861 - recall_1: 0.3304 - f1score: 0.1536 - val_loss: 1.1887 - val_acc: 0.4898 - val_auc_1: 0.7916 - val_precision_1: 0.5861 - val_recall_1: 0.3308 - val_f1score: 0.1381\n",
      "Epoch 167/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9484 - acc: 0.5807 - auc_1: 0.7917 - precision_1: 0.5863 - recall_1: 0.3312 - f1score: 0.1528 - val_loss: 1.3152 - val_acc: 0.4490 - val_auc_1: 0.7918 - val_precision_1: 0.5863 - val_recall_1: 0.3315 - val_f1score: 0.1322\n",
      "Epoch 168/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9328 - acc: 0.5866 - auc_1: 0.7919 - precision_1: 0.5865 - recall_1: 0.3318 - f1score: 0.1539 - val_loss: 1.2104 - val_acc: 0.4606 - val_auc_1: 0.7920 - val_precision_1: 0.5866 - val_recall_1: 0.3322 - val_f1score: 0.1348\n",
      "Epoch 169/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9425 - acc: 0.5931 - auc_1: 0.7922 - precision_1: 0.5868 - recall_1: 0.3326 - f1score: 0.1539 - val_loss: 1.4121 - val_acc: 0.3994 - val_auc_1: 0.7923 - val_precision_1: 0.5868 - val_recall_1: 0.3329 - val_f1score: 0.1253\n",
      "Epoch 170/200\n",
      "43/42 [==============================] - 14s 330ms/step - loss: 0.9345 - acc: 0.5829 - auc_1: 0.7924 - precision_1: 0.5869 - recall_1: 0.3332 - f1score: 0.1541 - val_loss: 1.1764 - val_acc: 0.4752 - val_auc_1: 0.7925 - val_precision_1: 0.5870 - val_recall_1: 0.3335 - val_f1score: 0.1364\n",
      "Epoch 171/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9295 - acc: 0.5793 - auc_1: 0.7927 - precision_1: 0.5871 - recall_1: 0.3339 - f1score: 0.1553 - val_loss: 1.3005 - val_acc: 0.4344 - val_auc_1: 0.7928 - val_precision_1: 0.5871 - val_recall_1: 0.3342 - val_f1score: 0.1311\n",
      "Epoch 172/200\n",
      "43/42 [==============================] - 14s 331ms/step - loss: 0.9325 - acc: 0.6004 - auc_1: 0.7929 - precision_1: 0.5873 - recall_1: 0.3346 - f1score: 0.1545 - val_loss: 1.3860 - val_acc: 0.4431 - val_auc_1: 0.7930 - val_precision_1: 0.5874 - val_recall_1: 0.3349 - val_f1score: 0.1295\n",
      "Epoch 173/200\n",
      "43/42 [==============================] - 14s 333ms/step - loss: 0.9283 - acc: 0.5902 - auc_1: 0.7931 - precision_1: 0.5875 - recall_1: 0.3353 - f1score: 0.1554 - val_loss: 1.3298 - val_acc: 0.4373 - val_auc_1: 0.7932 - val_precision_1: 0.5876 - val_recall_1: 0.3356 - val_f1score: 0.1289\n",
      "Epoch 174/200\n",
      "43/42 [==============================] - 15s 350ms/step - loss: 0.9430 - acc: 0.5785 - auc_1: 0.7933 - precision_1: 0.5877 - recall_1: 0.3359 - f1score: 0.1537 - val_loss: 1.2490 - val_acc: 0.4636 - val_auc_1: 0.7934 - val_precision_1: 0.5877 - val_recall_1: 0.3362 - val_f1score: 0.1328\n",
      "Epoch 175/200\n",
      "43/42 [==============================] - 15s 350ms/step - loss: 0.9340 - acc: 0.5909 - auc_1: 0.7936 - precision_1: 0.5879 - recall_1: 0.3366 - f1score: 0.1546 - val_loss: 1.0976 - val_acc: 0.4869 - val_auc_1: 0.7937 - val_precision_1: 0.5880 - val_recall_1: 0.3369 - val_f1score: 0.1391\n",
      "Epoch 176/200\n",
      "43/42 [==============================] - 15s 338ms/step - loss: 0.9363 - acc: 0.5800 - auc_1: 0.7938 - precision_1: 0.5881 - recall_1: 0.3372 - f1score: 0.1547 - val_loss: 1.0473 - val_acc: 0.5335 - val_auc_1: 0.7940 - val_precision_1: 0.5883 - val_recall_1: 0.3376 - val_f1score: 0.1433\n",
      "Epoch 177/200\n",
      "43/42 [==============================] - 15s 338ms/step - loss: 0.9275 - acc: 0.5785 - auc_1: 0.7942 - precision_1: 0.5885 - recall_1: 0.3380 - f1score: 0.1555 - val_loss: 1.2547 - val_acc: 0.4344 - val_auc_1: 0.7943 - val_precision_1: 0.5885 - val_recall_1: 0.3383 - val_f1score: 0.1316\n",
      "Epoch 178/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9351 - acc: 0.5931 - auc_1: 0.7944 - precision_1: 0.5886 - recall_1: 0.3386 - f1score: 0.1546 - val_loss: 1.2624 - val_acc: 0.4723 - val_auc_1: 0.7945 - val_precision_1: 0.5886 - val_recall_1: 0.3389 - val_f1score: 0.1336\n",
      "Epoch 179/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9370 - acc: 0.5946 - auc_1: 0.7946 - precision_1: 0.5888 - recall_1: 0.3393 - f1score: 0.1549 - val_loss: 1.2463 - val_acc: 0.4431 - val_auc_1: 0.7947 - val_precision_1: 0.5889 - val_recall_1: 0.3397 - val_f1score: 0.1346\n",
      "Epoch 180/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.8964 - acc: 0.6048 - auc_1: 0.7949 - precision_1: 0.5891 - recall_1: 0.3401 - f1score: 0.1573 - val_loss: 1.3288 - val_acc: 0.4461 - val_auc_1: 0.7950 - val_precision_1: 0.5892 - val_recall_1: 0.3404 - val_f1score: 0.1305\n",
      "Epoch 181/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9137 - acc: 0.5990 - auc_1: 0.7951 - precision_1: 0.5893 - recall_1: 0.3407 - f1score: 0.1557 - val_loss: 1.6359 - val_acc: 0.3965 - val_auc_1: 0.7952 - val_precision_1: 0.5894 - val_recall_1: 0.3410 - val_f1score: 0.1206\n",
      "Epoch 182/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9503 - acc: 0.5822 - auc_1: 0.7952 - precision_1: 0.5894 - recall_1: 0.3413 - f1score: 0.1539 - val_loss: 1.3441 - val_acc: 0.4257 - val_auc_1: 0.7953 - val_precision_1: 0.5895 - val_recall_1: 0.3417 - val_f1score: 0.1289\n",
      "Epoch 183/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9375 - acc: 0.5858 - auc_1: 0.7954 - precision_1: 0.5896 - recall_1: 0.3420 - f1score: 0.1545 - val_loss: 1.3594 - val_acc: 0.4286 - val_auc_1: 0.7955 - val_precision_1: 0.5897 - val_recall_1: 0.3423 - val_f1score: 0.1282\n",
      "Epoch 184/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9421 - acc: 0.5982 - auc_1: 0.7956 - precision_1: 0.5898 - recall_1: 0.3426 - f1score: 0.1545 - val_loss: 1.2236 - val_acc: 0.4665 - val_auc_1: 0.7957 - val_precision_1: 0.5900 - val_recall_1: 0.3429 - val_f1score: 0.1350\n",
      "Epoch 185/200\n",
      "43/42 [==============================] - 14s 337ms/step - loss: 0.9268 - acc: 0.5880 - auc_1: 0.7958 - precision_1: 0.5901 - recall_1: 0.3433 - f1score: 0.1557 - val_loss: 1.4112 - val_acc: 0.4111 - val_auc_1: 0.7959 - val_precision_1: 0.5901 - val_recall_1: 0.3436 - val_f1score: 0.1275\n",
      "Epoch 186/200\n",
      "43/42 [==============================] - 14s 336ms/step - loss: 0.9253 - acc: 0.5968 - auc_1: 0.7960 - precision_1: 0.5902 - recall_1: 0.3439 - f1score: 0.1554 - val_loss: 1.0939 - val_acc: 0.4869 - val_auc_1: 0.7961 - val_precision_1: 0.5903 - val_recall_1: 0.3442 - val_f1score: 0.1419\n",
      "Epoch 187/200\n",
      "43/42 [==============================] - 15s 341ms/step - loss: 0.9278 - acc: 0.6070 - auc_1: 0.7963 - precision_1: 0.5905 - recall_1: 0.3446 - f1score: 0.1558 - val_loss: 1.2969 - val_acc: 0.4315 - val_auc_1: 0.7964 - val_precision_1: 0.5906 - val_recall_1: 0.3449 - val_f1score: 0.1290\n",
      "Epoch 188/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.9200 - acc: 0.6041 - auc_1: 0.7965 - precision_1: 0.5907 - recall_1: 0.3453 - f1score: 0.1562 - val_loss: 1.0825 - val_acc: 0.5160 - val_auc_1: 0.7966 - val_precision_1: 0.5909 - val_recall_1: 0.3456 - val_f1score: 0.1434\n",
      "Epoch 189/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.8922 - acc: 0.6150 - auc_1: 0.7968 - precision_1: 0.5911 - recall_1: 0.3460 - f1score: 0.1587 - val_loss: 1.0564 - val_acc: 0.5015 - val_auc_1: 0.7970 - val_precision_1: 0.5913 - val_recall_1: 0.3464 - val_f1score: 0.1444\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 14s 334ms/step - loss: 0.9041 - acc: 0.6114 - auc_1: 0.7971 - precision_1: 0.5915 - recall_1: 0.3468 - f1score: 0.1573 - val_loss: 1.3208 - val_acc: 0.4694 - val_auc_1: 0.7972 - val_precision_1: 0.5916 - val_recall_1: 0.3471 - val_f1score: 0.1325\n",
      "Epoch 191/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.9080 - acc: 0.6034 - auc_1: 0.7974 - precision_1: 0.5918 - recall_1: 0.3475 - f1score: 0.1570 - val_loss: 1.2347 - val_acc: 0.4548 - val_auc_1: 0.7975 - val_precision_1: 0.5918 - val_recall_1: 0.3478 - val_f1score: 0.1347\n",
      "Epoch 192/200\n",
      "43/42 [==============================] - 14s 333ms/step - loss: 0.9296 - acc: 0.5807 - auc_1: 0.7976 - precision_1: 0.5919 - recall_1: 0.3481 - f1score: 0.1555 - val_loss: 1.1424 - val_acc: 0.4781 - val_auc_1: 0.7977 - val_precision_1: 0.5919 - val_recall_1: 0.3484 - val_f1score: 0.1386\n",
      "Epoch 193/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.8909 - acc: 0.5975 - auc_1: 0.7978 - precision_1: 0.5921 - recall_1: 0.3488 - f1score: 0.1581 - val_loss: 1.1307 - val_acc: 0.5452 - val_auc_1: 0.7980 - val_precision_1: 0.5922 - val_recall_1: 0.3491 - val_f1score: 0.1431\n",
      "Epoch 194/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9115 - acc: 0.6056 - auc_1: 0.7981 - precision_1: 0.5924 - recall_1: 0.3495 - f1score: 0.1573 - val_loss: 1.1542 - val_acc: 0.4898 - val_auc_1: 0.7983 - val_precision_1: 0.5926 - val_recall_1: 0.3498 - val_f1score: 0.1412\n",
      "Epoch 195/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.8965 - acc: 0.6194 - auc_1: 0.7984 - precision_1: 0.5928 - recall_1: 0.3502 - f1score: 0.1590 - val_loss: 1.1176 - val_acc: 0.5306 - val_auc_1: 0.7986 - val_precision_1: 0.5929 - val_recall_1: 0.3506 - val_f1score: 0.1427\n",
      "Epoch 196/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.9008 - acc: 0.6056 - auc_1: 0.7987 - precision_1: 0.5931 - recall_1: 0.3510 - f1score: 0.1579 - val_loss: 1.2300 - val_acc: 0.4898 - val_auc_1: 0.7988 - val_precision_1: 0.5933 - val_recall_1: 0.3513 - val_f1score: 0.1378\n",
      "Epoch 197/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9021 - acc: 0.6019 - auc_1: 0.7990 - precision_1: 0.5935 - recall_1: 0.3517 - f1score: 0.1582 - val_loss: 1.0182 - val_acc: 0.5190 - val_auc_1: 0.7991 - val_precision_1: 0.5937 - val_recall_1: 0.3520 - val_f1score: 0.1461\n",
      "Epoch 198/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.9080 - acc: 0.6099 - auc_1: 0.7993 - precision_1: 0.5939 - recall_1: 0.3524 - f1score: 0.1573 - val_loss: 1.1803 - val_acc: 0.4927 - val_auc_1: 0.7994 - val_precision_1: 0.5940 - val_recall_1: 0.3527 - val_f1score: 0.1370\n",
      "Epoch 199/200\n",
      "43/42 [==============================] - 14s 335ms/step - loss: 0.8993 - acc: 0.6180 - auc_1: 0.7995 - precision_1: 0.5942 - recall_1: 0.3530 - f1score: 0.1588 - val_loss: 1.0227 - val_acc: 0.5481 - val_auc_1: 0.7997 - val_precision_1: 0.5944 - val_recall_1: 0.3534 - val_f1score: 0.1464\n",
      "Epoch 200/200\n",
      "43/42 [==============================] - 14s 334ms/step - loss: 0.9122 - acc: 0.6187 - auc_1: 0.7998 - precision_1: 0.5946 - recall_1: 0.3537 - f1score: 0.1571 - val_loss: 1.1357 - val_acc: 0.5277 - val_auc_1: 0.7999 - val_precision_1: 0.5948 - val_recall_1: 0.3541 - val_f1score: 0.1449\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=len(X_train)/32, \n",
    "            epochs=200, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=len(X_val)/32, \n",
    "            callbacks=[checkpoint],\n",
    "            class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 3ms/step\n",
      "loss: 1.136, accuracy: 0.528, auc: 0.800, precision: 0.595, recall: 0.354, f1score: 0.145\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "new_model = models.load_model('ResNet_average_pooling_2.hdf5',compile=False)\n",
    "\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 3s 8ms/step\n",
      "loss: 1.018, accuracy: 0.519, auc: 0.795, precision: 0.552, recall: 0.418, f1score: 0.146\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = new_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
