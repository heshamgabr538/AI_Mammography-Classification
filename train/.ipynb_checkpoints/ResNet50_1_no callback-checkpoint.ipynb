{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 56, 56, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 56, 56, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 56, 56, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 126,876,036\n",
      "Trainable params: 126,822,916\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(512, activation='relu'))\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='ResNet_1_no callback.hdf5', \n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.8,\n",
    "                1: 1,\n",
    "                2: 1,\n",
    "                3: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/42 [==============================] - 28s 658ms/step - loss: 1.8233 - acc: 0.2820 - auc_2: 0.5278 - precision_2: 0.2845 - recall_2: 0.1925 - f1score: 0.0951 - val_loss: 23.0210 - val_acc: 0.2362 - val_auc_2: 0.5247 - val_precision_2: 0.2910 - val_recall_2: 0.1592 - val_f1score: nan\n",
      "Epoch 2/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.4192 - acc: 0.3075 - auc_2: 0.5351 - precision_2: 0.3017 - recall_2: 0.1548 - f1score: 0.1040 - val_loss: 2.2613 - val_acc: 0.2653 - val_auc_2: 0.5380 - val_precision_2: 0.2986 - val_recall_2: 0.1415 - val_f1score: 0.0867\n",
      "Epoch 3/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.4131 - acc: 0.3046 - auc_2: 0.5420 - precision_2: 0.3018 - recall_2: 0.1340 - f1score: 0.1039 - val_loss: 1.4567 - val_acc: 0.2449 - val_auc_2: 0.5457 - val_precision_2: 0.3063 - val_recall_2: 0.1250 - val_f1score: 0.0983\n",
      "Epoch 4/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.3494 - acc: 0.3112 - auc_2: 0.5496 - precision_2: 0.3091 - recall_2: 0.1167 - f1score: 0.1063 - val_loss: 1.4149 - val_acc: 0.2566 - val_auc_2: 0.5545 - val_precision_2: 0.3146 - val_recall_2: 0.1114 - val_f1score: 0.1002\n",
      "Epoch 5/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.3282 - acc: 0.3338 - auc_2: 0.5599 - precision_2: 0.3228 - recall_2: 0.1093 - f1score: 0.1082 - val_loss: 1.4657 - val_acc: 0.2391 - val_auc_2: 0.5630 - val_precision_2: 0.3267 - val_recall_2: 0.1064 - val_f1score: 0.1002\n",
      "Epoch 6/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2805 - acc: 0.3528 - auc_2: 0.5680 - precision_2: 0.3345 - recall_2: 0.1062 - f1score: 0.1113 - val_loss: 1.4327 - val_acc: 0.2799 - val_auc_2: 0.5717 - val_precision_2: 0.3405 - val_recall_2: 0.1034 - val_f1score: 0.1007\n",
      "Epoch 7/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2850 - acc: 0.3397 - auc_2: 0.5744 - precision_2: 0.3432 - recall_2: 0.1006 - f1score: 0.1101 - val_loss: 1.5460 - val_acc: 0.2857 - val_auc_2: 0.5768 - val_precision_2: 0.3465 - val_recall_2: 0.1004 - val_f1score: 0.0991\n",
      "Epoch 8/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.2535 - acc: 0.3689 - auc_2: 0.5799 - precision_2: 0.3509 - recall_2: 0.1002 - f1score: 0.1129 - val_loss: 1.4850 - val_acc: 0.2799 - val_auc_2: 0.5830 - val_precision_2: 0.3536 - val_recall_2: 0.0995 - val_f1score: 0.1006\n",
      "Epoch 9/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2806 - acc: 0.3411 - auc_2: 0.5848 - precision_2: 0.3533 - recall_2: 0.0980 - f1score: 0.1109 - val_loss: 1.4825 - val_acc: 0.3120 - val_auc_2: 0.5871 - val_precision_2: 0.3556 - val_recall_2: 0.0976 - val_f1score: 0.1021\n",
      "Epoch 10/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2653 - acc: 0.3740 - auc_2: 0.5892 - precision_2: 0.3587 - recall_2: 0.0977 - f1score: 0.1127 - val_loss: 1.4644 - val_acc: 0.2945 - val_auc_2: 0.5913 - val_precision_2: 0.3629 - val_recall_2: 0.0973 - val_f1score: 0.1031\n",
      "Epoch 11/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2488 - acc: 0.3689 - auc_2: 0.5935 - precision_2: 0.3652 - recall_2: 0.0963 - f1score: 0.1136 - val_loss: 1.5190 - val_acc: 0.2770 - val_auc_2: 0.5955 - val_precision_2: 0.3689 - val_recall_2: 0.0978 - val_f1score: 0.1020\n",
      "Epoch 12/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2715 - acc: 0.3462 - auc_2: 0.5972 - precision_2: 0.3717 - recall_2: 0.0991 - f1score: 0.1123 - val_loss: 1.3006 - val_acc: 0.3557 - val_auc_2: 0.5991 - val_precision_2: 0.3731 - val_recall_2: 0.0986 - val_f1score: 0.1110\n",
      "Epoch 13/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.2350 - acc: 0.3492 - auc_2: 0.6012 - precision_2: 0.3749 - recall_2: 0.0979 - f1score: 0.1138 - val_loss: 1.3598 - val_acc: 0.3819 - val_auc_2: 0.6033 - val_precision_2: 0.3779 - val_recall_2: 0.0979 - val_f1score: 0.1123\n",
      "Epoch 14/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2207 - acc: 0.3784 - auc_2: 0.6058 - precision_2: 0.3807 - recall_2: 0.0984 - f1score: 0.1157 - val_loss: 1.4114 - val_acc: 0.3090 - val_auc_2: 0.6078 - val_precision_2: 0.3826 - val_recall_2: 0.0992 - val_f1score: 0.1079\n",
      "Epoch 15/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1987 - acc: 0.3901 - auc_2: 0.6100 - precision_2: 0.3855 - recall_2: 0.0998 - f1score: 0.1174 - val_loss: 1.3812 - val_acc: 0.3294 - val_auc_2: 0.6122 - val_precision_2: 0.3884 - val_recall_2: 0.1011 - val_f1score: 0.1124\n",
      "Epoch 16/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.2092 - acc: 0.4025 - auc_2: 0.6146 - precision_2: 0.3920 - recall_2: 0.1021 - f1score: 0.1175 - val_loss: 1.4203 - val_acc: 0.3528 - val_auc_2: 0.6164 - val_precision_2: 0.3953 - val_recall_2: 0.1042 - val_f1score: 0.1118\n",
      "Epoch 17/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1861 - acc: 0.3996 - auc_2: 0.6185 - precision_2: 0.3981 - recall_2: 0.1057 - f1score: 0.1191 - val_loss: 1.3394 - val_acc: 0.3790 - val_auc_2: 0.6206 - val_precision_2: 0.4019 - val_recall_2: 0.1069 - val_f1score: 0.1137\n",
      "Epoch 18/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1852 - acc: 0.3791 - auc_2: 0.6225 - precision_2: 0.4033 - recall_2: 0.1069 - f1score: 0.1190 - val_loss: 1.2960 - val_acc: 0.3994 - val_auc_2: 0.6246 - val_precision_2: 0.4059 - val_recall_2: 0.1076 - val_f1score: 0.1171\n",
      "Epoch 19/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1529 - acc: 0.4127 - auc_2: 0.6270 - precision_2: 0.4103 - recall_2: 0.1090 - f1score: 0.1219 - val_loss: 1.3084 - val_acc: 0.4140 - val_auc_2: 0.6292 - val_precision_2: 0.4133 - val_recall_2: 0.1105 - val_f1score: 0.1179\n",
      "Epoch 20/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.2071 - acc: 0.3930 - auc_2: 0.6310 - precision_2: 0.4148 - recall_2: 0.1115 - f1score: 0.1192 - val_loss: 1.3352 - val_acc: 0.3615 - val_auc_2: 0.6323 - val_precision_2: 0.4163 - val_recall_2: 0.1132 - val_f1score: 0.1168\n",
      "Epoch 21/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1528 - acc: 0.4076 - auc_2: 0.6342 - precision_2: 0.4181 - recall_2: 0.1144 - f1score: 0.1221 - val_loss: 1.2691 - val_acc: 0.4286 - val_auc_2: 0.6361 - val_precision_2: 0.4215 - val_recall_2: 0.1157 - val_f1score: 0.1202\n",
      "Epoch 22/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1500 - acc: 0.4186 - auc_2: 0.6383 - precision_2: 0.4245 - recall_2: 0.1170 - f1score: 0.1232 - val_loss: 1.3608 - val_acc: 0.3819 - val_auc_2: 0.6397 - val_precision_2: 0.4259 - val_recall_2: 0.1178 - val_f1score: 0.1129\n",
      "Epoch 23/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1584 - acc: 0.4237 - auc_2: 0.6413 - precision_2: 0.4285 - recall_2: 0.1187 - f1score: 0.1226 - val_loss: 1.3325 - val_acc: 0.3965 - val_auc_2: 0.6427 - val_precision_2: 0.4313 - val_recall_2: 0.1202 - val_f1score: 0.1162\n",
      "Epoch 24/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1469 - acc: 0.4127 - auc_2: 0.6442 - precision_2: 0.4330 - recall_2: 0.1213 - f1score: 0.1233 - val_loss: 1.3303 - val_acc: 0.3819 - val_auc_2: 0.6457 - val_precision_2: 0.4347 - val_recall_2: 0.1225 - val_f1score: 0.1171\n",
      "Epoch 25/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1278 - acc: 0.4200 - auc_2: 0.6474 - precision_2: 0.4364 - recall_2: 0.1238 - f1score: 0.1246 - val_loss: 1.2907 - val_acc: 0.3644 - val_auc_2: 0.6489 - val_precision_2: 0.4376 - val_recall_2: 0.1244 - val_f1score: 0.1182\n",
      "Epoch 26/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1340 - acc: 0.4083 - auc_2: 0.6503 - precision_2: 0.4393 - recall_2: 0.1251 - f1score: 0.1251 - val_loss: 1.2507 - val_acc: 0.4461 - val_auc_2: 0.6519 - val_precision_2: 0.4411 - val_recall_2: 0.1268 - val_f1score: 0.1234\n",
      "Epoch 27/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1312 - acc: 0.4346 - auc_2: 0.6532 - precision_2: 0.4423 - recall_2: 0.1279 - f1score: 0.1250 - val_loss: 1.3662 - val_acc: 0.3936 - val_auc_2: 0.6546 - val_precision_2: 0.4441 - val_recall_2: 0.1291 - val_f1score: 0.1175\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1504 - acc: 0.4120 - auc_2: 0.6558 - precision_2: 0.4456 - recall_2: 0.1301 - f1score: 0.1244 - val_loss: 1.2753 - val_acc: 0.3936 - val_auc_2: 0.6569 - val_precision_2: 0.4473 - val_recall_2: 0.1312 - val_f1score: 0.1211\n",
      "Epoch 29/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1247 - acc: 0.4427 - auc_2: 0.6582 - precision_2: 0.4497 - recall_2: 0.1325 - f1score: 0.1265 - val_loss: 1.2148 - val_acc: 0.4286 - val_auc_2: 0.6596 - val_precision_2: 0.4518 - val_recall_2: 0.1337 - val_f1score: 0.1242\n",
      "Epoch 30/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1224 - acc: 0.4412 - auc_2: 0.6610 - precision_2: 0.4532 - recall_2: 0.1346 - f1score: 0.1267 - val_loss: 1.2700 - val_acc: 0.4052 - val_auc_2: 0.6622 - val_precision_2: 0.4546 - val_recall_2: 0.1357 - val_f1score: 0.1216\n",
      "Epoch 31/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1104 - acc: 0.4127 - auc_2: 0.6633 - precision_2: 0.4561 - recall_2: 0.1366 - f1score: 0.1266 - val_loss: 1.2125 - val_acc: 0.4023 - val_auc_2: 0.6646 - val_precision_2: 0.4586 - val_recall_2: 0.1381 - val_f1score: 0.1232\n",
      "Epoch 32/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1173 - acc: 0.4339 - auc_2: 0.6658 - precision_2: 0.4604 - recall_2: 0.1392 - f1score: 0.1268 - val_loss: 1.2650 - val_acc: 0.3848 - val_auc_2: 0.6668 - val_precision_2: 0.4613 - val_recall_2: 0.1401 - val_f1score: 0.1195\n",
      "Epoch 33/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.1029 - acc: 0.4434 - auc_2: 0.6680 - precision_2: 0.4624 - recall_2: 0.1408 - f1score: 0.1278 - val_loss: 1.2084 - val_acc: 0.3994 - val_auc_2: 0.6692 - val_precision_2: 0.4637 - val_recall_2: 0.1415 - val_f1score: 0.1242\n",
      "Epoch 34/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0846 - acc: 0.4543 - auc_2: 0.6703 - precision_2: 0.4651 - recall_2: 0.1424 - f1score: 0.1295 - val_loss: 1.2286 - val_acc: 0.4111 - val_auc_2: 0.6717 - val_precision_2: 0.4675 - val_recall_2: 0.1438 - val_f1score: 0.1245\n",
      "Epoch 35/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0993 - acc: 0.4237 - auc_2: 0.6728 - precision_2: 0.4688 - recall_2: 0.1452 - f1score: 0.1284 - val_loss: 1.1960 - val_acc: 0.4198 - val_auc_2: 0.6738 - val_precision_2: 0.4697 - val_recall_2: 0.1462 - val_f1score: 0.1270\n",
      "Epoch 36/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1000 - acc: 0.4390 - auc_2: 0.6749 - precision_2: 0.4703 - recall_2: 0.1472 - f1score: 0.1290 - val_loss: 1.2251 - val_acc: 0.4315 - val_auc_2: 0.6760 - val_precision_2: 0.4711 - val_recall_2: 0.1484 - val_f1score: 0.1262\n",
      "Epoch 37/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0881 - acc: 0.4500 - auc_2: 0.6771 - precision_2: 0.4725 - recall_2: 0.1497 - f1score: 0.1304 - val_loss: 1.1764 - val_acc: 0.4694 - val_auc_2: 0.6782 - val_precision_2: 0.4737 - val_recall_2: 0.1508 - val_f1score: 0.1288\n",
      "Epoch 38/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.1081 - acc: 0.4324 - auc_2: 0.6793 - precision_2: 0.4747 - recall_2: 0.1522 - f1score: 0.1289 - val_loss: 1.2930 - val_acc: 0.3703 - val_auc_2: 0.6800 - val_precision_2: 0.4744 - val_recall_2: 0.1533 - val_f1score: 0.1197\n",
      "Epoch 39/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0817 - acc: 0.4514 - auc_2: 0.6808 - precision_2: 0.4750 - recall_2: 0.1541 - f1score: 0.1302 - val_loss: 1.3101 - val_acc: 0.4227 - val_auc_2: 0.6817 - val_precision_2: 0.4760 - val_recall_2: 0.1553 - val_f1score: 0.1222\n",
      "Epoch 40/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0647 - acc: 0.4617 - auc_2: 0.6826 - precision_2: 0.4772 - recall_2: 0.1564 - f1score: 0.1316 - val_loss: 1.3928 - val_acc: 0.3907 - val_auc_2: 0.6835 - val_precision_2: 0.4782 - val_recall_2: 0.1575 - val_f1score: 0.1198\n",
      "Epoch 41/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0959 - acc: 0.4390 - auc_2: 0.6842 - precision_2: 0.4790 - recall_2: 0.1584 - f1score: 0.1296 - val_loss: 1.2092 - val_acc: 0.4490 - val_auc_2: 0.6850 - val_precision_2: 0.4802 - val_recall_2: 0.1597 - val_f1score: 0.1285\n",
      "Epoch 42/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0559 - acc: 0.4682 - auc_2: 0.6861 - precision_2: 0.4813 - recall_2: 0.1607 - f1score: 0.1323 - val_loss: 1.2462 - val_acc: 0.4344 - val_auc_2: 0.6870 - val_precision_2: 0.4823 - val_recall_2: 0.1617 - val_f1score: 0.1262\n",
      "Epoch 43/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0505 - acc: 0.4514 - auc_2: 0.6879 - precision_2: 0.4833 - recall_2: 0.1626 - f1score: 0.1324 - val_loss: 1.1926 - val_acc: 0.4257 - val_auc_2: 0.6889 - val_precision_2: 0.4842 - val_recall_2: 0.1632 - val_f1score: 0.1276\n",
      "Epoch 44/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0774 - acc: 0.4507 - auc_2: 0.6898 - precision_2: 0.4852 - recall_2: 0.1639 - f1score: 0.1310 - val_loss: 1.2098 - val_acc: 0.4694 - val_auc_2: 0.6905 - val_precision_2: 0.4861 - val_recall_2: 0.1647 - val_f1score: 0.1276\n",
      "Epoch 45/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0608 - acc: 0.4631 - auc_2: 0.6915 - precision_2: 0.4871 - recall_2: 0.1655 - f1score: 0.1327 - val_loss: 1.2132 - val_acc: 0.4402 - val_auc_2: 0.6923 - val_precision_2: 0.4878 - val_recall_2: 0.1663 - val_f1score: 0.1279\n",
      "Epoch 46/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0631 - acc: 0.4558 - auc_2: 0.6931 - precision_2: 0.4886 - recall_2: 0.1670 - f1score: 0.1317 - val_loss: 1.2806 - val_acc: 0.3732 - val_auc_2: 0.6938 - val_precision_2: 0.4889 - val_recall_2: 0.1676 - val_f1score: 0.1223\n",
      "Epoch 47/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0904 - acc: 0.4500 - auc_2: 0.6944 - precision_2: 0.4894 - recall_2: 0.1683 - f1score: 0.1305 - val_loss: 1.2442 - val_acc: 0.4286 - val_auc_2: 0.6950 - val_precision_2: 0.4901 - val_recall_2: 0.1692 - val_f1score: 0.1262\n",
      "Epoch 48/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0678 - acc: 0.4397 - auc_2: 0.6956 - precision_2: 0.4906 - recall_2: 0.1698 - f1score: 0.1313 - val_loss: 1.2207 - val_acc: 0.3819 - val_auc_2: 0.6963 - val_precision_2: 0.4908 - val_recall_2: 0.1703 - val_f1score: 0.1257\n",
      "Epoch 49/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0516 - acc: 0.4624 - auc_2: 0.6971 - precision_2: 0.4916 - recall_2: 0.1712 - f1score: 0.1332 - val_loss: 1.2272 - val_acc: 0.3965 - val_auc_2: 0.6977 - val_precision_2: 0.4917 - val_recall_2: 0.1719 - val_f1score: 0.1259\n",
      "Epoch 50/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0733 - acc: 0.4295 - auc_2: 0.6983 - precision_2: 0.4918 - recall_2: 0.1725 - f1score: 0.1313 - val_loss: 1.2738 - val_acc: 0.3994 - val_auc_2: 0.6989 - val_precision_2: 0.4920 - val_recall_2: 0.1733 - val_f1score: 0.1233\n",
      "Epoch 51/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0290 - acc: 0.4770 - auc_2: 0.6997 - precision_2: 0.4926 - recall_2: 0.1744 - f1score: 0.1358 - val_loss: 1.2095 - val_acc: 0.4198 - val_auc_2: 0.7004 - val_precision_2: 0.4932 - val_recall_2: 0.1754 - val_f1score: 0.1277\n",
      "Epoch 52/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0695 - acc: 0.4492 - auc_2: 0.7010 - precision_2: 0.4936 - recall_2: 0.1762 - f1score: 0.1322 - val_loss: 1.2707 - val_acc: 0.4198 - val_auc_2: 0.7015 - val_precision_2: 0.4938 - val_recall_2: 0.1768 - val_f1score: 0.1262\n",
      "Epoch 53/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0531 - acc: 0.4617 - auc_2: 0.7021 - precision_2: 0.4945 - recall_2: 0.1776 - f1score: 0.1331 - val_loss: 1.2206 - val_acc: 0.4198 - val_auc_2: 0.7027 - val_precision_2: 0.4953 - val_recall_2: 0.1784 - val_f1score: 0.1284\n",
      "Epoch 54/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0556 - acc: 0.4726 - auc_2: 0.7035 - precision_2: 0.4961 - recall_2: 0.1793 - f1score: 0.1343 - val_loss: 1.4062 - val_acc: 0.4111 - val_auc_2: 0.7039 - val_precision_2: 0.4963 - val_recall_2: 0.1801 - val_f1score: 0.1193\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0542 - acc: 0.4872 - auc_2: 0.7045 - precision_2: 0.4973 - recall_2: 0.1810 - f1score: 0.1344 - val_loss: 1.5058 - val_acc: 0.3819 - val_auc_2: 0.7048 - val_precision_2: 0.4979 - val_recall_2: 0.1819 - val_f1score: 0.1145\n",
      "Epoch 56/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0454 - acc: 0.4682 - auc_2: 0.7053 - precision_2: 0.4982 - recall_2: 0.1825 - f1score: 0.1344 - val_loss: 1.3440 - val_acc: 0.3761 - val_auc_2: 0.7058 - val_precision_2: 0.4981 - val_recall_2: 0.1833 - val_f1score: 0.1205\n",
      "Epoch 57/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0345 - acc: 0.4726 - auc_2: 0.7063 - precision_2: 0.4986 - recall_2: 0.1841 - f1score: 0.1354 - val_loss: 1.2830 - val_acc: 0.4169 - val_auc_2: 0.7069 - val_precision_2: 0.4993 - val_recall_2: 0.1850 - val_f1score: 0.1247\n",
      "Epoch 58/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0582 - acc: 0.4719 - auc_2: 0.7074 - precision_2: 0.4996 - recall_2: 0.1855 - f1score: 0.1331 - val_loss: 1.3063 - val_acc: 0.4402 - val_auc_2: 0.7078 - val_precision_2: 0.5001 - val_recall_2: 0.1860 - val_f1score: 0.1235\n",
      "Epoch 59/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0242 - acc: 0.4806 - auc_2: 0.7084 - precision_2: 0.5009 - recall_2: 0.1866 - f1score: 0.1352 - val_loss: 1.2228 - val_acc: 0.4052 - val_auc_2: 0.7089 - val_precision_2: 0.5015 - val_recall_2: 0.1872 - val_f1score: 0.1271\n",
      "Epoch 60/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0407 - acc: 0.4726 - auc_2: 0.7094 - precision_2: 0.5020 - recall_2: 0.1879 - f1score: 0.1344 - val_loss: 1.1927 - val_acc: 0.4227 - val_auc_2: 0.7100 - val_precision_2: 0.5023 - val_recall_2: 0.1885 - val_f1score: 0.1285\n",
      "Epoch 61/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0342 - acc: 0.4675 - auc_2: 0.7106 - precision_2: 0.5029 - recall_2: 0.1892 - f1score: 0.1352 - val_loss: 1.3232 - val_acc: 0.4490 - val_auc_2: 0.7110 - val_precision_2: 0.5031 - val_recall_2: 0.1900 - val_f1score: 0.1246\n",
      "Epoch 62/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0429 - acc: 0.4631 - auc_2: 0.7114 - precision_2: 0.5034 - recall_2: 0.1906 - f1score: 0.1344 - val_loss: 1.1656 - val_acc: 0.4286 - val_auc_2: 0.7119 - val_precision_2: 0.5038 - val_recall_2: 0.1913 - val_f1score: 0.1302\n",
      "Epoch 63/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0309 - acc: 0.5011 - auc_2: 0.7125 - precision_2: 0.5045 - recall_2: 0.1921 - f1score: 0.1361 - val_loss: 1.1906 - val_acc: 0.4810 - val_auc_2: 0.7130 - val_precision_2: 0.5051 - val_recall_2: 0.1928 - val_f1score: 0.1296\n",
      "Epoch 64/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0369 - acc: 0.4806 - auc_2: 0.7136 - precision_2: 0.5056 - recall_2: 0.1936 - f1score: 0.1355 - val_loss: 1.2566 - val_acc: 0.4227 - val_auc_2: 0.7140 - val_precision_2: 0.5062 - val_recall_2: 0.1942 - val_f1score: 0.1253\n",
      "Epoch 65/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0581 - acc: 0.4653 - auc_2: 0.7144 - precision_2: 0.5067 - recall_2: 0.1946 - f1score: 0.1340 - val_loss: 1.2317 - val_acc: 0.4257 - val_auc_2: 0.7147 - val_precision_2: 0.5071 - val_recall_2: 0.1954 - val_f1score: 0.1271\n",
      "Epoch 66/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0426 - acc: 0.4741 - auc_2: 0.7152 - precision_2: 0.5075 - recall_2: 0.1959 - f1score: 0.1349 - val_loss: 1.2403 - val_acc: 0.4344 - val_auc_2: 0.7156 - val_precision_2: 0.5080 - val_recall_2: 0.1966 - val_f1score: 0.1275\n",
      "Epoch 67/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0339 - acc: 0.4770 - auc_2: 0.7161 - precision_2: 0.5087 - recall_2: 0.1974 - f1score: 0.1358 - val_loss: 1.3093 - val_acc: 0.4198 - val_auc_2: 0.7164 - val_precision_2: 0.5089 - val_recall_2: 0.1980 - val_f1score: 0.1238\n",
      "Epoch 68/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0339 - acc: 0.4799 - auc_2: 0.7169 - precision_2: 0.5091 - recall_2: 0.1986 - f1score: 0.1357 - val_loss: 1.2305 - val_acc: 0.4257 - val_auc_2: 0.7172 - val_precision_2: 0.5093 - val_recall_2: 0.1992 - val_f1score: 0.1284\n",
      "Epoch 69/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0386 - acc: 0.4682 - auc_2: 0.7176 - precision_2: 0.5095 - recall_2: 0.1998 - f1score: 0.1353 - val_loss: 1.2104 - val_acc: 0.4373 - val_auc_2: 0.7181 - val_precision_2: 0.5100 - val_recall_2: 0.2003 - val_f1score: 0.1287\n",
      "Epoch 70/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0449 - acc: 0.4690 - auc_2: 0.7185 - precision_2: 0.5103 - recall_2: 0.2008 - f1score: 0.1349 - val_loss: 1.3292 - val_acc: 0.4082 - val_auc_2: 0.7188 - val_precision_2: 0.5105 - val_recall_2: 0.2013 - val_f1score: 0.1226\n",
      "Epoch 71/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0649 - acc: 0.4668 - auc_2: 0.7190 - precision_2: 0.5108 - recall_2: 0.2018 - f1score: 0.1338 - val_loss: 1.3302 - val_acc: 0.4548 - val_auc_2: 0.7193 - val_precision_2: 0.5112 - val_recall_2: 0.2023 - val_f1score: 0.1249\n",
      "Epoch 72/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0233 - acc: 0.4799 - auc_2: 0.7196 - precision_2: 0.5118 - recall_2: 0.2029 - f1score: 0.1368 - val_loss: 1.3628 - val_acc: 0.3878 - val_auc_2: 0.7200 - val_precision_2: 0.5123 - val_recall_2: 0.2035 - val_f1score: 0.1224\n",
      "Epoch 73/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0168 - acc: 0.4894 - auc_2: 0.7204 - precision_2: 0.5126 - recall_2: 0.2041 - f1score: 0.1377 - val_loss: 1.2517 - val_acc: 0.4344 - val_auc_2: 0.7208 - val_precision_2: 0.5127 - val_recall_2: 0.2048 - val_f1score: 0.1268\n",
      "Epoch 74/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0111 - acc: 0.4982 - auc_2: 0.7212 - precision_2: 0.5130 - recall_2: 0.2053 - f1score: 0.1372 - val_loss: 1.1967 - val_acc: 0.4402 - val_auc_2: 0.7216 - val_precision_2: 0.5134 - val_recall_2: 0.2059 - val_f1score: 0.1288\n",
      "Epoch 75/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0447 - acc: 0.4617 - auc_2: 0.7219 - precision_2: 0.5136 - recall_2: 0.2064 - f1score: 0.1349 - val_loss: 1.3183 - val_acc: 0.4169 - val_auc_2: 0.7222 - val_precision_2: 0.5136 - val_recall_2: 0.2069 - val_f1score: 0.1227\n",
      "Epoch 76/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0046 - acc: 0.5033 - auc_2: 0.7226 - precision_2: 0.5140 - recall_2: 0.2073 - f1score: 0.1379 - val_loss: 1.2006 - val_acc: 0.4140 - val_auc_2: 0.7230 - val_precision_2: 0.5145 - val_recall_2: 0.2078 - val_f1score: 0.1294\n",
      "Epoch 77/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0180 - acc: 0.5033 - auc_2: 0.7234 - precision_2: 0.5149 - recall_2: 0.2083 - f1score: 0.1376 - val_loss: 1.2506 - val_acc: 0.4052 - val_auc_2: 0.7238 - val_precision_2: 0.5151 - val_recall_2: 0.2088 - val_f1score: 0.1274\n",
      "Epoch 78/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0233 - acc: 0.4660 - auc_2: 0.7242 - precision_2: 0.5155 - recall_2: 0.2095 - f1score: 0.1376 - val_loss: 1.3395 - val_acc: 0.4344 - val_auc_2: 0.7244 - val_precision_2: 0.5157 - val_recall_2: 0.2101 - val_f1score: 0.1261\n",
      "Epoch 79/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0080 - acc: 0.4887 - auc_2: 0.7249 - precision_2: 0.5163 - recall_2: 0.2108 - f1score: 0.1380 - val_loss: 1.2663 - val_acc: 0.4519 - val_auc_2: 0.7252 - val_precision_2: 0.5164 - val_recall_2: 0.2112 - val_f1score: 0.1282\n",
      "Epoch 80/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0303 - acc: 0.4631 - auc_2: 0.7255 - precision_2: 0.5165 - recall_2: 0.2116 - f1score: 0.1359 - val_loss: 1.2775 - val_acc: 0.4198 - val_auc_2: 0.7258 - val_precision_2: 0.5165 - val_recall_2: 0.2121 - val_f1score: 0.1255\n",
      "Epoch 81/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0158 - acc: 0.4974 - auc_2: 0.7261 - precision_2: 0.5167 - recall_2: 0.2125 - f1score: 0.1369 - val_loss: 1.2000 - val_acc: 0.4431 - val_auc_2: 0.7264 - val_precision_2: 0.5171 - val_recall_2: 0.2131 - val_f1score: 0.1303\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 1.0140 - acc: 0.4755 - auc_2: 0.7268 - precision_2: 0.5174 - recall_2: 0.2136 - f1score: 0.1367 - val_loss: 1.2339 - val_acc: 0.4461 - val_auc_2: 0.7271 - val_precision_2: 0.5177 - val_recall_2: 0.2140 - val_f1score: 0.1280\n",
      "Epoch 83/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0448 - acc: 0.4653 - auc_2: 0.7274 - precision_2: 0.5178 - recall_2: 0.2145 - f1score: 0.1350 - val_loss: 1.3698 - val_acc: 0.3469 - val_auc_2: 0.7275 - val_precision_2: 0.5176 - val_recall_2: 0.2147 - val_f1score: 0.1200\n",
      "Epoch 84/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9974 - acc: 0.4901 - auc_2: 0.7279 - precision_2: 0.5177 - recall_2: 0.2150 - f1score: 0.1382 - val_loss: 1.3661 - val_acc: 0.3848 - val_auc_2: 0.7281 - val_precision_2: 0.5178 - val_recall_2: 0.2154 - val_f1score: 0.1231\n",
      "Epoch 85/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9783 - acc: 0.4945 - auc_2: 0.7285 - precision_2: 0.5181 - recall_2: 0.2159 - f1score: 0.1406 - val_loss: 1.2942 - val_acc: 0.4461 - val_auc_2: 0.7288 - val_precision_2: 0.5184 - val_recall_2: 0.2165 - val_f1score: 0.1272\n",
      "Epoch 86/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9989 - acc: 0.4967 - auc_2: 0.7292 - precision_2: 0.5188 - recall_2: 0.2171 - f1score: 0.1392 - val_loss: 1.3874 - val_acc: 0.4344 - val_auc_2: 0.7294 - val_precision_2: 0.5190 - val_recall_2: 0.2178 - val_f1score: 0.1241\n",
      "Epoch 87/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9989 - acc: 0.5040 - auc_2: 0.7298 - precision_2: 0.5193 - recall_2: 0.2184 - f1score: 0.1394 - val_loss: 1.2425 - val_acc: 0.4490 - val_auc_2: 0.7301 - val_precision_2: 0.5195 - val_recall_2: 0.2190 - val_f1score: 0.1288\n",
      "Epoch 88/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9990 - acc: 0.4872 - auc_2: 0.7304 - precision_2: 0.5198 - recall_2: 0.2195 - f1score: 0.1389 - val_loss: 1.3247 - val_acc: 0.4402 - val_auc_2: 0.7307 - val_precision_2: 0.5200 - val_recall_2: 0.2202 - val_f1score: 0.1284\n",
      "Epoch 89/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 1.0120 - acc: 0.4755 - auc_2: 0.7310 - precision_2: 0.5203 - recall_2: 0.2208 - f1score: 0.1382 - val_loss: 1.3064 - val_acc: 0.4169 - val_auc_2: 0.7312 - val_precision_2: 0.5203 - val_recall_2: 0.2213 - val_f1score: 0.1265\n",
      "Epoch 90/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9876 - acc: 0.4938 - auc_2: 0.7315 - precision_2: 0.5207 - recall_2: 0.2219 - f1score: 0.1398 - val_loss: 1.3092 - val_acc: 0.4140 - val_auc_2: 0.7318 - val_precision_2: 0.5210 - val_recall_2: 0.2224 - val_f1score: 0.1265\n",
      "Epoch 91/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9759 - acc: 0.4887 - auc_2: 0.7321 - precision_2: 0.5213 - recall_2: 0.2229 - f1score: 0.1402 - val_loss: 1.2777 - val_acc: 0.4257 - val_auc_2: 0.7324 - val_precision_2: 0.5213 - val_recall_2: 0.2234 - val_f1score: 0.1276\n",
      "Epoch 92/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9900 - acc: 0.4872 - auc_2: 0.7327 - precision_2: 0.5215 - recall_2: 0.2239 - f1score: 0.1398 - val_loss: 1.1967 - val_acc: 0.4519 - val_auc_2: 0.7330 - val_precision_2: 0.5217 - val_recall_2: 0.2245 - val_f1score: 0.1318\n",
      "Epoch 93/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9767 - acc: 0.5128 - auc_2: 0.7334 - precision_2: 0.5220 - recall_2: 0.2251 - f1score: 0.1410 - val_loss: 1.1654 - val_acc: 0.4227 - val_auc_2: 0.7337 - val_precision_2: 0.5221 - val_recall_2: 0.2255 - val_f1score: 0.1322\n",
      "Epoch 94/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9560 - acc: 0.5252 - auc_2: 0.7342 - precision_2: 0.5226 - recall_2: 0.2262 - f1score: 0.1429 - val_loss: 1.1595 - val_acc: 0.4723 - val_auc_2: 0.7345 - val_precision_2: 0.5230 - val_recall_2: 0.2268 - val_f1score: 0.1340\n",
      "Epoch 95/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9778 - acc: 0.5215 - auc_2: 0.7349 - precision_2: 0.5235 - recall_2: 0.2275 - f1score: 0.1415 - val_loss: 1.1872 - val_acc: 0.4227 - val_auc_2: 0.7352 - val_precision_2: 0.5238 - val_recall_2: 0.2281 - val_f1score: 0.1304\n",
      "Epoch 96/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9769 - acc: 0.5201 - auc_2: 0.7356 - precision_2: 0.5243 - recall_2: 0.2286 - f1score: 0.1417 - val_loss: 1.2671 - val_acc: 0.3994 - val_auc_2: 0.7359 - val_precision_2: 0.5244 - val_recall_2: 0.2292 - val_f1score: 0.1266\n",
      "Epoch 97/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9839 - acc: 0.4960 - auc_2: 0.7362 - precision_2: 0.5247 - recall_2: 0.2297 - f1score: 0.1411 - val_loss: 1.2268 - val_acc: 0.4082 - val_auc_2: 0.7364 - val_precision_2: 0.5249 - val_recall_2: 0.2303 - val_f1score: 0.1288\n",
      "Epoch 98/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9734 - acc: 0.5121 - auc_2: 0.7367 - precision_2: 0.5253 - recall_2: 0.2308 - f1score: 0.1414 - val_loss: 1.3006 - val_acc: 0.4140 - val_auc_2: 0.7370 - val_precision_2: 0.5257 - val_recall_2: 0.2313 - val_f1score: 0.1274\n",
      "Epoch 99/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9572 - acc: 0.5237 - auc_2: 0.7374 - precision_2: 0.5262 - recall_2: 0.2320 - f1score: 0.1433 - val_loss: 1.1746 - val_acc: 0.4490 - val_auc_2: 0.7377 - val_precision_2: 0.5265 - val_recall_2: 0.2325 - val_f1score: 0.1314\n",
      "Epoch 100/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9622 - acc: 0.5237 - auc_2: 0.7380 - precision_2: 0.5268 - recall_2: 0.2329 - f1score: 0.1427 - val_loss: 1.2201 - val_acc: 0.4315 - val_auc_2: 0.7384 - val_precision_2: 0.5270 - val_recall_2: 0.2334 - val_f1score: 0.1299\n",
      "Epoch 101/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9739 - acc: 0.5274 - auc_2: 0.7387 - precision_2: 0.5274 - recall_2: 0.2341 - f1score: 0.1419 - val_loss: 1.2605 - val_acc: 0.4344 - val_auc_2: 0.7389 - val_precision_2: 0.5278 - val_recall_2: 0.2346 - val_f1score: 0.1289\n",
      "Epoch 102/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9680 - acc: 0.5026 - auc_2: 0.7392 - precision_2: 0.5281 - recall_2: 0.2352 - f1score: 0.1416 - val_loss: 1.3987 - val_acc: 0.3907 - val_auc_2: 0.7394 - val_precision_2: 0.5283 - val_recall_2: 0.2357 - val_f1score: 0.1245\n",
      "Epoch 103/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9910 - acc: 0.5164 - auc_2: 0.7397 - precision_2: 0.5285 - recall_2: 0.2363 - f1score: 0.1405 - val_loss: 1.3955 - val_acc: 0.4111 - val_auc_2: 0.7399 - val_precision_2: 0.5286 - val_recall_2: 0.2368 - val_f1score: 0.1244\n",
      "Epoch 104/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9698 - acc: 0.5215 - auc_2: 0.7401 - precision_2: 0.5289 - recall_2: 0.2373 - f1score: 0.1420 - val_loss: 1.3425 - val_acc: 0.4344 - val_auc_2: 0.7403 - val_precision_2: 0.5291 - val_recall_2: 0.2378 - val_f1score: 0.1265\n",
      "Epoch 105/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9643 - acc: 0.5128 - auc_2: 0.7406 - precision_2: 0.5294 - recall_2: 0.2383 - f1score: 0.1421 - val_loss: 1.2142 - val_acc: 0.4548 - val_auc_2: 0.7409 - val_precision_2: 0.5298 - val_recall_2: 0.2387 - val_f1score: 0.1313\n",
      "Epoch 106/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9700 - acc: 0.5172 - auc_2: 0.7411 - precision_2: 0.5300 - recall_2: 0.2392 - f1score: 0.1417 - val_loss: 1.1297 - val_acc: 0.4694 - val_auc_2: 0.7414 - val_precision_2: 0.5302 - val_recall_2: 0.2396 - val_f1score: 0.1354\n",
      "Epoch 107/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9662 - acc: 0.5223 - auc_2: 0.7417 - precision_2: 0.5305 - recall_2: 0.2401 - f1score: 0.1427 - val_loss: 1.1548 - val_acc: 0.4461 - val_auc_2: 0.7421 - val_precision_2: 0.5308 - val_recall_2: 0.2406 - val_f1score: 0.1344\n",
      "Epoch 108/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9315 - acc: 0.5325 - auc_2: 0.7424 - precision_2: 0.5311 - recall_2: 0.2411 - f1score: 0.1445 - val_loss: 1.1180 - val_acc: 0.4577 - val_auc_2: 0.7427 - val_precision_2: 0.5314 - val_recall_2: 0.2417 - val_f1score: 0.1382\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9579 - acc: 0.5026 - auc_2: 0.7431 - precision_2: 0.5317 - recall_2: 0.2423 - f1score: 0.1435 - val_loss: 1.1998 - val_acc: 0.4461 - val_auc_2: 0.7433 - val_precision_2: 0.5318 - val_recall_2: 0.2428 - val_f1score: 0.1320\n",
      "Epoch 110/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9420 - acc: 0.5157 - auc_2: 0.7436 - precision_2: 0.5321 - recall_2: 0.2433 - f1score: 0.1440 - val_loss: 1.2788 - val_acc: 0.4490 - val_auc_2: 0.7439 - val_precision_2: 0.5322 - val_recall_2: 0.2437 - val_f1score: 0.1294\n",
      "Epoch 111/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9608 - acc: 0.5310 - auc_2: 0.7442 - precision_2: 0.5325 - recall_2: 0.2442 - f1score: 0.1432 - val_loss: 1.2275 - val_acc: 0.4577 - val_auc_2: 0.7444 - val_precision_2: 0.5327 - val_recall_2: 0.2446 - val_f1score: 0.1313\n",
      "Epoch 112/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9502 - acc: 0.5186 - auc_2: 0.7447 - precision_2: 0.5328 - recall_2: 0.2451 - f1score: 0.1433 - val_loss: 1.3636 - val_acc: 0.4636 - val_auc_2: 0.7449 - val_precision_2: 0.5330 - val_recall_2: 0.2456 - val_f1score: 0.1270\n",
      "Epoch 113/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9452 - acc: 0.5237 - auc_2: 0.7452 - precision_2: 0.5334 - recall_2: 0.2461 - f1score: 0.1434 - val_loss: 1.1464 - val_acc: 0.4781 - val_auc_2: 0.7454 - val_precision_2: 0.5337 - val_recall_2: 0.2466 - val_f1score: 0.1364\n",
      "Epoch 114/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9661 - acc: 0.5303 - auc_2: 0.7457 - precision_2: 0.5339 - recall_2: 0.2471 - f1score: 0.1427 - val_loss: 1.0876 - val_acc: 0.5044 - val_auc_2: 0.7460 - val_precision_2: 0.5343 - val_recall_2: 0.2477 - val_f1score: 0.1382\n",
      "Epoch 115/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9354 - acc: 0.5369 - auc_2: 0.7463 - precision_2: 0.5349 - recall_2: 0.2483 - f1score: 0.1452 - val_loss: 1.1645 - val_acc: 0.4490 - val_auc_2: 0.7466 - val_precision_2: 0.5352 - val_recall_2: 0.2489 - val_f1score: 0.1332\n",
      "Epoch 116/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9444 - acc: 0.5245 - auc_2: 0.7469 - precision_2: 0.5354 - recall_2: 0.2494 - f1score: 0.1448 - val_loss: 1.1680 - val_acc: 0.4577 - val_auc_2: 0.7471 - val_precision_2: 0.5357 - val_recall_2: 0.2499 - val_f1score: 0.1339\n",
      "Epoch 117/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9509 - acc: 0.5420 - auc_2: 0.7474 - precision_2: 0.5360 - recall_2: 0.2505 - f1score: 0.1450 - val_loss: 1.1986 - val_acc: 0.4723 - val_auc_2: 0.7477 - val_precision_2: 0.5363 - val_recall_2: 0.2510 - val_f1score: 0.1339\n",
      "Epoch 118/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9257 - acc: 0.5274 - auc_2: 0.7480 - precision_2: 0.5367 - recall_2: 0.2515 - f1score: 0.1459 - val_loss: 1.2011 - val_acc: 0.4548 - val_auc_2: 0.7483 - val_precision_2: 0.5370 - val_recall_2: 0.2520 - val_f1score: 0.1334\n",
      "Epoch 119/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9526 - acc: 0.5383 - auc_2: 0.7486 - precision_2: 0.5374 - recall_2: 0.2526 - f1score: 0.1447 - val_loss: 1.3066 - val_acc: 0.4315 - val_auc_2: 0.7487 - val_precision_2: 0.5375 - val_recall_2: 0.2531 - val_f1score: 0.1295\n",
      "Epoch 120/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9335 - acc: 0.5230 - auc_2: 0.7490 - precision_2: 0.5377 - recall_2: 0.2536 - f1score: 0.1453 - val_loss: 1.2784 - val_acc: 0.4373 - val_auc_2: 0.7492 - val_precision_2: 0.5379 - val_recall_2: 0.2541 - val_f1score: 0.1301\n",
      "Epoch 121/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9216 - acc: 0.5347 - auc_2: 0.7495 - precision_2: 0.5383 - recall_2: 0.2547 - f1score: 0.1464 - val_loss: 1.2329 - val_acc: 0.4490 - val_auc_2: 0.7497 - val_precision_2: 0.5386 - val_recall_2: 0.2552 - val_f1score: 0.1329\n",
      "Epoch 122/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9216 - acc: 0.5383 - auc_2: 0.7500 - precision_2: 0.5389 - recall_2: 0.2558 - f1score: 0.1471 - val_loss: 1.3371 - val_acc: 0.4548 - val_auc_2: 0.7503 - val_precision_2: 0.5391 - val_recall_2: 0.2564 - val_f1score: 0.1296\n",
      "Epoch 123/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9326 - acc: 0.5354 - auc_2: 0.7505 - precision_2: 0.5394 - recall_2: 0.2569 - f1score: 0.1463 - val_loss: 1.2902 - val_acc: 0.4402 - val_auc_2: 0.7507 - val_precision_2: 0.5396 - val_recall_2: 0.2575 - val_f1score: 0.1305\n",
      "Epoch 124/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9577 - acc: 0.5296 - auc_2: 0.7510 - precision_2: 0.5398 - recall_2: 0.2580 - f1score: 0.1454 - val_loss: 1.1489 - val_acc: 0.4781 - val_auc_2: 0.7512 - val_precision_2: 0.5401 - val_recall_2: 0.2586 - val_f1score: 0.1374\n",
      "Epoch 125/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9281 - acc: 0.5325 - auc_2: 0.7515 - precision_2: 0.5404 - recall_2: 0.2592 - f1score: 0.1464 - val_loss: 1.2908 - val_acc: 0.4519 - val_auc_2: 0.7517 - val_precision_2: 0.5405 - val_recall_2: 0.2596 - val_f1score: 0.1291\n",
      "Epoch 126/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9285 - acc: 0.5522 - auc_2: 0.7520 - precision_2: 0.5408 - recall_2: 0.2601 - f1score: 0.1459 - val_loss: 1.1675 - val_acc: 0.4490 - val_auc_2: 0.7522 - val_precision_2: 0.5411 - val_recall_2: 0.2606 - val_f1score: 0.1354\n",
      "Epoch 127/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9450 - acc: 0.5128 - auc_2: 0.7524 - precision_2: 0.5412 - recall_2: 0.2609 - f1score: 0.1444 - val_loss: 1.0851 - val_acc: 0.4665 - val_auc_2: 0.7526 - val_precision_2: 0.5412 - val_recall_2: 0.2613 - val_f1score: 0.1394\n",
      "Epoch 128/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9053 - acc: 0.5559 - auc_2: 0.7530 - precision_2: 0.5417 - recall_2: 0.2619 - f1score: 0.1480 - val_loss: 1.1384 - val_acc: 0.4548 - val_auc_2: 0.7532 - val_precision_2: 0.5420 - val_recall_2: 0.2624 - val_f1score: 0.1366\n",
      "Epoch 129/200\n",
      "43/42 [==============================] - 16s 361ms/step - loss: 0.9489 - acc: 0.5347 - auc_2: 0.7535 - precision_2: 0.5422 - recall_2: 0.2629 - f1score: 0.1448 - val_loss: 1.1313 - val_acc: 0.4752 - val_auc_2: 0.7537 - val_precision_2: 0.5423 - val_recall_2: 0.2632 - val_f1score: 0.1367\n",
      "Epoch 130/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9468 - acc: 0.5259 - auc_2: 0.7539 - precision_2: 0.5425 - recall_2: 0.2638 - f1score: 0.1455 - val_loss: 1.1293 - val_acc: 0.4898 - val_auc_2: 0.7542 - val_precision_2: 0.5428 - val_recall_2: 0.2642 - val_f1score: 0.1374\n",
      "Epoch 131/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9291 - acc: 0.5471 - auc_2: 0.7544 - precision_2: 0.5432 - recall_2: 0.2648 - f1score: 0.1467 - val_loss: 1.2217 - val_acc: 0.4490 - val_auc_2: 0.7546 - val_precision_2: 0.5434 - val_recall_2: 0.2653 - val_f1score: 0.1340\n",
      "Epoch 132/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9237 - acc: 0.5420 - auc_2: 0.7549 - precision_2: 0.5436 - recall_2: 0.2657 - f1score: 0.1468 - val_loss: 1.2387 - val_acc: 0.4810 - val_auc_2: 0.7551 - val_precision_2: 0.5438 - val_recall_2: 0.2662 - val_f1score: 0.1353\n",
      "Epoch 133/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9365 - acc: 0.5296 - auc_2: 0.7553 - precision_2: 0.5440 - recall_2: 0.2667 - f1score: 0.1465 - val_loss: 1.1286 - val_acc: 0.4927 - val_auc_2: 0.7556 - val_precision_2: 0.5442 - val_recall_2: 0.2672 - val_f1score: 0.1392\n",
      "Epoch 134/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9274 - acc: 0.5573 - auc_2: 0.7558 - precision_2: 0.5445 - recall_2: 0.2677 - f1score: 0.1475 - val_loss: 1.1774 - val_acc: 0.4431 - val_auc_2: 0.7560 - val_precision_2: 0.5447 - val_recall_2: 0.2681 - val_f1score: 0.1342\n",
      "Epoch 135/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9229 - acc: 0.5310 - auc_2: 0.7563 - precision_2: 0.5448 - recall_2: 0.2685 - f1score: 0.1466 - val_loss: 1.1500 - val_acc: 0.4752 - val_auc_2: 0.7565 - val_precision_2: 0.5451 - val_recall_2: 0.2689 - val_f1score: 0.1355\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9164 - acc: 0.5332 - auc_2: 0.7567 - precision_2: 0.5453 - recall_2: 0.2693 - f1score: 0.1467 - val_loss: 1.0859 - val_acc: 0.4723 - val_auc_2: 0.7570 - val_precision_2: 0.5455 - val_recall_2: 0.2697 - val_f1score: 0.1397\n",
      "Epoch 137/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9302 - acc: 0.5398 - auc_2: 0.7573 - precision_2: 0.5458 - recall_2: 0.2702 - f1score: 0.1479 - val_loss: 1.2023 - val_acc: 0.4286 - val_auc_2: 0.7574 - val_precision_2: 0.5459 - val_recall_2: 0.2707 - val_f1score: 0.1335\n",
      "Epoch 138/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9128 - acc: 0.5369 - auc_2: 0.7576 - precision_2: 0.5461 - recall_2: 0.2711 - f1score: 0.1471 - val_loss: 1.2084 - val_acc: 0.4752 - val_auc_2: 0.7579 - val_precision_2: 0.5464 - val_recall_2: 0.2716 - val_f1score: 0.1350\n",
      "Epoch 139/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9292 - acc: 0.5369 - auc_2: 0.7581 - precision_2: 0.5466 - recall_2: 0.2721 - f1score: 0.1478 - val_loss: 1.2225 - val_acc: 0.4869 - val_auc_2: 0.7583 - val_precision_2: 0.5467 - val_recall_2: 0.2726 - val_f1score: 0.1351\n",
      "Epoch 140/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9234 - acc: 0.5486 - auc_2: 0.7585 - precision_2: 0.5470 - recall_2: 0.2731 - f1score: 0.1477 - val_loss: 1.1945 - val_acc: 0.4373 - val_auc_2: 0.7587 - val_precision_2: 0.5472 - val_recall_2: 0.2735 - val_f1score: 0.1353\n",
      "Epoch 141/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8999 - acc: 0.5588 - auc_2: 0.7589 - precision_2: 0.5474 - recall_2: 0.2740 - f1score: 0.1483 - val_loss: 1.2482 - val_acc: 0.4577 - val_auc_2: 0.7592 - val_precision_2: 0.5476 - val_recall_2: 0.2744 - val_f1score: 0.1320\n",
      "Epoch 142/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9213 - acc: 0.5413 - auc_2: 0.7594 - precision_2: 0.5479 - recall_2: 0.2748 - f1score: 0.1473 - val_loss: 1.3094 - val_acc: 0.4373 - val_auc_2: 0.7595 - val_precision_2: 0.5480 - val_recall_2: 0.2752 - val_f1score: 0.1296\n",
      "Epoch 143/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9332 - acc: 0.5376 - auc_2: 0.7597 - precision_2: 0.5481 - recall_2: 0.2756 - f1score: 0.1464 - val_loss: 1.2262 - val_acc: 0.4344 - val_auc_2: 0.7599 - val_precision_2: 0.5482 - val_recall_2: 0.2760 - val_f1score: 0.1326\n",
      "Epoch 144/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8901 - acc: 0.5544 - auc_2: 0.7601 - precision_2: 0.5484 - recall_2: 0.2764 - f1score: 0.1496 - val_loss: 1.2088 - val_acc: 0.4781 - val_auc_2: 0.7603 - val_precision_2: 0.5487 - val_recall_2: 0.2769 - val_f1score: 0.1356\n",
      "Epoch 145/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8794 - acc: 0.5661 - auc_2: 0.7606 - precision_2: 0.5491 - recall_2: 0.2775 - f1score: 0.1514 - val_loss: 1.1360 - val_acc: 0.4752 - val_auc_2: 0.7609 - val_precision_2: 0.5494 - val_recall_2: 0.2780 - val_f1score: 0.1388\n",
      "Epoch 146/200\n",
      "43/42 [==============================] - 16s 361ms/step - loss: 0.9003 - acc: 0.5559 - auc_2: 0.7611 - precision_2: 0.5497 - recall_2: 0.2785 - f1score: 0.1496 - val_loss: 1.0624 - val_acc: 0.4898 - val_auc_2: 0.7613 - val_precision_2: 0.5499 - val_recall_2: 0.2789 - val_f1score: 0.1425\n",
      "Epoch 147/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9255 - acc: 0.5332 - auc_2: 0.7616 - precision_2: 0.5501 - recall_2: 0.2793 - f1score: 0.1469 - val_loss: 1.0762 - val_acc: 0.4898 - val_auc_2: 0.7618 - val_precision_2: 0.5502 - val_recall_2: 0.2797 - val_f1score: 0.1408\n",
      "Epoch 148/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8978 - acc: 0.5478 - auc_2: 0.7620 - precision_2: 0.5504 - recall_2: 0.2801 - f1score: 0.1490 - val_loss: 1.1599 - val_acc: 0.4402 - val_auc_2: 0.7622 - val_precision_2: 0.5506 - val_recall_2: 0.2804 - val_f1score: 0.1369\n",
      "Epoch 149/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8910 - acc: 0.5581 - auc_2: 0.7625 - precision_2: 0.5508 - recall_2: 0.2809 - f1score: 0.1497 - val_loss: 1.1355 - val_acc: 0.4519 - val_auc_2: 0.7627 - val_precision_2: 0.5510 - val_recall_2: 0.2814 - val_f1score: 0.1384\n",
      "Epoch 150/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8911 - acc: 0.5500 - auc_2: 0.7629 - precision_2: 0.5512 - recall_2: 0.2818 - f1score: 0.1504 - val_loss: 1.2631 - val_acc: 0.4431 - val_auc_2: 0.7631 - val_precision_2: 0.5513 - val_recall_2: 0.2822 - val_f1score: 0.1318\n",
      "Epoch 151/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8896 - acc: 0.5595 - auc_2: 0.7633 - precision_2: 0.5516 - recall_2: 0.2826 - f1score: 0.1497 - val_loss: 1.2080 - val_acc: 0.4402 - val_auc_2: 0.7635 - val_precision_2: 0.5518 - val_recall_2: 0.2831 - val_f1score: 0.1352\n",
      "Epoch 152/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8870 - acc: 0.5551 - auc_2: 0.7637 - precision_2: 0.5520 - recall_2: 0.2835 - f1score: 0.1508 - val_loss: 1.3056 - val_acc: 0.4227 - val_auc_2: 0.7639 - val_precision_2: 0.5522 - val_recall_2: 0.2840 - val_f1score: 0.1301\n",
      "Epoch 153/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8813 - acc: 0.5683 - auc_2: 0.7641 - precision_2: 0.5524 - recall_2: 0.2844 - f1score: 0.1512 - val_loss: 1.1785 - val_acc: 0.4665 - val_auc_2: 0.7643 - val_precision_2: 0.5527 - val_recall_2: 0.2849 - val_f1score: 0.1367\n",
      "Epoch 154/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9070 - acc: 0.5493 - auc_2: 0.7645 - precision_2: 0.5529 - recall_2: 0.2853 - f1score: 0.1496 - val_loss: 1.1963 - val_acc: 0.4606 - val_auc_2: 0.7647 - val_precision_2: 0.5531 - val_recall_2: 0.2858 - val_f1score: 0.1355\n",
      "Epoch 155/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8925 - acc: 0.5464 - auc_2: 0.7649 - precision_2: 0.5533 - recall_2: 0.2862 - f1score: 0.1497 - val_loss: 1.2348 - val_acc: 0.4344 - val_auc_2: 0.7651 - val_precision_2: 0.5535 - val_recall_2: 0.2866 - val_f1score: 0.1336\n",
      "Epoch 156/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8949 - acc: 0.5515 - auc_2: 0.7653 - precision_2: 0.5537 - recall_2: 0.2870 - f1score: 0.1502 - val_loss: 1.1588 - val_acc: 0.4869 - val_auc_2: 0.7655 - val_precision_2: 0.5539 - val_recall_2: 0.2874 - val_f1score: 0.1390\n",
      "Epoch 157/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8782 - acc: 0.5646 - auc_2: 0.7657 - precision_2: 0.5542 - recall_2: 0.2879 - f1score: 0.1506 - val_loss: 1.1953 - val_acc: 0.4431 - val_auc_2: 0.7659 - val_precision_2: 0.5544 - val_recall_2: 0.2883 - val_f1score: 0.1363\n",
      "Epoch 158/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.9145 - acc: 0.5340 - auc_2: 0.7661 - precision_2: 0.5545 - recall_2: 0.2887 - f1score: 0.1484 - val_loss: 1.2859 - val_acc: 0.4257 - val_auc_2: 0.7662 - val_precision_2: 0.5546 - val_recall_2: 0.2891 - val_f1score: 0.1308\n",
      "Epoch 159/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8758 - acc: 0.5551 - auc_2: 0.7665 - precision_2: 0.5548 - recall_2: 0.2895 - f1score: 0.1513 - val_loss: 1.1243 - val_acc: 0.5015 - val_auc_2: 0.7666 - val_precision_2: 0.5549 - val_recall_2: 0.2899 - val_f1score: 0.1394\n",
      "Epoch 160/200\n",
      "43/42 [==============================] - 16s 361ms/step - loss: 0.8712 - acc: 0.5668 - auc_2: 0.7669 - precision_2: 0.5552 - recall_2: 0.2903 - f1score: 0.1514 - val_loss: 1.0773 - val_acc: 0.4927 - val_auc_2: 0.7671 - val_precision_2: 0.5554 - val_recall_2: 0.2907 - val_f1score: 0.1429\n",
      "Epoch 161/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8750 - acc: 0.5705 - auc_2: 0.7674 - precision_2: 0.5557 - recall_2: 0.2912 - f1score: 0.1525 - val_loss: 1.1842 - val_acc: 0.5131 - val_auc_2: 0.7675 - val_precision_2: 0.5558 - val_recall_2: 0.2917 - val_f1score: 0.1394\n",
      "Epoch 162/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8864 - acc: 0.5522 - auc_2: 0.7678 - precision_2: 0.5561 - recall_2: 0.2922 - f1score: 0.1512 - val_loss: 1.2668 - val_acc: 0.4636 - val_auc_2: 0.7679 - val_precision_2: 0.5562 - val_recall_2: 0.2926 - val_f1score: 0.1318\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8965 - acc: 0.5464 - auc_2: 0.7681 - precision_2: 0.5563 - recall_2: 0.2929 - f1score: 0.1493 - val_loss: 1.1549 - val_acc: 0.4577 - val_auc_2: 0.7683 - val_precision_2: 0.5565 - val_recall_2: 0.2933 - val_f1score: 0.1381\n",
      "Epoch 164/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8786 - acc: 0.5654 - auc_2: 0.7685 - precision_2: 0.5567 - recall_2: 0.2937 - f1score: 0.1517 - val_loss: 1.1245 - val_acc: 0.4781 - val_auc_2: 0.7687 - val_precision_2: 0.5569 - val_recall_2: 0.2942 - val_f1score: 0.1392\n",
      "Epoch 165/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8874 - acc: 0.5522 - auc_2: 0.7689 - precision_2: 0.5570 - recall_2: 0.2945 - f1score: 0.1508 - val_loss: 1.1304 - val_acc: 0.4985 - val_auc_2: 0.7691 - val_precision_2: 0.5573 - val_recall_2: 0.2949 - val_f1score: 0.1401\n",
      "Epoch 166/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8959 - acc: 0.5551 - auc_2: 0.7692 - precision_2: 0.5574 - recall_2: 0.2953 - f1score: 0.1501 - val_loss: 1.1294 - val_acc: 0.4723 - val_auc_2: 0.7694 - val_precision_2: 0.5575 - val_recall_2: 0.2956 - val_f1score: 0.1395\n",
      "Epoch 167/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8749 - acc: 0.5632 - auc_2: 0.7696 - precision_2: 0.5577 - recall_2: 0.2960 - f1score: 0.1521 - val_loss: 1.1638 - val_acc: 0.4606 - val_auc_2: 0.7698 - val_precision_2: 0.5579 - val_recall_2: 0.2964 - val_f1score: 0.1394\n",
      "Epoch 168/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8731 - acc: 0.5690 - auc_2: 0.7701 - precision_2: 0.5581 - recall_2: 0.2969 - f1score: 0.1519 - val_loss: 1.1034 - val_acc: 0.5102 - val_auc_2: 0.7702 - val_precision_2: 0.5584 - val_recall_2: 0.2973 - val_f1score: 0.1420\n",
      "Epoch 169/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8641 - acc: 0.5683 - auc_2: 0.7705 - precision_2: 0.5587 - recall_2: 0.2977 - f1score: 0.1526 - val_loss: 1.3205 - val_acc: 0.4636 - val_auc_2: 0.7706 - val_precision_2: 0.5588 - val_recall_2: 0.2981 - val_f1score: 0.1325\n",
      "Epoch 170/200\n",
      "43/42 [==============================] - 16s 361ms/step - loss: 0.8689 - acc: 0.5581 - auc_2: 0.7708 - precision_2: 0.5590 - recall_2: 0.2985 - f1score: 0.1528 - val_loss: 1.3283 - val_acc: 0.4315 - val_auc_2: 0.7710 - val_precision_2: 0.5591 - val_recall_2: 0.2989 - val_f1score: 0.1306\n",
      "Epoch 171/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8685 - acc: 0.5690 - auc_2: 0.7711 - precision_2: 0.5592 - recall_2: 0.2993 - f1score: 0.1516 - val_loss: 1.3511 - val_acc: 0.4461 - val_auc_2: 0.7713 - val_precision_2: 0.5594 - val_recall_2: 0.2997 - val_f1score: 0.1319\n",
      "Epoch 172/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8771 - acc: 0.5515 - auc_2: 0.7714 - precision_2: 0.5595 - recall_2: 0.3001 - f1score: 0.1520 - val_loss: 1.0816 - val_acc: 0.5248 - val_auc_2: 0.7716 - val_precision_2: 0.5597 - val_recall_2: 0.3005 - val_f1score: 0.1440\n",
      "Epoch 173/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8838 - acc: 0.5522 - auc_2: 0.7719 - precision_2: 0.5599 - recall_2: 0.3009 - f1score: 0.1516 - val_loss: 1.1395 - val_acc: 0.5248 - val_auc_2: 0.7720 - val_precision_2: 0.5600 - val_recall_2: 0.3013 - val_f1score: 0.1416\n",
      "Epoch 174/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8642 - acc: 0.5683 - auc_2: 0.7722 - precision_2: 0.5602 - recall_2: 0.3017 - f1score: 0.1531 - val_loss: 1.0933 - val_acc: 0.4898 - val_auc_2: 0.7724 - val_precision_2: 0.5604 - val_recall_2: 0.3021 - val_f1score: 0.1410\n",
      "Epoch 175/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8938 - acc: 0.5537 - auc_2: 0.7726 - precision_2: 0.5606 - recall_2: 0.3025 - f1score: 0.1513 - val_loss: 1.1959 - val_acc: 0.4694 - val_auc_2: 0.7727 - val_precision_2: 0.5607 - val_recall_2: 0.3029 - val_f1score: 0.1377\n",
      "Epoch 176/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8598 - acc: 0.5705 - auc_2: 0.7729 - precision_2: 0.5609 - recall_2: 0.3034 - f1score: 0.1533 - val_loss: 1.1407 - val_acc: 0.4723 - val_auc_2: 0.7731 - val_precision_2: 0.5610 - val_recall_2: 0.3037 - val_f1score: 0.1393\n",
      "Epoch 177/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.9213 - acc: 0.5544 - auc_2: 0.7733 - precision_2: 0.5611 - recall_2: 0.3041 - f1score: 0.1499 - val_loss: 1.1554 - val_acc: 0.4810 - val_auc_2: 0.7734 - val_precision_2: 0.5613 - val_recall_2: 0.3045 - val_f1score: 0.1386\n",
      "Epoch 178/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8574 - acc: 0.5771 - auc_2: 0.7736 - precision_2: 0.5615 - recall_2: 0.3049 - f1score: 0.1537 - val_loss: 1.1033 - val_acc: 0.4985 - val_auc_2: 0.7738 - val_precision_2: 0.5617 - val_recall_2: 0.3053 - val_f1score: 0.1395\n",
      "Epoch 179/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8606 - acc: 0.5814 - auc_2: 0.7740 - precision_2: 0.5619 - recall_2: 0.3057 - f1score: 0.1540 - val_loss: 1.1164 - val_acc: 0.5073 - val_auc_2: 0.7742 - val_precision_2: 0.5621 - val_recall_2: 0.3061 - val_f1score: 0.1408\n",
      "Epoch 180/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8662 - acc: 0.5573 - auc_2: 0.7744 - precision_2: 0.5623 - recall_2: 0.3065 - f1score: 0.1527 - val_loss: 1.1409 - val_acc: 0.4665 - val_auc_2: 0.7745 - val_precision_2: 0.5624 - val_recall_2: 0.3069 - val_f1score: 0.1381\n",
      "Epoch 181/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8474 - acc: 0.5734 - auc_2: 0.7747 - precision_2: 0.5626 - recall_2: 0.3073 - f1score: 0.1548 - val_loss: 1.1794 - val_acc: 0.4694 - val_auc_2: 0.7749 - val_precision_2: 0.5628 - val_recall_2: 0.3077 - val_f1score: 0.1376\n",
      "Epoch 182/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8548 - acc: 0.5793 - auc_2: 0.7751 - precision_2: 0.5631 - recall_2: 0.3081 - f1score: 0.1547 - val_loss: 1.1140 - val_acc: 0.5248 - val_auc_2: 0.7753 - val_precision_2: 0.5632 - val_recall_2: 0.3086 - val_f1score: 0.1419\n",
      "Epoch 183/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8692 - acc: 0.5705 - auc_2: 0.7755 - precision_2: 0.5634 - recall_2: 0.3089 - f1score: 0.1525 - val_loss: 1.0713 - val_acc: 0.5131 - val_auc_2: 0.7757 - val_precision_2: 0.5636 - val_recall_2: 0.3093 - val_f1score: 0.1428\n",
      "Epoch 184/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8531 - acc: 0.5895 - auc_2: 0.7758 - precision_2: 0.5639 - recall_2: 0.3097 - f1score: 0.1543 - val_loss: 1.2400 - val_acc: 0.4344 - val_auc_2: 0.7760 - val_precision_2: 0.5640 - val_recall_2: 0.3101 - val_f1score: 0.1349\n",
      "Epoch 185/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8341 - acc: 0.5880 - auc_2: 0.7762 - precision_2: 0.5642 - recall_2: 0.3105 - f1score: 0.1557 - val_loss: 1.2251 - val_acc: 0.4869 - val_auc_2: 0.7764 - val_precision_2: 0.5644 - val_recall_2: 0.3109 - val_f1score: 0.1380\n",
      "Epoch 186/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8634 - acc: 0.5807 - auc_2: 0.7765 - precision_2: 0.5645 - recall_2: 0.3113 - f1score: 0.1532 - val_loss: 1.0844 - val_acc: 0.5073 - val_auc_2: 0.7767 - val_precision_2: 0.5647 - val_recall_2: 0.3117 - val_f1score: 0.1432\n",
      "Epoch 187/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8338 - acc: 0.5734 - auc_2: 0.7769 - precision_2: 0.5649 - recall_2: 0.3121 - f1score: 0.1561 - val_loss: 1.4912 - val_acc: 0.4898 - val_auc_2: 0.7771 - val_precision_2: 0.5651 - val_recall_2: 0.3125 - val_f1score: 0.1298\n",
      "Epoch 188/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8683 - acc: 0.5814 - auc_2: 0.7772 - precision_2: 0.5653 - recall_2: 0.3129 - f1score: 0.1538 - val_loss: 1.2352 - val_acc: 0.5073 - val_auc_2: 0.7774 - val_precision_2: 0.5655 - val_recall_2: 0.3133 - val_f1score: 0.1392\n",
      "Epoch 189/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8636 - acc: 0.5741 - auc_2: 0.7775 - precision_2: 0.5657 - recall_2: 0.3137 - f1score: 0.1538 - val_loss: 1.2624 - val_acc: 0.4781 - val_auc_2: 0.7777 - val_precision_2: 0.5658 - val_recall_2: 0.3141 - val_f1score: 0.1359\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8443 - acc: 0.5814 - auc_2: 0.7778 - precision_2: 0.5660 - recall_2: 0.3145 - f1score: 0.1554 - val_loss: 1.2458 - val_acc: 0.4869 - val_auc_2: 0.7780 - val_precision_2: 0.5662 - val_recall_2: 0.3149 - val_f1score: 0.1385\n",
      "Epoch 191/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8347 - acc: 0.5836 - auc_2: 0.7782 - precision_2: 0.5663 - recall_2: 0.3153 - f1score: 0.1560 - val_loss: 1.2411 - val_acc: 0.4606 - val_auc_2: 0.7784 - val_precision_2: 0.5665 - val_recall_2: 0.3157 - val_f1score: 0.1360\n",
      "Epoch 192/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8351 - acc: 0.5924 - auc_2: 0.7785 - precision_2: 0.5667 - recall_2: 0.3161 - f1score: 0.1567 - val_loss: 1.1664 - val_acc: 0.5131 - val_auc_2: 0.7787 - val_precision_2: 0.5669 - val_recall_2: 0.3165 - val_f1score: 0.1418\n",
      "Epoch 193/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8341 - acc: 0.5924 - auc_2: 0.7789 - precision_2: 0.5672 - recall_2: 0.3169 - f1score: 0.1560 - val_loss: 1.3701 - val_acc: 0.4461 - val_auc_2: 0.7790 - val_precision_2: 0.5673 - val_recall_2: 0.3173 - val_f1score: 0.1306\n",
      "Epoch 194/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8197 - acc: 0.5917 - auc_2: 0.7792 - precision_2: 0.5675 - recall_2: 0.3177 - f1score: 0.1575 - val_loss: 1.2188 - val_acc: 0.4810 - val_auc_2: 0.7794 - val_precision_2: 0.5676 - val_recall_2: 0.3181 - val_f1score: 0.1385\n",
      "Epoch 195/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8378 - acc: 0.5829 - auc_2: 0.7796 - precision_2: 0.5678 - recall_2: 0.3185 - f1score: 0.1563 - val_loss: 1.5810 - val_acc: 0.4198 - val_auc_2: 0.7797 - val_precision_2: 0.5679 - val_recall_2: 0.3188 - val_f1score: 0.1245\n",
      "Epoch 196/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8384 - acc: 0.5844 - auc_2: 0.7798 - precision_2: 0.5680 - recall_2: 0.3192 - f1score: 0.1566 - val_loss: 1.5095 - val_acc: 0.4606 - val_auc_2: 0.7799 - val_precision_2: 0.5681 - val_recall_2: 0.3195 - val_f1score: 0.1296\n",
      "Epoch 197/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8439 - acc: 0.5836 - auc_2: 0.7801 - precision_2: 0.5683 - recall_2: 0.3199 - f1score: 0.1556 - val_loss: 1.2758 - val_acc: 0.4723 - val_auc_2: 0.7802 - val_precision_2: 0.5684 - val_recall_2: 0.3203 - val_f1score: 0.1366\n",
      "Epoch 198/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8188 - acc: 0.6004 - auc_2: 0.7804 - precision_2: 0.5687 - recall_2: 0.3207 - f1score: 0.1580 - val_loss: 1.1330 - val_acc: 0.5160 - val_auc_2: 0.7806 - val_precision_2: 0.5689 - val_recall_2: 0.3211 - val_f1score: 0.1421\n",
      "Epoch 199/200\n",
      "43/42 [==============================] - 15s 360ms/step - loss: 0.8001 - acc: 0.5880 - auc_2: 0.7808 - precision_2: 0.5691 - recall_2: 0.3215 - f1score: 0.1588 - val_loss: 1.2584 - val_acc: 0.4781 - val_auc_2: 0.7810 - val_precision_2: 0.5693 - val_recall_2: 0.3219 - val_f1score: 0.1375\n",
      "Epoch 200/200\n",
      "43/42 [==============================] - 15s 359ms/step - loss: 0.8387 - acc: 0.5829 - auc_2: 0.7812 - precision_2: 0.5695 - recall_2: 0.3222 - f1score: 0.1563 - val_loss: 1.2136 - val_acc: 0.4898 - val_auc_2: 0.7813 - val_precision_2: 0.5696 - val_recall_2: 0.3226 - val_f1score: 0.1399\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=len(X_train)/32, \n",
    "            epochs=200, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=len(X_val)/32, \n",
    "            callbacks=[checkpoint],\n",
    "            class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 3ms/step\n",
      "loss: 1.214, accuracy: 0.490, auc: 0.781, precision: 0.570, recall: 0.323, f1score: 0.140\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "\n",
    "new_model = models.load_model('ResNet_1_no callback.hdf5',compile=False)\n",
    "\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 2s 7ms/step\n",
      "loss: 1.062, accuracy: 0.490, auc: 0.792, precision: 0.523, recall: 0.359, f1score: 0.142\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = new_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
