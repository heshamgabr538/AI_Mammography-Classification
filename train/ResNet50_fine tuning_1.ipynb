{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 401412    \n",
      "=================================================================\n",
      "Total params: 23,989,124\n",
      "Trainable params: 401,412\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='ResNet_fine tuning_1.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 45s 300ms/step - loss: 1.3979 - acc: 0.4762 - auc: 0.6938 - precision: 0.4273 - recall: 0.3651 - f1score: 0.1355 - val_loss: 1.5081 - val_acc: 0.2268 - val_auc: 0.7560 - val_precision: 0.4942 - val_recall: 0.4174 - val_f1score: 0.0955\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 39s 262ms/step - loss: 1.0073 - acc: 0.5787 - auc: 0.7805 - precision: 0.5232 - recall: 0.4464 - f1score: 0.1596 - val_loss: 1.5117 - val_acc: 0.2268 - val_auc: 0.7990 - val_precision: 0.5441 - val_recall: 0.4671 - val_f1score: 0.0948\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.8813 - acc: 0.6273 - auc: 0.8118 - precision: 0.5605 - recall: 0.4845 - f1score: 0.1689 - val_loss: 1.5273 - val_acc: 0.2268 - val_auc: 0.8222 - val_precision: 0.5752 - val_recall: 0.5002 - val_f1score: 0.0946\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.7590 - acc: 0.6719 - auc: 0.8318 - precision: 0.5883 - recall: 0.5155 - f1score: 0.1782 - val_loss: 1.6605 - val_acc: 0.2268 - val_auc: 0.8400 - val_precision: 0.5971 - val_recall: 0.5303 - val_f1score: 0.0892\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.6992 - acc: 0.6968 - auc: 0.8468 - precision: 0.6048 - recall: 0.5424 - f1score: 0.1827 - val_loss: 1.6511 - val_acc: 0.2268 - val_auc: 0.8529 - val_precision: 0.6124 - val_recall: 0.5536 - val_f1score: 0.0894\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.6386 - acc: 0.7176 - auc: 0.8586 - precision: 0.6199 - recall: 0.5639 - f1score: 0.1874 - val_loss: 1.6564 - val_acc: 0.2268 - val_auc: 0.8636 - val_precision: 0.6265 - val_recall: 0.5732 - val_f1score: 0.0890\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.6213 - acc: 0.7345 - auc: 0.8677 - precision: 0.6326 - recall: 0.5815 - f1score: 0.1898 - val_loss: 1.7852 - val_acc: 0.2268 - val_auc: 0.8716 - val_precision: 0.6383 - val_recall: 0.5895 - val_f1score: 0.0851\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.5632 - acc: 0.7580 - auc: 0.8755 - precision: 0.6443 - recall: 0.5973 - f1score: 0.1941 - val_loss: 1.8583 - val_acc: 0.2268 - val_auc: 0.8789 - val_precision: 0.6494 - val_recall: 0.6042 - val_f1score: 0.0832\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.5172 - acc: 0.7773 - auc: 0.8825 - precision: 0.6549 - recall: 0.6112 - f1score: 0.1983 - val_loss: 1.9464 - val_acc: 0.2268 - val_auc: 0.8857 - val_precision: 0.6601 - val_recall: 0.6178 - val_f1score: 0.0807\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.4714 - acc: 0.8003 - auc: 0.8890 - precision: 0.6658 - recall: 0.6246 - f1score: 0.2021 - val_loss: 2.0329 - val_acc: 0.2268 - val_auc: 0.8919 - val_precision: 0.6707 - val_recall: 0.6307 - val_f1score: 0.0794\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.4616 - acc: 0.8011 - auc: 0.8946 - precision: 0.6755 - recall: 0.6365 - f1score: 0.2029 - val_loss: 1.8903 - val_acc: 0.2268 - val_auc: 0.8970 - val_precision: 0.6794 - val_recall: 0.6415 - val_f1score: 0.0829\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.4360 - acc: 0.8140 - auc: 0.8995 - precision: 0.6836 - recall: 0.6465 - f1score: 0.2056 - val_loss: 1.9776 - val_acc: 0.2268 - val_auc: 0.9017 - val_precision: 0.6876 - val_recall: 0.6515 - val_f1score: 0.0801\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.4046 - acc: 0.8268 - auc: 0.9041 - precision: 0.6920 - recall: 0.6568 - f1score: 0.2079 - val_loss: 1.9137 - val_acc: 0.2268 - val_auc: 0.9061 - val_precision: 0.6954 - val_recall: 0.6611 - val_f1score: 0.0832\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.3696 - acc: 0.8432 - auc: 0.9084 - precision: 0.6997 - recall: 0.6661 - f1score: 0.2115 - val_loss: 1.9561 - val_acc: 0.2268 - val_auc: 0.9104 - val_precision: 0.7032 - val_recall: 0.6704 - val_f1score: 0.0831\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.3604 - acc: 0.8546 - auc: 0.9124 - precision: 0.7071 - recall: 0.6749 - f1score: 0.2127 - val_loss: 1.9741 - val_acc: 0.2268 - val_auc: 0.9142 - val_precision: 0.7106 - val_recall: 0.6791 - val_f1score: 0.0835\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.3392 - acc: 0.8533 - auc: 0.9161 - precision: 0.7142 - recall: 0.6832 - f1score: 0.2142 - val_loss: 1.9700 - val_acc: 0.2268 - val_auc: 0.9177 - val_precision: 0.7170 - val_recall: 0.6867 - val_f1score: 0.0828\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.3103 - acc: 0.8668 - auc: 0.9194 - precision: 0.7203 - recall: 0.6905 - f1score: 0.2166 - val_loss: 1.9955 - val_acc: 0.2268 - val_auc: 0.9210 - val_precision: 0.7233 - val_recall: 0.6941 - val_f1score: 0.0833\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.3060 - acc: 0.8807 - auc: 0.9226 - precision: 0.7267 - recall: 0.6979 - f1score: 0.2175 - val_loss: 2.1660 - val_acc: 0.2268 - val_auc: 0.9240 - val_precision: 0.7298 - val_recall: 0.7015 - val_f1score: 0.0770\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.3086 - acc: 0.8760 - auc: 0.9253 - precision: 0.7326 - recall: 0.7047 - f1score: 0.2173 - val_loss: 1.9743 - val_acc: 0.2268 - val_auc: 0.9265 - val_precision: 0.7352 - val_recall: 0.7078 - val_f1score: 0.0827\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.2835 - acc: 0.8834 - auc: 0.9279 - precision: 0.7381 - recall: 0.7111 - f1score: 0.2193 - val_loss: 1.9487 - val_acc: 0.2268 - val_auc: 0.9291 - val_precision: 0.7404 - val_recall: 0.7139 - val_f1score: 0.0830\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2703 - acc: 0.8920 - auc: 0.9304 - precision: 0.7431 - recall: 0.7170 - f1score: 0.2208 - val_loss: 1.8693 - val_acc: 0.2268 - val_auc: 0.9315 - val_precision: 0.7455 - val_recall: 0.7197 - val_f1score: 0.0864\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2518 - acc: 0.8986 - auc: 0.9328 - precision: 0.7481 - recall: 0.7227 - f1score: 0.2225 - val_loss: 1.9930 - val_acc: 0.2268 - val_auc: 0.9339 - val_precision: 0.7503 - val_recall: 0.7254 - val_f1score: 0.0837\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.2596 - acc: 0.9011 - auc: 0.9349 - precision: 0.7527 - recall: 0.7281 - f1score: 0.2223 - val_loss: 2.0756 - val_acc: 0.2268 - val_auc: 0.9359 - val_precision: 0.7549 - val_recall: 0.7307 - val_f1score: 0.0824\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2370 - acc: 0.9064 - auc: 0.9370 - precision: 0.7573 - recall: 0.7334 - f1score: 0.2240 - val_loss: 1.9363 - val_acc: 0.2268 - val_auc: 0.9379 - val_precision: 0.7593 - val_recall: 0.7358 - val_f1score: 0.0838\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.2416 - acc: 0.9051 - auc: 0.9389 - precision: 0.7614 - recall: 0.7382 - f1score: 0.2239 - val_loss: 2.1090 - val_acc: 0.2268 - val_auc: 0.9397 - val_precision: 0.7633 - val_recall: 0.7404 - val_f1score: 0.0813\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2314 - acc: 0.9092 - auc: 0.9406 - precision: 0.7653 - recall: 0.7427 - f1score: 0.2250 - val_loss: 1.9876 - val_acc: 0.2268 - val_auc: 0.9414 - val_precision: 0.7670 - val_recall: 0.7448 - val_f1score: 0.0883\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.2109 - acc: 0.9188 - auc: 0.9424 - precision: 0.7691 - recall: 0.7471 - f1score: 0.2268 - val_loss: 2.0395 - val_acc: 0.2268 - val_auc: 0.9432 - val_precision: 0.7709 - val_recall: 0.7492 - val_f1score: 0.0862\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.2023 - acc: 0.9219 - auc: 0.9440 - precision: 0.7729 - recall: 0.7515 - f1score: 0.2276 - val_loss: 1.9697 - val_acc: 0.2268 - val_auc: 0.9448 - val_precision: 0.7746 - val_recall: 0.7535 - val_f1score: 0.0872\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1818 - acc: 0.9339 - auc: 0.9457 - precision: 0.7766 - recall: 0.7558 - f1score: 0.2299 - val_loss: 1.9818 - val_acc: 0.2268 - val_auc: 0.9464 - val_precision: 0.7784 - val_recall: 0.7578 - val_f1score: 0.0872\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1857 - acc: 0.9272 - auc: 0.9472 - precision: 0.7802 - recall: 0.7599 - f1score: 0.2293 - val_loss: 1.8962 - val_acc: 0.2268 - val_auc: 0.9479 - val_precision: 0.7817 - val_recall: 0.7616 - val_f1score: 0.0897\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.1934 - acc: 0.9283 - auc: 0.9486 - precision: 0.7834 - recall: 0.7636 - f1score: 0.2290 - val_loss: 1.9660 - val_acc: 0.2268 - val_auc: 0.9493 - val_precision: 0.7848 - val_recall: 0.7653 - val_f1score: 0.0882\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.1803 - acc: 0.9331 - auc: 0.9499 - precision: 0.7865 - recall: 0.7672 - f1score: 0.2301 - val_loss: 1.9824 - val_acc: 0.2268 - val_auc: 0.9506 - val_precision: 0.7879 - val_recall: 0.7688 - val_f1score: 0.0880\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1726 - acc: 0.9335 - auc: 0.9512 - precision: 0.7895 - recall: 0.7706 - f1score: 0.2310 - val_loss: 1.9701 - val_acc: 0.2268 - val_auc: 0.9518 - val_precision: 0.7908 - val_recall: 0.7722 - val_f1score: 0.0868\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1700 - acc: 0.9364 - auc: 0.9524 - precision: 0.7923 - recall: 0.7738 - f1score: 0.2311 - val_loss: 2.0533 - val_acc: 0.2268 - val_auc: 0.9530 - val_precision: 0.7936 - val_recall: 0.7754 - val_f1score: 0.0842\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1730 - acc: 0.9310 - auc: 0.9536 - precision: 0.7950 - recall: 0.7769 - f1score: 0.2307 - val_loss: 1.7970 - val_acc: 0.2268 - val_auc: 0.9541 - val_precision: 0.7961 - val_recall: 0.7783 - val_f1score: 0.0920\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.1578 - acc: 0.9411 - auc: 0.9547 - precision: 0.7976 - recall: 0.7799 - f1score: 0.2323 - val_loss: 1.8720 - val_acc: 0.2268 - val_auc: 0.9552 - val_precision: 0.7988 - val_recall: 0.7812 - val_f1score: 0.0897\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1572 - acc: 0.9411 - auc: 0.9558 - precision: 0.8001 - recall: 0.7827 - f1score: 0.2324 - val_loss: 1.8862 - val_acc: 0.2268 - val_auc: 0.9562 - val_precision: 0.8012 - val_recall: 0.7841 - val_f1score: 0.0888\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1496 - acc: 0.9463 - auc: 0.9568 - precision: 0.8026 - recall: 0.7856 - f1score: 0.2335 - val_loss: 1.9756 - val_acc: 0.2268 - val_auc: 0.9572 - val_precision: 0.8037 - val_recall: 0.7869 - val_f1score: 0.0848\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1439 - acc: 0.9503 - auc: 0.9578 - precision: 0.8050 - recall: 0.7883 - f1score: 0.2339 - val_loss: 1.9516 - val_acc: 0.2268 - val_auc: 0.9582 - val_precision: 0.8061 - val_recall: 0.7896 - val_f1score: 0.0854\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.1444 - acc: 0.9481 - auc: 0.9587 - precision: 0.8073 - recall: 0.7910 - f1score: 0.2339 - val_loss: 1.9271 - val_acc: 0.2268 - val_auc: 0.9591 - val_precision: 0.8084 - val_recall: 0.7922 - val_f1score: 0.0875\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1449 - acc: 0.9508 - auc: 0.9595 - precision: 0.8096 - recall: 0.7935 - f1score: 0.2341 - val_loss: 1.9680 - val_acc: 0.2268 - val_auc: 0.9599 - val_precision: 0.8106 - val_recall: 0.7947 - val_f1score: 0.0829\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.1293 - acc: 0.9556 - auc: 0.9604 - precision: 0.8118 - recall: 0.7960 - f1score: 0.2355 - val_loss: 1.8948 - val_acc: 0.2268 - val_auc: 0.9608 - val_precision: 0.8128 - val_recall: 0.7972 - val_f1score: 0.0854\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1371 - acc: 0.9516 - auc: 0.9612 - precision: 0.8139 - recall: 0.7984 - f1score: 0.2347 - val_loss: 1.8364 - val_acc: 0.2268 - val_auc: 0.9616 - val_precision: 0.8148 - val_recall: 0.7995 - val_f1score: 0.0889\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1256 - acc: 0.9575 - auc: 0.9620 - precision: 0.8159 - recall: 0.8007 - f1score: 0.2359 - val_loss: 1.7312 - val_acc: 0.2268 - val_auc: 0.9624 - val_precision: 0.8174 - val_recall: 0.8016 - val_f1score: 0.0923\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.1152 - acc: 0.9628 - auc: 0.9628 - precision: 0.8190 - recall: 0.8027 - f1score: 0.2368 - val_loss: 1.8401 - val_acc: 0.2268 - val_auc: 0.9632 - val_precision: 0.8199 - val_recall: 0.8038 - val_f1score: 0.0895\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1151 - acc: 0.9599 - auc: 0.9636 - precision: 0.8209 - recall: 0.8049 - f1score: 0.2369 - val_loss: 1.8592 - val_acc: 0.2268 - val_auc: 0.9639 - val_precision: 0.8218 - val_recall: 0.8059 - val_f1score: 0.0872\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.1228 - acc: 0.9601 - auc: 0.9643 - precision: 0.8228 - recall: 0.8071 - f1score: 0.2365 - val_loss: 1.8731 - val_acc: 0.2268 - val_auc: 0.9646 - val_precision: 0.8236 - val_recall: 0.8081 - val_f1score: 0.0881\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1134 - acc: 0.9632 - auc: 0.9650 - precision: 0.8246 - recall: 0.8091 - f1score: 0.2371 - val_loss: 1.8318 - val_acc: 0.2268 - val_auc: 0.9653 - val_precision: 0.8255 - val_recall: 0.8101 - val_f1score: 0.0898\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1120 - acc: 0.9600 - auc: 0.9656 - precision: 0.8265 - recall: 0.8111 - f1score: 0.2374 - val_loss: 1.8468 - val_acc: 0.2268 - val_auc: 0.9659 - val_precision: 0.8274 - val_recall: 0.8120 - val_f1score: 0.0888\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.1105 - acc: 0.9628 - auc: 0.9663 - precision: 0.8285 - recall: 0.8130 - f1score: 0.2375 - val_loss: 1.8512 - val_acc: 0.2268 - val_auc: 0.9666 - val_precision: 0.8292 - val_recall: 0.8138 - val_f1score: 0.0886\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=150, \n",
    "            epochs=50, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=32, \n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('X_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 3ms/step\n",
      "loss: 1.851, accuracy: 0.227, auc: 0.966, precision: 0.828, recall: 0.813, f1score: 0.089\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 2s 3ms/step\n",
      "loss: 902.773, accuracy: 0.209, auc: 0.965, precision: 0.827, recall: 0.812, f1score: nan\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_model.save('ResNet50_fine tuning_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
