{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#data path 수정\n",
    "os.chdir(\"C:\\\\Users\\\\Owner2\\\\Desktop\\\\G팔로미_vuno\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('data_X.npy')\n",
    "y=np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True, #center 중심 유지\n",
    "    #featurewise_std_normalization=True, #normalization\n",
    "    rotation_range=25.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=[0.2,1.0],\n",
    "    horizontal_flip=True) #수평방향 뒤집기\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dgf=datagen.flow(X_train,y_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner2\\Anaconda3\\envs\\keras2\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 401412    \n",
      "=================================================================\n",
      "Total params: 23,989,124\n",
      "Trainable params: 401,412\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#customizing my layers\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(model)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(precision, recall):\n",
    "    _f1score = ( 2 * recall * precision) / (recall + precision)\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(filepath='My_VGG_{epoch:03d}_{val_loss:.7f}.hdf5',monitor='loss', mode='min', save_best_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath='ResNet_fine tuning_1.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['acc',tf.keras.metrics.AUC(),\n",
    "                      tf.keras.metrics.Precision(),\n",
    "                      tf.keras.metrics.Recall(),f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 48s 321ms/step - loss: 1.2707 - acc: 0.5290 - auc: 0.7261 - precision: 0.4676 - recall: 0.4056 - f1score: 0.1464 - val_loss: 2.8421 - val_acc: 0.3434 - val_auc: 0.7802 - val_precision: 0.5304 - val_recall: 0.4805 - val_f1score: 0.0903\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.9424 - acc: 0.6142 - auc: 0.7946 - precision: 0.5451 - recall: 0.5014 - f1score: 0.1672 - val_loss: 3.0694 - val_acc: 0.3434 - val_auc: 0.8063 - val_precision: 0.5579 - val_recall: 0.5180 - val_f1score: 0.0893\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.8140 - acc: 0.6553 - auc: 0.8145 - precision: 0.5695 - recall: 0.5324 - f1score: 0.1754 - val_loss: 3.2671 - val_acc: 0.3434 - val_auc: 0.8201 - val_precision: 0.5781 - val_recall: 0.5434 - val_f1score: 0.0880\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.7363 - acc: 0.6901 - auc: 0.8251 - precision: 0.5874 - recall: 0.5548 - f1score: 0.1823 - val_loss: 3.4190 - val_acc: 0.3434 - val_auc: 0.8294 - val_precision: 0.5953 - val_recall: 0.5646 - val_f1score: 0.0875\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.6891 - acc: 0.7022 - auc: 0.8329 - precision: 0.6008 - recall: 0.5716 - f1score: 0.1854 - val_loss: 3.7742 - val_acc: 0.3434 - val_auc: 0.8360 - val_precision: 0.6070 - val_recall: 0.5790 - val_f1score: 0.0867\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.6281 - acc: 0.7278 - auc: 0.8390 - precision: 0.6128 - recall: 0.5856 - f1score: 0.1904 - val_loss: 3.8651 - val_acc: 0.3434 - val_auc: 0.8416 - val_precision: 0.6187 - val_recall: 0.5923 - val_f1score: 0.0865\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.5769 - acc: 0.7540 - auc: 0.8442 - precision: 0.6245 - recall: 0.5988 - f1score: 0.1943 - val_loss: 3.8977 - val_acc: 0.3434 - val_auc: 0.8467 - val_precision: 0.6301 - val_recall: 0.6053 - val_f1score: 0.0865\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.5442 - acc: 0.7674 - auc: 0.8490 - precision: 0.6354 - recall: 0.6113 - f1score: 0.1975 - val_loss: 3.8844 - val_acc: 0.3434 - val_auc: 0.8510 - val_precision: 0.6401 - val_recall: 0.6168 - val_f1score: 0.0865\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.5084 - acc: 0.7798 - auc: 0.8532 - precision: 0.6448 - recall: 0.6220 - f1score: 0.2002 - val_loss: 4.0644 - val_acc: 0.3434 - val_auc: 0.8549 - val_precision: 0.6489 - val_recall: 0.6268 - val_f1score: 0.0864\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.4854 - acc: 0.7865 - auc: 0.8566 - precision: 0.6524 - recall: 0.6308 - f1score: 0.2019 - val_loss: 3.8448 - val_acc: 0.3434 - val_auc: 0.8583 - val_precision: 0.6565 - val_recall: 0.6355 - val_f1score: 0.0865\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.4427 - acc: 0.8047 - auc: 0.8601 - precision: 0.6603 - recall: 0.6398 - f1score: 0.2053 - val_loss: 3.8461 - val_acc: 0.3434 - val_auc: 0.8617 - val_precision: 0.6641 - val_recall: 0.6440 - val_f1score: 0.0865\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.4508 - acc: 0.8079 - auc: 0.8632 - precision: 0.6674 - recall: 0.6478 - f1score: 0.2052 - val_loss: 3.9006 - val_acc: 0.3434 - val_auc: 0.8640 - val_precision: 0.6706 - val_recall: 0.6514 - val_f1score: 0.0864\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.4058 - acc: 0.8221 - auc: 0.8652 - precision: 0.6740 - recall: 0.6551 - f1score: 0.2090 - val_loss: 3.8049 - val_acc: 0.3434 - val_auc: 0.8665 - val_precision: 0.6771 - val_recall: 0.6585 - val_f1score: 0.0865\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.3947 - acc: 0.8275 - auc: 0.8679 - precision: 0.6799 - recall: 0.6616 - f1score: 0.2097 - val_loss: 3.8724 - val_acc: 0.3434 - val_auc: 0.8687 - val_precision: 0.6828 - val_recall: 0.6649 - val_f1score: 0.0865\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.3834 - acc: 0.8359 - auc: 0.8697 - precision: 0.6857 - recall: 0.6681 - f1score: 0.2112 - val_loss: 3.7609 - val_acc: 0.3434 - val_auc: 0.8708 - val_precision: 0.6883 - val_recall: 0.6710 - val_f1score: 0.0866\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.3350 - acc: 0.8579 - auc: 0.8722 - precision: 0.6914 - recall: 0.6744 - f1score: 0.2151 - val_loss: 3.9096 - val_acc: 0.3434 - val_auc: 0.8730 - val_precision: 0.6943 - val_recall: 0.6776 - val_f1score: 0.0864\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.3438 - acc: 0.8497 - auc: 0.8739 - precision: 0.6968 - recall: 0.6804 - f1score: 0.2145 - val_loss: 3.8800 - val_acc: 0.3434 - val_auc: 0.8748 - val_precision: 0.6991 - val_recall: 0.6830 - val_f1score: 0.0865\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.3130 - acc: 0.8665 - auc: 0.8760 - precision: 0.7018 - recall: 0.6859 - f1score: 0.2170 - val_loss: 3.9655 - val_acc: 0.3434 - val_auc: 0.8767 - val_precision: 0.7042 - val_recall: 0.6886 - val_f1score: 0.0864\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.3126 - acc: 0.8657 - auc: 0.8775 - precision: 0.7065 - recall: 0.6911 - f1score: 0.2172 - val_loss: 3.9571 - val_acc: 0.3434 - val_auc: 0.8781 - val_precision: 0.7087 - val_recall: 0.6936 - val_f1score: 0.0864\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.2954 - acc: 0.8759 - auc: 0.8789 - precision: 0.7112 - recall: 0.6962 - f1score: 0.2190 - val_loss: 3.9896 - val_acc: 0.3434 - val_auc: 0.8795 - val_precision: 0.7132 - val_recall: 0.6985 - val_f1score: 0.0864\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.2940 - acc: 0.8779 - auc: 0.8802 - precision: 0.7153 - recall: 0.7008 - f1score: 0.2189 - val_loss: 3.8648 - val_acc: 0.3434 - val_auc: 0.8807 - val_precision: 0.7173 - val_recall: 0.7030 - val_f1score: 0.0864\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.2978 - acc: 0.8701 - auc: 0.8814 - precision: 0.7192 - recall: 0.7050 - f1score: 0.2189 - val_loss: 3.8780 - val_acc: 0.3434 - val_auc: 0.8819 - val_precision: 0.7208 - val_recall: 0.7068 - val_f1score: 0.0864\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.2770 - acc: 0.8800 - auc: 0.8825 - precision: 0.7226 - recall: 0.7088 - f1score: 0.2206 - val_loss: 4.0402 - val_acc: 0.3434 - val_auc: 0.8830 - val_precision: 0.7243 - val_recall: 0.7107 - val_f1score: 0.0863\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.2509 - acc: 0.8930 - auc: 0.8836 - precision: 0.7262 - recall: 0.7128 - f1score: 0.2232 - val_loss: 3.9083 - val_acc: 0.3434 - val_auc: 0.8841 - val_precision: 0.7280 - val_recall: 0.7147 - val_f1score: 0.0864\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 40s 269ms/step - loss: 0.2483 - acc: 0.8927 - auc: 0.8847 - precision: 0.7297 - recall: 0.7166 - f1score: 0.2232 - val_loss: 4.1727 - val_acc: 0.3434 - val_auc: 0.8852 - val_precision: 0.7313 - val_recall: 0.7184 - val_f1score: 0.0862\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.2475 - acc: 0.9023 - auc: 0.8857 - precision: 0.7331 - recall: 0.7204 - f1score: 0.2237 - val_loss: 4.0875 - val_acc: 0.3434 - val_auc: 0.8862 - val_precision: 0.7347 - val_recall: 0.7221 - val_f1score: 0.0863\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.2403 - acc: 0.9052 - auc: 0.8867 - precision: 0.7364 - recall: 0.7240 - f1score: 0.2245 - val_loss: 4.1424 - val_acc: 0.3434 - val_auc: 0.8871 - val_precision: 0.7379 - val_recall: 0.7257 - val_f1score: 0.0862\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.2292 - acc: 0.9061 - auc: 0.8876 - precision: 0.7395 - recall: 0.7274 - f1score: 0.2255 - val_loss: 4.1930 - val_acc: 0.3434 - val_auc: 0.8880 - val_precision: 0.7409 - val_recall: 0.7290 - val_f1score: 0.0862\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 41s 272ms/step - loss: 0.2226 - acc: 0.9107 - auc: 0.8885 - precision: 0.7424 - recall: 0.7306 - f1score: 0.2262 - val_loss: 3.9409 - val_acc: 0.3434 - val_auc: 0.8889 - val_precision: 0.7439 - val_recall: 0.7322 - val_f1score: 0.0864\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.2284 - acc: 0.9019 - auc: 0.8894 - precision: 0.7452 - recall: 0.7336 - f1score: 0.2257 - val_loss: 4.0368 - val_acc: 0.3434 - val_auc: 0.8897 - val_precision: 0.7464 - val_recall: 0.7349 - val_f1score: 0.0863\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 41s 270ms/step - loss: 0.2107 - acc: 0.9210 - auc: 0.8902 - precision: 0.7478 - recall: 0.7365 - f1score: 0.2273 - val_loss: 3.9541 - val_acc: 0.3434 - val_auc: 0.8905 - val_precision: 0.7492 - val_recall: 0.7380 - val_f1score: 0.0864\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.2126 - acc: 0.9132 - auc: 0.8910 - precision: 0.7505 - recall: 0.7394 - f1score: 0.2273 - val_loss: 3.8197 - val_acc: 0.3434 - val_auc: 0.8913 - val_precision: 0.7517 - val_recall: 0.7408 - val_f1score: 0.0865\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 41s 270ms/step - loss: 0.1951 - acc: 0.9233 - auc: 0.8918 - precision: 0.7531 - recall: 0.7423 - f1score: 0.2287 - val_loss: 4.1014 - val_acc: 0.3434 - val_auc: 0.8921 - val_precision: 0.7543 - val_recall: 0.7436 - val_f1score: 0.0863\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1734 - acc: 0.9371 - auc: 0.8926 - precision: 0.7557 - recall: 0.7451 - f1score: 0.2310 - val_loss: 4.1540 - val_acc: 0.3434 - val_auc: 0.8929 - val_precision: 0.7570 - val_recall: 0.7466 - val_f1score: 0.0863\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1951 - acc: 0.9244 - auc: 0.8933 - precision: 0.7583 - recall: 0.7479 - f1score: 0.2290 - val_loss: 4.1502 - val_acc: 0.3434 - val_auc: 0.8936 - val_precision: 0.7594 - val_recall: 0.7491 - val_f1score: 0.0863\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.1680 - acc: 0.9338 - auc: 0.8940 - precision: 0.7606 - recall: 0.7504 - f1score: 0.2313 - val_loss: 4.3192 - val_acc: 0.3434 - val_auc: 0.8943 - val_precision: 0.7617 - val_recall: 0.7517 - val_f1score: 0.0862\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1687 - acc: 0.9369 - auc: 0.8946 - precision: 0.7629 - recall: 0.7530 - f1score: 0.2315 - val_loss: 4.4031 - val_acc: 0.3434 - val_auc: 0.8949 - val_precision: 0.7641 - val_recall: 0.7542 - val_f1score: 0.0861\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1723 - acc: 0.9340 - auc: 0.8952 - precision: 0.7652 - recall: 0.7554 - f1score: 0.2312 - val_loss: 4.5738 - val_acc: 0.3434 - val_auc: 0.8954 - val_precision: 0.7662 - val_recall: 0.7565 - val_f1score: 0.0861\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.1517 - acc: 0.9411 - auc: 0.8958 - precision: 0.7673 - recall: 0.7578 - f1score: 0.2330 - val_loss: 4.3212 - val_acc: 0.3434 - val_auc: 0.8960 - val_precision: 0.7684 - val_recall: 0.7589 - val_f1score: 0.0862\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.1610 - acc: 0.9365 - auc: 0.8963 - precision: 0.7694 - recall: 0.7600 - f1score: 0.2322 - val_loss: 4.4752 - val_acc: 0.3434 - val_auc: 0.8965 - val_precision: 0.7704 - val_recall: 0.7611 - val_f1score: 0.0861\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1674 - acc: 0.9357 - auc: 0.8968 - precision: 0.7713 - recall: 0.7621 - f1score: 0.2317 - val_loss: 4.3855 - val_acc: 0.3434 - val_auc: 0.8970 - val_precision: 0.7722 - val_recall: 0.7631 - val_f1score: 0.0862\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1639 - acc: 0.9378 - auc: 0.8973 - precision: 0.7732 - recall: 0.7641 - f1score: 0.2321 - val_loss: 4.2603 - val_acc: 0.3434 - val_auc: 0.8975 - val_precision: 0.7741 - val_recall: 0.7651 - val_f1score: 0.0863\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1470 - acc: 0.9413 - auc: 0.8978 - precision: 0.7750 - recall: 0.7661 - f1score: 0.2335 - val_loss: 4.3470 - val_acc: 0.3434 - val_auc: 0.8980 - val_precision: 0.7759 - val_recall: 0.7670 - val_f1score: 0.0862\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1517 - acc: 0.9441 - auc: 0.8983 - precision: 0.7769 - recall: 0.7681 - f1score: 0.2336 - val_loss: 4.2476 - val_acc: 0.3434 - val_auc: 0.8985 - val_precision: 0.7777 - val_recall: 0.7690 - val_f1score: 0.0863\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1517 - acc: 0.9403 - auc: 0.8988 - precision: 0.7785 - recall: 0.7699 - f1score: 0.2334 - val_loss: 4.4116 - val_acc: 0.3434 - val_auc: 0.8990 - val_precision: 0.7793 - val_recall: 0.7707 - val_f1score: 0.0862\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.1461 - acc: 0.9451 - auc: 0.8993 - precision: 0.7801 - recall: 0.7716 - f1score: 0.2338 - val_loss: 4.5386 - val_acc: 0.3434 - val_auc: 0.8995 - val_precision: 0.7809 - val_recall: 0.7725 - val_f1score: 0.0862\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.1370 - acc: 0.9485 - auc: 0.8997 - precision: 0.7818 - recall: 0.7735 - f1score: 0.2350 - val_loss: 4.5522 - val_acc: 0.3434 - val_auc: 0.8999 - val_precision: 0.7826 - val_recall: 0.7743 - val_f1score: 0.0862\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1410 - acc: 0.9487 - auc: 0.9001 - precision: 0.7834 - recall: 0.7752 - f1score: 0.2346 - val_loss: 4.4349 - val_acc: 0.3434 - val_auc: 0.9003 - val_precision: 0.7841 - val_recall: 0.7760 - val_f1score: 0.0862\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1389 - acc: 0.9505 - auc: 0.9005 - precision: 0.7849 - recall: 0.7768 - f1score: 0.2350 - val_loss: 4.5550 - val_acc: 0.3434 - val_auc: 0.9007 - val_precision: 0.7856 - val_recall: 0.7776 - val_f1score: 0.0862\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.1212 - acc: 0.9554 - auc: 0.9009 - precision: 0.7865 - recall: 0.7785 - f1score: 0.2364 - val_loss: 4.6913 - val_acc: 0.3434 - val_auc: 0.9011 - val_precision: 0.7872 - val_recall: 0.7793 - val_f1score: 0.0861\n"
     ]
    }
   ],
   "source": [
    "history = additional_model.fit_generator(dgf, \n",
    "            steps_per_epoch=150, \n",
    "            epochs=50, \n",
    "            validation_data=(X_val,y_val), \n",
    "            validation_steps=32, \n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1, len(acc) + 1)\n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load('X_test.npy')\n",
    "y_test=np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859/859 [==============================] - 3s 3ms/step\n",
      "loss: 4.691, accuracy: 0.343, auc: 0.900, precision: 0.786, recall: 0.778, f1score: 0.086\n"
     ]
    }
   ],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_val, y_val, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss, _acc, _auc, _precision, _recall, _f1score = additional_model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, auc: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _auc, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_model.save('ResNet50_fine tuning_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
